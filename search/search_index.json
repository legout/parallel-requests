{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"fastreq","text":"<p>A high-performance Python library for executing parallel HTTP requests with built-in retry logic, proxy rotation, rate limiting, and support for multiple HTTP backends.</p>"},{"location":"#features","title":"Features","text":"<ul> <li>Parallel Execution: Execute multiple HTTP requests concurrently with automatic async/sync handling</li> <li>Multiple Backends: Support for niquests, aiohttp, and requests with automatic backend detection</li> <li>Retry Logic: Exponential backoff with jitter for resilient request handling</li> <li>Proxy Rotation: Automatic proxy management with support for authenticated proxies</li> <li>Rate Limiting: Token bucket algorithm for precise request rate control</li> <li>User-Agent Rotation: Built-in user agent string rotation</li> <li>Cookie Management: Session-based cookie handling with set/reset methods</li> <li>Flexible Response Parsing: Custom parse functions, keyed responses, and graceful failure handling</li> <li>HTTP/2 Support: Full HTTP/2 support when using the niquests backend</li> <li>Streaming: Efficient streaming of large responses</li> </ul>"},{"location":"#installation","title":"Installation","text":"<pre><code>pip install fastreq\n\n# Install with all backend support\npip install fastreq[all]\n\n# Install with specific backend\npip install fastreq[niquests]  # For HTTP/2 support\npip install fastreq[aiohttp]\npip install fastreq[requests]\n</code></pre>"},{"location":"#quick-start","title":"Quick Start","text":"<pre><code>from fastreq import fastreq\n\n# Make parallel requests\nresults = fastreq(\n    urls=[\n        \"https://api.github.com/repos/python/cpython\",\n        \"https://api.github.com/repos/python/cpython/issues\",\n        \"https://api.github.com/repos/python/cpython/pulls\",\n    ],\n    concurrency=3,\n)\n\nfor result in results:\n    print(result.json())\n</code></pre>"},{"location":"#async-usage","title":"Async Usage","text":"<pre><code>import asyncio\nfrom fastreq import fastreq_async\n\nasync def main():\n    results = await fastreq_async(\n        urls=[\n            \"https://httpbin.org/delay/1\",\n            \"https://httpbin.org/delay/2\",\n            \"https://httpbin.org/delay/3\",\n        ],\n        concurrency=5,\n        timeout=10,\n    )\n    return results\n\nresults = asyncio.run(main())\n</code></pre>"},{"location":"#quick-links","title":"Quick Links","text":""},{"location":"#new-users","title":"New Users","text":"<ul> <li>Getting Started Tutorial - Installation and your first parallel requests</li> <li>Basic Examples - Runnable code samples</li> </ul>"},{"location":"#common-tasks","title":"Common Tasks","text":"<ul> <li>Make Parallel Requests</li> <li>Handle Rate Limits</li> <li>Configure Retries</li> <li>Use Proxies</li> </ul>"},{"location":"#api-reference","title":"API Reference","text":"<ul> <li>API Overview</li> <li>FastRequests Class</li> <li>Configuration Options</li> </ul>"},{"location":"#advanced-topics","title":"Advanced Topics","text":"<ul> <li>Architecture</li> <li>Backend Comparison</li> </ul>"},{"location":"#examples","title":"Examples","text":"<p>Visit the examples folder for executable code samples covering all library features.</p>"},{"location":"#backend-selection","title":"Backend Selection","text":"<p>The library automatically detects and uses the best available backend in this priority order:</p> <ol> <li>niquests - Recommended (HTTP/2 support, streaming, async native)</li> <li>aiohttp - Streaming support, async native</li> <li>requests - Sync-first, streaming via thread wrapper</li> </ol> <p>To explicitly select a backend:</p> <pre><code>from fastreq import fastreq\n\nresults = fastreq(\n    urls=[\"https://httpbin.org/get\"],\n    backend=\"niquests\",  # Explicit backend selection\n)\n</code></pre>"},{"location":"#license","title":"License","text":"<p>MIT License - see LICENSE for details.</p>"},{"location":"explanation/","title":"Explanations","text":"<p>Explain how things work under the hood and why design decisions were made.</p>"},{"location":"explanation/#what-are-explanations","title":"What are Explanations?","text":"<p>Explanations provide in-depth understanding of the library's internal mechanics, design philosophy, and algorithms. Unlike tutorials (which teach you how to do something) or how-to guides (which provide step-by-step solutions), explanations focus on the \"why\" and \"how it works.\"</p>"},{"location":"explanation/#documentation-types","title":"Documentation Types","text":"Type Purpose Example Tutorials Learning-oriented, step-by-step lessons \"Make your first parallel request\" How-to Guides Problem-solving, practical solutions \"Handle rate limits for an API\" Reference Technical details, API documentation <code>FastRequests</code> class parameters Explanations Understanding internal design \"Why token bucket for rate limiting?\""},{"location":"explanation/#when-to-consult-explanations","title":"When to Consult Explanations","text":"<p>Consult explanations when you want to understand:</p> <ul> <li>Design decisions - Why certain algorithms or patterns were chosen</li> <li>Internal mechanics - How features work under the hood</li> <li>Trade-offs - Benefits and limitations of different approaches</li> <li>Performance characteristics - How different backends or settings affect performance</li> <li>Algorithm details - Mathematical formulas or implementation details</li> </ul>"},{"location":"explanation/#explanation-topics","title":"Explanation Topics","text":""},{"location":"explanation/#architecture","title":"Architecture","text":"<p>Architecture - Design philosophy, component overview, and how parts interact</p>"},{"location":"explanation/#backends","title":"Backends","text":"<p>Backends - HTTP client library comparison, auto-detection, and when to use each</p>"},{"location":"explanation/#rate-limiting","title":"Rate Limiting","text":"<p>Rate Limiting - Token bucket algorithm, burst handling, and concurrency control</p>"},{"location":"explanation/#retry-strategy","title":"Retry Strategy","text":"<p>Retry Strategy - Exponential backoff, jitter, and thundering herd prevention</p>"},{"location":"explanation/#proxy-rotation","title":"Proxy Rotation","text":"<p>Proxy Rotation - IP rotation, proxy validation, and health tracking</p>"},{"location":"explanation/#related-documentation","title":"Related Documentation","text":"<ul> <li>Tutorials - Start here for hands-on learning</li> <li>How-to Guides - Practical solutions to common problems</li> <li>Reference - Complete API documentation</li> </ul>"},{"location":"explanation/architecture/","title":"Architecture","text":"<p>The fastreq library is designed around a few core principles that enable flexible, efficient, and maintainable parallel HTTP requests.</p>"},{"location":"explanation/architecture/#design-philosophy","title":"Design Philosophy","text":""},{"location":"explanation/architecture/#strategy-pattern","title":"Strategy Pattern","text":"<p>The library uses the Strategy pattern to support multiple HTTP backends through a common interface. This allows you to:</p> <ul> <li>Swap between niquests, aiohttp, and requests without changing application code</li> <li>Add new backends without modifying the client logic</li> <li>Test with different backends to find the best fit for your use case</li> </ul> <p>The <code>Backend</code> abstract base class defines the contract that all backends must implement:</p> <pre><code>class Backend(ABC):\n    @abstractmethod\n    async def request(self, config: RequestConfig) -&gt; NormalizedResponse:\n        ...\n\n    @abstractmethod\n    async def close(self) -&gt; None:\n        ...\n\n    @abstractmethod\n    def supports_http2(self) -&gt; bool:\n        ...\n</code></pre>"},{"location":"explanation/architecture/#async-first-design","title":"Async-First Design","text":"<p>Python's <code>asyncio</code> is the foundation of the library. All operations are asynchronous internally, even when using synchronous backends like requests. The synchronous <code>fastreq()</code> function is just a thin wrapper that runs <code>asyncio.run()</code> behind the scenes.</p> <p>Why async-first?</p> <ul> <li>Performance: Non-blocking I/O allows thousands of concurrent requests</li> <li>Efficiency: Thread pools only used when necessary (for sync backends)</li> <li>Modern: Aligns with modern Python async ecosystem</li> <li>Flexible: Works seamlessly in async applications and sync contexts</li> </ul>"},{"location":"explanation/architecture/#separation-of-concerns","title":"Separation of Concerns","text":"<p>The library is organized into distinct layers:</p> <pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                     User API Layer                         \u2502\n\u2502  fastreq() / fastreq_async()           \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                              \u2502\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                   Client Layer                              \u2502\n\u2502           FastRequests class                                \u2502\n\u2502  (orchestrates requests, retries, rate limiting)            \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                              \u2502\n        \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n        \u2502                     \u2502                     \u2502\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502  Retry Layer  \u2502   \u2502  Rate Limiter   \u2502   \u2502   Utilities      \u2502\n\u2502   (backoff)   \u2502   \u2502  (token bucket) \u2502   \u2502  (proxies, etc.) \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                              \u2502\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                   Backend Layer                             \u2502\n\u2502    NiquestsBackend \u2502 AiohttpBackend \u2502 RequestsBackend        \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                              \u2502\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                 HTTP Libraries                              \u2502\n\u2502    niquests \u2502 aiohttp \u2502 requests                            \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"explanation/architecture/#component-overview","title":"Component Overview","text":""},{"location":"explanation/architecture/#fastrequests-client","title":"FastRequests (Client)","text":"<p>The main client class that orchestrates everything:</p> <ul> <li>Backend selection: Auto-detects or uses specified backend</li> <li>Request coordination: Runs parallel requests with concurrency control</li> <li>Configuration: Centralized settings for all requests</li> <li>Context management: Handles session lifecycle</li> <li>Cookie management: Maintains session cookies across requests</li> </ul> <p>Located in: <code>src/fastreq/client.py</code></p>"},{"location":"explanation/architecture/#backends","title":"Backends","text":"<p>HTTP client adapters that provide a normalized interface:</p> <ul> <li>NiquestsBackend: Full async, HTTP/2 support, streaming</li> <li>AiohttpBackend: Mature async library, streaming, no HTTP/2</li> <li>RequestsBackend: Synchronous wrapper, familiar API, no HTTP/2</li> </ul> <p>All backends implement the <code>Backend</code> interface and return <code>NormalizedResponse</code> objects.</p> <p>Located in: <code>src/fastreq/backends/</code></p>"},{"location":"explanation/architecture/#utilities","title":"Utilities","text":"<p>Supporting utilities that handle cross-cutting concerns:</p> <ul> <li>Retry: Exponential backoff with jitter for resilient requests</li> <li>Rate Limiter: Token bucket algorithm for request rate control</li> <li>Proxies: Proxy rotation and validation</li> <li>Headers: Header management and random user agent rotation</li> <li>Logging: Structured logging configuration</li> <li>Validators: Input validation and error handling</li> </ul> <p>Located in: <code>src/fastreq/utils/</code></p>"},{"location":"explanation/architecture/#backend-abstraction-layer","title":"Backend Abstraction Layer","text":"<p>The backend abstraction is crucial for the library's flexibility. Here's how it works:</p>"},{"location":"explanation/architecture/#request-normalization","title":"Request Normalization","text":"<p>All requests go through a <code>RequestConfig</code> dataclass:</p> <pre><code>@dataclass\nclass RequestConfig:\n    url: str\n    method: str = \"GET\"\n    params: dict[str, Any] | None = None\n    data: Any = None\n    json: Any = None\n    headers: dict[str, str] | None = None\n    cookies: dict[str, str] | None = None\n    timeout: float | None = None\n    proxy: str | None = None\n    http2: bool = True\n    stream: bool = False\n    follow_redirects: bool = True\n    verify_ssl: bool = True\n</code></pre> <p>This normalized configuration is passed to each backend, which then translates it to the underlying library's API.</p>"},{"location":"explanation/architecture/#response-normalization","title":"Response Normalization","text":"<p>All backends return a <code>NormalizedResponse</code>:</p> <pre><code>@dataclass\nclass NormalizedResponse:\n    status_code: int\n    headers: dict[str, str]      # All lowercase\n    content: bytes\n    text: str\n    json_data: Any\n    url: str\n    is_json: bool = False\n</code></pre> <p>This provides a consistent interface regardless of which backend you use.</p>"},{"location":"explanation/architecture/#backend-detection-flow","title":"Backend Detection Flow","text":"<pre><code>User creates FastRequests(backend=\"auto\")\n         \u2502\n         \u25bc\nTry importing niquests\n    \u251c\u2500\u2500 Success \u2192 Use NiquestsBackend\n    \u2514\u2500\u2500 ImportError\n         \u2502\n         \u25bc\nTry importing aiohttp\n    \u251c\u2500\u2500 Success \u2192 Use AiohttpBackend\n    \u2514\u2500\u2500 ImportError\n         \u2502\n         \u25bc\nTry importing requests\n    \u251c\u2500\u2500 Success \u2192 Use RequestsBackend\n    \u2514\u2500\u2500 ImportError\n         \u2502\n         \u25bc\nRaise ConfigurationError(\"No suitable backend found\")\n</code></pre>"},{"location":"explanation/architecture/#how-components-interact","title":"How Components Interact","text":""},{"location":"explanation/architecture/#request-lifecycle","title":"Request Lifecycle","text":"<pre><code>1. User calls client.request(urls=[...])\n         \u2502\n2. Create RequestOptions for each URL\n         \u2502\n3. Create async tasks for parallel execution\n         \u2502\n         \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n         \u2502                             \u2502\n4. Acquire rate limit token     \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n         \u2502                    \u2502   Execute         \u2502\n         \u2502                    \u2502   Request        \u2502\n5. Acquire semaphore slot     \u2502                  \u2502\n         \u2502                    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n         \u2502                             \u2502\n6. Backend makes HTTP request      \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n         \u2502                         \u2502   Check Retry    \u2502\n         \u2502                         \u2502   Should we?     \u2502\n7. Get NormalizedResponse        \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n         \u2502                             \u2502\n8. Parse response (JSON/text/content) \u2500\u2500\u25ba Yes \u2192 Wait with backoff \u2192 Retry\n         \u2502                             \u2502        \u2502\n9. Return result                     No       \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"explanation/architecture/#retry-integration","title":"Retry Integration","text":"<p>The retry strategy wraps the entire request execution:</p> <pre><code>response = await self._retry_strategy.execute(make_request)\n</code></pre> <p>If <code>make_request()</code> fails, the retry strategy: 1. Checks if the error is retryable 2. Calculates exponential backoff delay with jitter 3. Waits the calculated time 4. Retries up to <code>max_retries</code></p>"},{"location":"explanation/architecture/#rate-limiting-integration","title":"Rate Limiting Integration","text":"<p>Rate limiting happens just before the actual HTTP request:</p> <pre><code>async with rate_limit_ctx:\n    return await backend.request(config)\n</code></pre> <p>If no tokens are available: 1. Wait until tokens are refilled 2. Acquire a token 3. Proceed with request</p> <p>The semaphore ensures concurrency is never exceeded, regardless of token availability.</p>"},{"location":"explanation/architecture/#design-decisions-and-trade-offs","title":"Design Decisions and Trade-offs","text":""},{"location":"explanation/architecture/#why-strategy-pattern-for-backends","title":"Why Strategy Pattern for Backends?","text":"<p>Benefits: - Easy to add new backends (just implement the interface) - Backend selection is transparent to user code - Backends can be swapped at runtime</p> <p>Trade-offs: - Requires all backends to be async (even requests uses thread wrapper) - Some library-specific features might not be exposed</p>"},{"location":"explanation/architecture/#why-token-bucket-for-rate-limiting","title":"Why Token Bucket for Rate Limiting?","text":"<p>Benefits: - Allows bursts up to <code>burst</code> size - Smoother request pattern than fixed window - Easy to understand and tune</p> <p>Trade-offs: - Requires tracking state (tokens, last refill time) - Not as precise as leaky bucket for short timescales</p>"},{"location":"explanation/architecture/#why-exponential-backoff-with-jitter","title":"Why Exponential Backoff with Jitter?","text":"<p>Benefits: - Prevents thundering herd problem - Reduces load on failing services - Jitter distributes retry attempts</p> <p>Trade-offs: - Increases total latency on failures - Requires tuning for optimal results</p>"},{"location":"explanation/architecture/#why-separate-rate-limiting-and-concurrency-control","title":"Why Separate Rate Limiting and Concurrency Control?","text":"<p>The library uses both a token bucket (rate limiting) and a semaphore (concurrency):</p> <p>Rate Limiting (Token Bucket): - Controls request rate (requests per second) - Allows bursts - Time-based control</p> <p>Concurrency (Semaphore): - Limits simultaneous connections - Prevents resource exhaustion - Count-based control</p> <p>Why both? They solve different problems: - Rate limiting protects remote APIs from overload - Concurrency control protects your application from resource exhaustion</p> <p>For example, with <code>rate_limit=10</code> and <code>concurrency=20</code>: - You'll never exceed 10 requests per second - You can have up to 20 requests waiting (10 active, 10 queued)</p>"},{"location":"explanation/architecture/#performance-characteristics","title":"Performance Characteristics","text":""},{"location":"explanation/architecture/#memory-usage","title":"Memory Usage","text":"<p>Memory scales with: - <code>concurrency</code>: Number of concurrent requests - Response size: Larger responses use more memory - Queue depth: Waiting requests hold their parameters</p>"},{"location":"explanation/architecture/#cpu-usage","title":"CPU Usage","text":"<p>CPU usage is primarily from: - Async event loop management (low overhead) - JSON parsing (scales with response size) - Rate limiting calculations (negligible)</p>"},{"location":"explanation/architecture/#network-usage","title":"Network Usage","text":"<p>Network behavior depends on backend: - niquests: HTTP/2 multiplexing, efficient connection reuse - aiohttp: Connection pooling, HTTP/1.1 pipelining - requests: Standard HTTP/1.1, connection pooling</p>"},{"location":"explanation/architecture/#future-extensibility","title":"Future Extensibility","text":"<p>The architecture supports easy extension:</p>"},{"location":"explanation/architecture/#adding-a-new-backend","title":"Adding a New Backend","text":"<ol> <li>Create a new class inheriting from <code>Backend</code></li> <li>Implement all abstract methods</li> <li>Add to auto-detection list in <code>_select_backend()</code></li> </ol>"},{"location":"explanation/architecture/#adding-a-new-retry-algorithm","title":"Adding a New Retry Algorithm","text":"<ol> <li>Create a new strategy class</li> <li>Implement the same interface as <code>RetryStrategy</code></li> <li>Make it configurable via <code>RetryConfig</code></li> </ol>"},{"location":"explanation/architecture/#adding-a-new-rate-limiting-algorithm","title":"Adding a New Rate Limiting Algorithm","text":"<ol> <li>Create a new limiter class</li> <li>Implement the same async context manager interface</li> <li>Make it configurable via <code>RateLimitConfig</code></li> </ol>"},{"location":"explanation/backends/","title":"Backends","text":"<p>The fastreq library supports four HTTP backends, each with different capabilities and trade-offs.</p>"},{"location":"explanation/backends/#overview","title":"Overview","text":"Backend HTTP/2 Streaming Async Native Notes niquests \u2713 \u2713 \u2713 Recommended default httpx \u2713* \u2713 \u2713 Modern API, httpx ecosystem aiohttp \u2717 \u2713 \u2713 Mature, widely used requests \u2717 \u2713 \u2717 Familiar API, wrapped <p>*HTTP/2 requires httpx[http2] extra (installs h2 package)</p>"},{"location":"explanation/backends/#auto-detection-order","title":"Auto-Detection Order","text":"<p>When <code>backend=\"auto\"</code> (default), the library checks backends in this order:</p> <ol> <li>niquests - HTTP/2 support, streaming, async native</li> <li>httpx - HTTP/2 support (with h2 extra), modern async API</li> <li>aiohttp - Streaming support, async native</li> <li>requests - Streaming via thread wrapper, sync-first</li> </ol> <p>The first available backend is used. This means if you have both niquests and httpx installed, niquests will be selected.</p>"},{"location":"explanation/backends/#niquests-backend","title":"Niquests Backend","text":""},{"location":"explanation/backends/#capabilities","title":"Capabilities","text":"<ul> <li>HTTP/2 Support: Native HTTP/2 with multiplexing</li> <li>Streaming: Full streaming support for large files</li> <li>Async Native: Built on async I/O from the ground up</li> <li>Connection Reuse: Efficient connection pooling</li> </ul>"},{"location":"explanation/backends/#when-to-use","title":"When to Use","text":"<ul> <li>Default choice for most use cases</li> <li>HTTP/2 APIs (e.g., some modern web services)</li> <li>High-throughput scenarios where connection reuse matters</li> <li>Large file downloads with streaming</li> </ul>"},{"location":"explanation/backends/#implementation-details","title":"Implementation Details","text":"<pre><code>class NiquestsBackend(Backend):\n    async def __init__(self, http2_enabled: bool = True):\n        self._session = niquests.AsyncSession(\n            disable_http2=not http2_enabled\n        )\n\n    async def request(self, config: RequestConfig) -&gt; NormalizedResponse:\n        response = await self._session.request(**kwargs)\n        # Handles streaming automatically\n        if config.stream:\n            content = await response.content\n        else:\n            content = response.content\n</code></pre>"},{"location":"explanation/backends/#performance-characteristics","title":"Performance Characteristics","text":"<ul> <li>HTTP/2 Multiplexing: Multiple requests over single connection</li> <li>Low Overhead: Async native, minimal thread usage</li> <li>Efficient Streaming: Memory-efficient for large responses</li> </ul>"},{"location":"explanation/backends/#httpx-backend","title":"Httpx Backend","text":""},{"location":"explanation/backends/#capabilities_1","title":"Capabilities","text":"<ul> <li>HTTP/2 Support: Native HTTP/2 when <code>h2</code> extra is installed</li> <li>Streaming: Full streaming support for large files</li> <li>Async Native: Built on async I/O with httpx.AsyncClient</li> <li>Modern API: Clean, well-designed interface</li> <li>Connection Reuse: Efficient connection pooling</li> </ul>"},{"location":"explanation/backends/#when-to-use_1","title":"When to Use","text":"<ul> <li>Prefer httpx for new projects or if you already use httpx</li> <li>HTTP/2 APIs when you want the httpx ecosystem</li> <li>Modern async applications that value clean APIs</li> <li>Large file downloads with streaming</li> </ul>"},{"location":"explanation/backends/#implementation-details_1","title":"Implementation Details","text":"<pre><code>class HttpxBackend(Backend):\n    async def __init__(self, http2_enabled: bool = True):\n        self._h2_available = self._check_h2_available()\n        http2 = http2_enabled and self._h2_available\n        self._client = httpx.AsyncClient(http2=http2)\n\n    async def request(self, config: RequestConfig) -&gt; NormalizedResponse:\n        if config.stream:\n            async with self._client.stream(**kwargs) as response:\n                content = await response.aread()\n        else:\n            response = await self._client.request(**kwargs)\n            content = response.content\n</code></pre> <p>Note: HTTP/2 requires the <code>h2</code> package (<code>pip install httpx[http2]</code>). Without it, the backend falls back to HTTP/1.1.</p>"},{"location":"explanation/backends/#performance-characteristics_1","title":"Performance Characteristics","text":"<ul> <li>HTTP/2 Multiplexing: When h2 is available</li> <li>Low Overhead: Modern async implementation</li> <li>Efficient Streaming: Memory-efficient for large responses</li> <li>Modern Design: Clean API, well-documented</li> </ul>"},{"location":"explanation/backends/#aiohttp-backend","title":"Aiohttp Backend","text":""},{"location":"explanation/backends/#capabilities_2","title":"Capabilities","text":"<ul> <li>No HTTP/2: Only HTTP/1.1 (unless using external extensions)</li> <li>Streaming: Full streaming support</li> <li>Async Native: Pure async implementation</li> <li>Mature Library: Widely used and battle-tested</li> </ul>"},{"location":"explanation/backends/#when-to-use_2","title":"When to Use","text":"<ul> <li>Already using aiohttp in your project</li> <li>Need aiohttp-specific features not exposed by our abstraction</li> <li>HTTP/1.1 environments (most standard web services)</li> <li>Familiar aiohttp API (though we abstract it)</li> </ul>"},{"location":"explanation/backends/#implementation-details_2","title":"Implementation Details","text":"<pre><code>class AiohttpBackend(Backend):\n    async def __init__(self, http2_enabled: bool = True):\n        self._session = aiohttp.ClientSession()\n        # http2_enabled is ignored, warning is issued\n\n    async def request(self, config: RequestConfig) -&gt; NormalizedResponse:\n        response = await self._session.request(**kwargs)\n        content = await response.read()  # Always read full content\n</code></pre> <p>Note: When <code>http2=True</code> is set with aiohttp, a warning is issued because aiohttp doesn't natively support HTTP/2.</p>"},{"location":"explanation/backends/#performance-characteristics_2","title":"Performance Characteristics","text":"<ul> <li>Connection Pooling: Efficient connection reuse</li> <li>Mature Stability: Years of production use</li> <li>HTTP/1.1 Only: No multiplexing benefits</li> <li>Low Overhead: Async native, minimal thread usage</li> </ul>"},{"location":"explanation/backends/#requests-backend","title":"Requests Backend","text":""},{"location":"explanation/backends/#capabilities_3","title":"Capabilities","text":"<ul> <li>No HTTP/2: Only HTTP/1.1</li> <li>Streaming: Full streaming support (via thread wrapper)</li> <li>Sync-First: Synchronous library wrapped in async</li> <li>Familiar API: Most developers know requests</li> </ul>"},{"location":"explanation/backends/#when-to-use_3","title":"When to Use","text":"<ul> <li>Already using requests and don't want to add dependencies</li> <li>Sync codebases migrating to async gradually</li> <li>Need requests-specific features (session hooks, custom adapters)</li> <li>Simple use cases where HTTP/2 isn't needed</li> </ul>"},{"location":"explanation/backends/#implementation-details_3","title":"Implementation Details","text":"<pre><code>class RequestsBackend(Backend):\n    async def __init__(self, http2_enabled: bool = True):\n        self._session = requests.Session()\n        # http2_enabled is ignored, warning is issued\n\n    async def request(self, config: RequestConfig) -&gt; NormalizedResponse:\n        def _make_request():\n            return self._session.request(**kwargs)\n\n        # Run synchronous request in thread pool\n        response = await asyncio.to_thread(_make_request)\n</code></pre> <p>Thread Wrapper: The synchronous <code>requests.Session.request()</code> is executed in a thread pool using <code>asyncio.to_thread()</code>. This allows it to work in an async context but adds thread overhead.</p>"},{"location":"explanation/backends/#performance-characteristics_3","title":"Performance Characteristics","text":"<ul> <li>Thread Pool Overhead: Each request runs in a thread pool</li> <li>Connection Pooling: Standard requests connection reuse</li> <li>Familiar Stability: Proven in production</li> <li>No HTTP/2 Benefits: Misses multiplexing advantages</li> </ul>"},{"location":"explanation/backends/#feature-comparison-table","title":"Feature Comparison Table","text":"Feature niquests httpx aiohttp requests HTTP/2 \u2713 (native) \u2713 (with h2) \u2717 (extensions only) \u2717 HTTP/1.1 \u2713 \u2713 \u2713 \u2713 Streaming \u2713 \u2713 \u2713 \u2713 (thread wrapper) Async Native \u2713 \u2713 \u2713 \u2717 (thread wrapper) Connection Pooling \u2713 \u2713 \u2713 \u2713 Session Cookies \u2713 \u2713 \u2713 \u2713 Thread Safe \u2713 \u2713 \u2713 \u2713 Maturity Medium High High Very High Installation Size ~2MB ~1MB ~1MB ~0.5MB"},{"location":"explanation/backends/#performance-considerations","title":"Performance Considerations","text":""},{"location":"explanation/backends/#throughput","title":"Throughput","text":"<p>For high-throughput scenarios, performance typically ranks:</p> <ol> <li>niquests (HTTP/2): Fastest due to multiplexing</li> <li>aiohttp: Fast, mature async implementation</li> <li>requests: Slightly slower due to thread overhead</li> </ol>"},{"location":"explanation/backends/#memory-usage","title":"Memory Usage","text":"<p>All backends have similar memory characteristics for the same workload, but:</p> <ul> <li>niquests with HTTP/2: Fewer connections \u2192 less memory for connections</li> <li>requests: Thread pool uses additional memory</li> <li>aiohttp: Standard async memory footprint</li> </ul>"},{"location":"explanation/backends/#latency","title":"Latency","text":"<p>For single-request latency, differences are minimal. For concurrent requests:</p> <ul> <li>HTTP/2 (niquests): Lower latency due to connection reuse</li> <li>HTTP/1.1 (aiohttp/requests): Higher latency under high concurrency</li> </ul>"},{"location":"explanation/backends/#cpu-usage","title":"CPU Usage","text":"<p>CPU usage generally follows async vs sync pattern:</p> <ul> <li>niquests/aiohttp: Lower CPU (async native)</li> <li>requests: Higher CPU (thread pool overhead)</li> </ul>"},{"location":"explanation/backends/#backend-selection-guide","title":"Backend Selection Guide","text":""},{"location":"explanation/backends/#choose-niquests-if","title":"Choose niquests if:","text":"<ul> <li>\u2713 You want HTTP/2 support</li> <li>\u2713 You need maximum performance</li> <li>\u2713 You're starting a new project</li> <li>\u2713 You care about connection efficiency</li> </ul>"},{"location":"explanation/backends/#choose-httpx-if","title":"Choose httpx if:","text":"<ul> <li>\u2713 You prefer httpx's modern API</li> <li>\u2713 You need HTTP/2 with aio-like async interface</li> <li>\u2713 Your project uses httpx</li> <li>\u2713 You value clean, well-documented APIs</li> </ul>"},{"location":"explanation/backends/#choose-aiohttp-if","title":"Choose aiohttp if:","text":"<ul> <li>\u2713 You're already using aiohttp</li> <li>\u2713 You need aiohttp-specific features</li> <li>\u2713 Your project uses aiohttp extensively</li> <li>\u2713 HTTP/1.1 is sufficient</li> </ul>"},{"location":"explanation/backends/#choose-requests-if","title":"Choose requests if:","text":"<ul> <li>\u2713 You're already using requests</li> <li>\u2713 You want to minimize dependencies</li> <li>\u2713 You're migrating a sync codebase</li> <li>\u2713 HTTP/2 isn't needed</li> <li>\u2713 You need requests-specific features (custom adapters, hooks)</li> </ul>"},{"location":"explanation/backends/#example-backend-specific-behavior","title":"Example: Backend-Specific Behavior","text":""},{"location":"explanation/backends/#http2-multiplexing-niquestshttpx-only","title":"HTTP/2 Multiplexing (niquests/httpx only)","text":"<p>With HTTP/2, multiple requests share a single connection:</p> <pre><code># With niquests (HTTP/2 enabled)\nclient = FastRequests(backend=\"niquests\", http2=True)\n# All 100 requests share 1-2 connections due to multiplexing\nresults = await client.request(urls=[url] * 100)\n\n# With httpx (HTTP/2 enabled, requires h2)\nclient = FastRequests(backend=\"httpx\", http2=True)\n# All 100 requests share 1-2 connections due to multiplexing\nresults = await client.request(urls=[url] * 100)\n</code></pre>"},{"location":"explanation/backends/#connection-behavior-http11-backends","title":"Connection Behavior (HTTP/1.1 backends)","text":"<p>With HTTP/1.1, each connection handles one request at a time:</p> <pre><code># With aiohttp or requests (HTTP/1.1 only)\nclient = FastRequests(backend=\"aiohttp\")\n# With concurrency=20, up to 20 connections are used\nresults = await client.request(urls=[url] * 100)\n</code></pre> <p>The <code>concurrency</code> parameter directly limits the number of concurrent connections.</p>"},{"location":"explanation/backends/#installation-and-dependencies","title":"Installation and Dependencies","text":""},{"location":"explanation/backends/#installing-with-specific-backend","title":"Installing with Specific Backend","text":"<pre><code># Install only niquests\npip install fastreq[niquests]\n\n# Install only httpx (HTTP/2 requires httpx[http2])\npip install fastreq[httpx]\n\n# Install only aiohttp\npip install fastreq[aiohttp]\n\n# Install only requests\npip install fastreq[requests]\n\n# Install all backends (recommended)\npip install fastreq[all]\n</code></pre>"},{"location":"explanation/backends/#dependency-sizes","title":"Dependency Sizes","text":"<ul> <li>niquests: ~2MB (includes urllib3 dependencies)</li> <li>httpx: ~1MB (includes httpcore, h2 optional)</li> <li>aiohttp: ~1MB (includes yarl, multidict)</li> <li>requests: ~0.5MB (includes urllib3)</li> </ul>"},{"location":"explanation/backends/#backend-internals","title":"Backend Internals","text":""},{"location":"explanation/backends/#session-management","title":"Session Management","text":"<p>All backends implement async context managers:</p> <pre><code>async with FastRequests(backend=\"niquests\") as client:\n    # Backend session is initialized here\n    results = await client.request(urls=[...])\n    # Backend session is closed here automatically\n</code></pre>"},{"location":"explanation/backends/#error-handling","title":"Error Handling","text":"<p>Each backend catches its library-specific exceptions and wraps them in <code>BackendError</code>:</p> <pre><code># niquests\nexcept niquests.RequestException as e:\n    raise BackendError(f\"Request failed: {e}\", backend_name=self.name)\n\n# httpx\nexcept httpx.HTTPError as e:\n    raise BackendError(f\"Request failed: {e}\", backend_name=self.name)\n\n# aiohttp\nexcept (aiohttp.ClientError, asyncio.TimeoutError) as e:\n    raise BackendError(f\"Request failed: {e}\", backend_name=self.name)\n\n# requests\nexcept requests.RequestException as e:\n    raise BackendError(f\"Request failed: {e}\", backend_name=self.name)\n</code></pre>"},{"location":"explanation/backends/#response-normalization","title":"Response Normalization","text":"<p>All backends return <code>NormalizedResponse</code> with consistent structure:</p> <pre><code># Regardless of backend, you get the same interface\nresponse = await backend.request(config)\nprint(response.status_code)    # HTTP status code\nprint(response.headers)        # Headers (lowercase keys)\nprint(response.content)        # Raw bytes\nprint(response.text)           # Decoded string\nprint(response.json_data)      # Parsed JSON (if applicable)\nprint(response.url)            # Final URL (after redirects)\n</code></pre>"},{"location":"explanation/backends/#troubleshooting","title":"Troubleshooting","text":""},{"location":"explanation/backends/#http2-not-working","title":"HTTP/2 Not Working","text":"<p>Problem: You set <code>http2=True</code> but requests are still HTTP/1.1</p> <p>Solution: Ensure you're using niquests or httpx backend:</p> <pre><code># niquests\nclient = FastRequests(backend=\"niquests\", http2=True)\n\n# httpx (requires httpx[http2] extra)\nclient = FastRequests(backend=\"httpx\", http2=True)\n</code></pre>"},{"location":"explanation/backends/#http2-with-httpx","title":"HTTP/2 with httpx","text":"<p>Problem: You want HTTP/2 with httpx but it's not working</p> <p>Solution: Install the h2 extra:</p> <pre><code>pip install httpx[http2]\n# or\npip install fastreq[httpx]\n</code></pre> <p>The backend will automatically detect if h2 is available and enable HTTP/2.</p>"},{"location":"explanation/backends/#backend-not-found","title":"Backend Not Found","text":"<p>Problem: <code>ConfigurationError: No suitable backend found</code></p> <p>Solution: Install a backend: <pre><code>pip install fastreq[all]  # or specific backend\n</code></pre></p>"},{"location":"explanation/backends/#thread-pool-exhaustion-requests-backend","title":"Thread Pool Exhaustion (requests backend)","text":"<p>Problem: High CPU usage with requests backend</p> <p>Solution: Reduce concurrency or use aiohttp/niquests: <pre><code>client = FastRequests(\n    backend=\"requests\",  # or \"aiohttp\"\n    concurrency=10,      # Lower concurrency for requests\n)\n</code></pre></p>"},{"location":"explanation/backends/#related-documentation","title":"Related Documentation","text":"<ul> <li>Architecture - Design philosophy and component interaction</li> <li>Rate Limiting - How rate limiting works with different backends</li> <li>Retry Strategy - Retry behavior across backends</li> </ul>"},{"location":"explanation/proxy-rotation/","title":"Proxy Rotation","text":"<p>Proxy rotation distributes requests across multiple proxy servers to avoid IP-based rate limits, bypass geographical restrictions, and maintain anonymity.</p>"},{"location":"explanation/proxy-rotation/#why-proxy-rotation","title":"Why Proxy Rotation?","text":""},{"location":"explanation/proxy-rotation/#ip-based-rate-limits","title":"IP-Based Rate Limits","text":"<p>Many services enforce rate limits based on IP address:</p> <pre><code>Without proxy rotation:\nYour IP: 192.168.1.100\n\u251c\u2500 Request 1  \u2192 API (count: 1/100)\n\u251c\u2500 Request 2  \u2192 API (count: 2/100)\n\u251c\u2500 Request 3  \u2192 API (count: 3/100)\n...\n\u2514\u2500 Request 100\u2192 API (count: 100/100)\n                  BLOCKED! \u274c\n\nWith proxy rotation:\nRequest 1  \u2192 Proxy A (192.168.1.10)  \u2192 API (count: 1/100)\nRequest 2  \u2192 Proxy B (192.168.1.11)  \u2192 API (count: 1/100)\nRequest 3  \u2192 Proxy C (192.168.1.12)  \u2192 API (count: 1/100)\nRequest 4  \u2192 Proxy A (192.168.1.10)  \u2192 API (count: 2/100)\nRequest 5  \u2192 Proxy B (192.168.1.11)  \u2192 API (count: 2/100)\n...\nAll requests succeed! \u2713\n</code></pre>"},{"location":"explanation/proxy-rotation/#use-cases","title":"Use Cases","text":"<p>1. Web Scraping - Avoid IP blocks when scraping at scale - Distribute load across multiple IPs - Maintain anonymity</p> <p>2. API Access - Bypass per-IP rate limits - Access geo-restricted APIs - Reduce risk of API key deactivation</p> <p>3. Testing - Simulate requests from different locations - Test geo-specific functionality - Verify load balancing</p> <p>4. Privacy - Hide your real IP address - Prevent tracking - Access region-locked content</p>"},{"location":"explanation/proxy-rotation/#proxy-formats-supported","title":"Proxy Formats Supported","text":"<p>The proxy manager supports multiple proxy formats for flexibility:</p>"},{"location":"explanation/proxy-rotation/#format-1-ipport","title":"Format 1: IP:PORT","text":"<pre><code>\"192.168.1.10:8080\"\n\"203.0.113.5:3128\"\n</code></pre> <p>Pattern: <code>^(\\d{1,3}\\.){3}\\d{1,3}:\\d{1,5}$</code></p>"},{"location":"explanation/proxy-rotation/#format-2-ipportuserpass","title":"Format 2: IP:PORT:USER:PASS","text":"<pre><code>\"192.168.1.10:8080:admin:secret\"\n\"203.0.113.5:3128:user:pass123\"\n</code></pre> <p>Pattern: <code>^(\\d{1,3}\\.){3}\\d{1,3}:\\d{1,5}:[^:]+:[^:]+$</code></p>"},{"location":"explanation/proxy-rotation/#format-3-full-url-with-credentials","title":"Format 3: Full URL with Credentials","text":"<pre><code>\"http://admin:secret@192.168.1.10:8080\"\n\"https://user:pass@proxy.example.com:3128\"\n</code></pre> <p>Patterns: - <code>^http://[^:]+:[^@]+@[^:]+:\\d+$</code> - <code>^https://[^:]+:[^@]+@[^:]+\\d+$</code></p>"},{"location":"explanation/proxy-rotation/#automatic-format-conversion","title":"Automatic Format Conversion","text":"<p>The proxy manager normalizes formats internally:</p> <pre><code># Input in IP:PORT:USER:PASS format\n\"192.168.1.10:8080:admin:secret\"\n\n# Internally converted to URL format\n\"http://admin:secret@192.168.1.10:8080\"\n</code></pre>"},{"location":"explanation/proxy-rotation/#proxy-validation","title":"Proxy Validation","text":"<p>The proxy manager validates proxies to ensure they're properly formatted before use.</p>"},{"location":"explanation/proxy-rotation/#format-validation","title":"Format Validation","text":"<pre><code>@classmethod\ndef validate(cls, proxy: str) -&gt; bool:\n    \"\"\"Validate proxy format.\"\"\"\n    if not proxy or not isinstance(proxy, str):\n        return False\n\n    for pattern in cls.PROXY_PATTERNS:\n        if re.match(pattern, proxy):\n            # For IP-based formats, validate octets\n            if pattern in cls.PROXY_PATTERNS[:2]:\n                ip_part = proxy.split(\":\")[0]\n                if not cls._validate_ip_octets(ip_part):\n                    return False\n            return True\n\n    return False\n</code></pre>"},{"location":"explanation/proxy-rotation/#ip-octet-validation","title":"IP Octet Validation","text":"<p>IP addresses are validated to ensure each octet is in the valid range (0-255):</p> <pre><code>@classmethod\ndef _validate_ip_octets(cls, ip: str) -&gt; bool:\n    \"\"\"Validate IP octets are in range 0-255.\"\"\"\n    octets = ip.split(\".\")\n    if len(octets) != 4:\n        return False\n\n    try:\n        return all(0 &lt;= int(octet) &lt;= 255 for octet in octets)\n    except ValueError:\n        return False\n</code></pre>"},{"location":"explanation/proxy-rotation/#validation-examples","title":"Validation Examples","text":"<pre><code>ProxyManager.validate(\"192.168.1.10:8080\")              # \u2713 Valid\nProxyManager.validate(\"192.168.1.10:8080:admin:pass\")    # \u2713 Valid\nProxyManager.validate(\"http://admin:pass@192.168.1.10:8080\")  # \u2713 Valid\n\nProxyManager.validate(\"256.1.1.1:8080\")                  # \u2717 Invalid octet\nProxyManager.validate(\"192.168.1:8080\")                  # \u2717 Invalid IP format\nProxyManager.validate(\"not-a-proxy\")                     # \u2717 Invalid format\n</code></pre>"},{"location":"explanation/proxy-rotation/#loading-and-filtering","title":"Loading and Filtering","text":"<p>When proxies are loaded, invalid ones are filtered out:</p> <pre><code>def _load_proxies(self) -&gt; None:\n    proxies = []\n\n    # Load from various sources\n    if self._config.list:\n        proxies.extend(self._config.list)\n\n    # Filter invalid proxies\n    self._proxies = []\n    for proxy in proxies:\n        if self.validate(proxy):\n            self._proxies.append(proxy)\n        else:\n            logger.debug(f\"Filtered invalid proxy format: {proxy}\")\n</code></pre>"},{"location":"explanation/proxy-rotation/#failed-proxy-tracking","title":"Failed Proxy Tracking","text":"<p>The proxy manager tracks failed proxies to avoid repeatedly using problematic ones.</p>"},{"location":"explanation/proxy-rotation/#failed-proxy-state","title":"Failed Proxy State","text":"<pre><code>class ProxyManager:\n    def __init__(self, config: ProxyConfig):\n        self._proxies: List[str] = []\n        self._failed_proxies: Dict[str, float] = {}\n        self._lock = asyncio.Lock()\n</code></pre> <ul> <li><code>_proxies</code>: All valid proxies</li> <li><code>_failed_proxies</code>: Failed proxies with retry timestamps</li> <li><code>_lock</code>: Async lock for thread-safe operations</li> </ul>"},{"location":"explanation/proxy-rotation/#marking-failed-proxies","title":"Marking Failed Proxies","text":"<pre><code>async def mark_failed(self, proxy: str) -&gt; None:\n    \"\"\"Mark proxy as failed (unavailable for retry_delay).\"\"\"\n    async with self._lock:\n        if proxy in self._proxies:\n            self._failed_proxies[proxy] = (\n                time.time() + self._config.retry_delay\n            )\n</code></pre> <p>When a proxy fails, it's marked with a timestamp indicating when it should be retried.</p>"},{"location":"explanation/proxy-rotation/#marking-successful-proxies","title":"Marking Successful Proxies","text":"<pre><code>async def mark_success(self, proxy: str) -&gt; None:\n    \"\"\"Mark proxy as successful (clear failed status).\"\"\"\n    async with self._lock:\n        self._failed_proxies.pop(proxy, None)\n</code></pre> <p>If a proxy succeeds again, its failed status is cleared.</p>"},{"location":"explanation/proxy-rotation/#getting-next-proxy","title":"Getting Next Proxy","text":"<pre><code>async def get_next(self) -&gt; Optional[str]:\n    \"\"\"Get next available proxy.\"\"\"\n    async with self._lock:\n        now = time.time()\n\n        # Remove expired failed entries\n        self._failed_proxies = {\n            p: t for p, t in self._failed_proxies.items() if t &gt; now\n        }\n\n        # Get available proxies (not in failed state)\n        available = [\n            p for p in self._proxies\n            if p not in self._failed_proxies\n        ]\n\n        if not available:\n            return None\n\n        return random.choice(available)\n</code></pre>"},{"location":"explanation/proxy-rotation/#failed-proxy-lifecycle","title":"Failed Proxy Lifecycle","text":"<pre><code>Time 0s: Proxy fails \u2192 mark_failed() \u2192 _failed_proxies[proxy] = 60s\nTime 10s: get_next() \u2192 Proxy excluded from selection\nTime 30s: get_next() \u2192 Proxy excluded from selection\nTime 60s: get_next() \u2192 Expired, removed from _failed_proxies\nTime 60s: Proxy available for selection again\n</code></pre>"},{"location":"explanation/proxy-rotation/#retry-delay-configuration","title":"Retry Delay Configuration","text":"<pre><code>@dataclass\nclass ProxyConfig:\n    retry_delay: float = 60.0  # Seconds before retrying failed proxy\n</code></pre> <p>Default retry delay is 60 seconds. Adjust based on your needs:</p> <pre><code># Short retry delay for quick testing\nProxyConfig(retry_delay=10.0)\n\n# Long retry delay for production scraping\nProxyConfig(retry_delay=300.0)  # 5 minutes\n</code></pre>"},{"location":"explanation/proxy-rotation/#webshareio-integration","title":"WebShare.io Integration","text":"<p>The proxy manager integrates with WebShare.io for easy proxy management.</p>"},{"location":"explanation/proxy-rotation/#loading-from-webshare","title":"Loading from WebShare","text":"<pre><code>def _load_webshare_proxies(self, url: str) -&gt; List[str]:\n    \"\"\"Load proxies from WebShare.io URL.\"\"\"\n    import requests\n\n    try:\n        response = requests.get(url, timeout=10)\n        response.raise_for_status()\n\n        proxies = []\n        for line in response.text.strip().split(\"\\n\"):\n            line = line.strip()\n            if not line:\n                continue\n\n            # WebShare format: IP:PORT:USER:PASS\n            parts = line.split(\":\")\n            if len(parts) &gt;= 4:\n                ip, port, user, pw = parts[:4]\n                proxy = f\"http://{user}:{pw}@{ip}:{port}\"\n                proxies.append(proxy)\n\n        return proxies\n\n    except Exception as e:\n        raise ProxyValidationError(\n            f\"Failed to load webshare proxies: {e}\"\n        ) from e\n</code></pre>"},{"location":"explanation/proxy-rotation/#using-webshare-proxies","title":"Using WebShare Proxies","text":"<pre><code>from fastreq.utils.proxies import ProxyManager, ProxyConfig\n\nconfig = ProxyConfig(\n    enabled=True,\n    webshare_url=\"https://your-webshare-proxy-list-url\",\n    retry_delay=60.0,\n)\n\nmanager = ProxyManager(config)\nproxy = await manager.get_next()\n</code></pre>"},{"location":"explanation/proxy-rotation/#environment-variable-loading","title":"Environment Variable Loading","text":"<p>Proxies can also be loaded from the <code>PROXIES</code> environment variable:</p> <pre><code># Set environment variable\nexport PROXIES=\"192.168.1.10:8080,192.168.1.11:8080\"\n\n# Automatically loaded\nmanager = ProxyManager(config)\n</code></pre>"},{"location":"explanation/proxy-rotation/#proxy-manager-internals","title":"Proxy Manager Internals","text":""},{"location":"explanation/proxy-rotation/#thread-safety","title":"Thread Safety","text":"<p>All proxy operations are protected by an async lock:</p> <pre><code>async def get_next(self) -&gt; Optional[str]:\n    async with self._lock:  # Thread-safe\n        # Modify shared state\n</code></pre> <p>This ensures multiple concurrent tasks can safely access the proxy manager.</p>"},{"location":"explanation/proxy-rotation/#proxy-statistics","title":"Proxy Statistics","text":"<p>The proxy manager provides statistics:</p> <pre><code>def count(self) -&gt; int:\n    \"\"\"Get total number of proxies.\"\"\"\n    return len(self._proxies)\n\ndef count_available(self) -&gt; int:\n    \"\"\"Get number of available proxies.\"\"\"\n    now = time.time()\n    return sum(\n        1 for p in self._proxies\n        if p not in self._failed_proxies\n        or self._failed_proxies[p] &lt;= now\n    )\n</code></pre>"},{"location":"explanation/proxy-rotation/#random-selection","title":"Random Selection","text":"<p>Proxies are selected randomly to distribute load:</p> <pre><code>return random.choice(available)\n</code></pre> <p>Random selection helps avoid: - Predictable patterns - Uneven proxy usage - Hotspots on specific proxies</p>"},{"location":"explanation/proxy-rotation/#example-usage","title":"Example Usage","text":""},{"location":"explanation/proxy-rotation/#basic-proxy-rotation","title":"Basic Proxy Rotation","text":"<pre><code>from fastreq import FastRequests\nfrom fastreq.utils.proxies import ProxyManager, ProxyConfig\n\n# Configure proxy rotation\nproxy_config = ProxyConfig(\n    enabled=True,\n    list=[\n        \"192.168.1.10:8080\",\n        \"192.168.1.11:8080:admin:pass\",\n        \"http://user:pass@192.168.1.12:8080\",\n    ],\n    retry_delay=60.0,\n)\n\n# Create client with proxy rotation\nclient = FastRequests(\n    random_proxy=True,  # Enable proxy rotation\n    concurrency=10,\n)\n</code></pre>"},{"location":"explanation/proxy-rotation/#webshare-integration","title":"WebShare Integration","text":"<pre><code>proxy_config = ProxyConfig(\n    enabled=True,\n    webshare_url=\"https://your-api.webshare.io/api/v2/proxy\",\n    retry_delay=120.0,  # 2 minutes\n)\n\nmanager = ProxyManager(proxy_config)\nprint(f\"Loaded {manager.count()} proxies\")\n</code></pre>"},{"location":"explanation/proxy-rotation/#monitoring-proxy-health","title":"Monitoring Proxy Health","text":"<pre><code>manager = ProxyManager(proxy_config)\n\n# Check proxy status\nprint(f\"Total proxies: {manager.count()}\")\nprint(f\"Available proxies: {manager.count_available()}\")\n\n# Get next available proxy\nproxy = await manager.get_next()\nif proxy:\n    print(f\"Using proxy: {proxy}\")\nelse:\n    print(\"No proxies available!\")\n</code></pre>"},{"location":"explanation/proxy-rotation/#best-practices","title":"Best Practices","text":""},{"location":"explanation/proxy-rotation/#1-use-multiple-proxies","title":"1. Use Multiple Proxies","text":"<p>Don't rely on a single proxy:</p> <pre><code># Good: Multiple proxies for rotation\nProxyConfig(list=[\n    \"192.168.1.10:8080\",\n    \"192.168.1.11:8080\",\n    \"192.168.1.12:8080\",\n])\n\n# Bad: Single proxy (no rotation benefit)\nProxyConfig(list=[\"192.168.1.10:8080\"])\n</code></pre>"},{"location":"explanation/proxy-rotation/#2-handle-proxy-exhaustion","title":"2. Handle Proxy Exhaustion","text":"<p>When all proxies fail, the request will fail without a proxy:</p> <pre><code>proxy = await manager.get_next()\nif not proxy:\n    logger.error(\"All proxies failed!\")\n    # Handle gracefully: wait, alert, etc.\n</code></pre>"},{"location":"explanation/proxy-rotation/#3-monitor-failed-proxies","title":"3. Monitor Failed Proxies","text":"<p>Track proxy health and rotation:</p> <pre><code>logger.info(f\"Proxies: {manager.count_available()}/{manager.count()}\")\n\nif manager.count_available() &lt; manager.count() * 0.5:\n    logger.warning(\"More than 50% of proxies failed!\")\n</code></pre>"},{"location":"explanation/proxy-rotation/#4-use-appropriate-retry-delays","title":"4. Use Appropriate Retry Delays","text":"<p>Adjust retry delay based on proxy quality:</p> <pre><code># High-quality proxies: Short retry delay\nProxyConfig(retry_delay=30.0)\n\n# Low-quality proxies: Long retry delay\nProxyConfig(retry_delay=300.0)\n</code></pre>"},{"location":"explanation/proxy-rotation/#5-validate-proxies-before-use","title":"5. Validate Proxies Before Use","text":"<p>The manager validates format, but consider testing connectivity:</p> <pre><code># Format validation is automatic\n# You might want to add connectivity tests\n</code></pre>"},{"location":"explanation/proxy-rotation/#troubleshooting","title":"Troubleshooting","text":""},{"location":"explanation/proxy-rotation/#all-proxies-failing","title":"All Proxies Failing","text":"<p>Problem: <code>count_available()</code> returns 0</p> <p>Possible Causes: 1. All proxies marked as failed 2. Retry delay too long 3. Proxies genuinely offline</p> <p>Solutions: <pre><code># Reduce retry delay\nProxyConfig(retry_delay=30.0)  # Instead of 60.0\n\n# Check proxy connectivity manually\n# Consider using a proxy health check service\n</code></pre></p>"},{"location":"explanation/proxy-rotation/#invalid-proxy-format","title":"Invalid Proxy Format","text":"<p>Problem: Proxies being filtered out</p> <p>Solution: Check format: <pre><code>from fastreq.utils.proxies import ProxyManager\n\nProxyManager.validate(\"192.168.1.10:8080\")  # Should return True\nProxyManager.validate(\"invalid\")             # Should return False\n</code></pre></p>"},{"location":"explanation/proxy-rotation/#proxy-not-working","title":"Proxy Not Working","text":"<p>Problem: Requests still failing with proxy</p> <p>Possible Causes: 1. Proxy is offline 2. Credentials incorrect 3. Proxy blocked by target</p> <p>Solution: Test proxy manually: <pre><code>import requests\n\nproxy = \"http://user:pass@192.168.1.10:8080\"\ntry:\n    response = requests.get(\n        \"https://httpbin.org/ip\",\n        proxies={\"http\": proxy, \"https\": proxy},\n        timeout=10\n    )\n    print(response.json())  # Should show proxy IP\nexcept Exception as e:\n    print(f\"Proxy failed: {e}\")\n</code></pre></p>"},{"location":"explanation/proxy-rotation/#related-documentation","title":"Related Documentation","text":"<ul> <li>How-to: Use Proxies - Practical proxy usage guide</li> <li>Architecture - How proxy rotation integrates with other components</li> </ul>"},{"location":"explanation/rate-limiting/","title":"Rate Limiting","text":"<p>Rate limiting controls the rate at which requests are sent to prevent overwhelming servers or hitting API rate limits. The fastreq library uses the token bucket algorithm for efficient and flexible rate limiting.</p>"},{"location":"explanation/rate-limiting/#token-bucket-algorithm","title":"Token Bucket Algorithm","text":"<p>The token bucket algorithm is a fundamental rate limiting technique that allows for both controlled request rates and burst capability.</p>"},{"location":"explanation/rate-limiting/#how-it-works","title":"How It Works","text":"<p>Imagine a bucket that holds tokens:</p> <pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502      Token Bucket           \u2502\n\u2502                             \u2502\n\u2502  Token Token Token Token    \u2502  \u2190 burst size (max tokens)\n\u2502                             \u2502\n\u2502  Refill: 10 tokens/second   \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n         \u2502\n         \u25bc\n   Make request?\n   Consume 1 token\n</code></pre>"},{"location":"explanation/rate-limiting/#key-concepts","title":"Key Concepts","text":"<p>Bucket Size (Burst): Maximum number of tokens the bucket can hold.</p> <p>Refill Rate: How quickly tokens are added to the bucket (tokens per second).</p> <p>Token Consumption: Each request consumes one token.</p>"},{"location":"explanation/rate-limiting/#algorithm-details","title":"Algorithm Details","text":"<pre><code>class TokenBucket:\n    def __init__(self, requests_per_second: float, burst: int):\n        self.requests_per_second = requests_per_second\n        self.burst = burst\n        self._tokens = float(burst)  # Start full\n        self._last_update = time.monotonic()\n\n    def _refill_tokens(self):\n        now = time.monotonic()\n        elapsed = now - self._last_update\n        # Add tokens based on elapsed time\n        self._tokens = min(\n            self.burst,\n            self._tokens + elapsed * self.requests_per_second\n        )\n        self._last_update = now\n</code></pre>"},{"location":"explanation/rate-limiting/#token-refill","title":"Token Refill","text":"<p>Tokens are refilled based on elapsed time since the last request:</p> <pre><code>If requests_per_second = 10 and burst = 5:\n\nTime 0s:  [\u2588\u2588\u2588\u2588\u2588] 5 tokens (full bucket)\nTime 0.1s:[\u2588\u2588\u2588\u2588\u2592\u2592] 4 tokens (0.1 * 10 = 1 token consumed)\nTime 0.2s:[\u2588\u2588\u2588\u2592\u2592\u2592] 3 tokens\nTime 0.3s:[\u2588\u2588\u2592\u2592\u2592\u2592] 2 tokens\nTime 0.5s:[\u2588\u2592\u2592\u2592\u2592\u2592] 1 token\nTime 0.6s:[\u2592\u2592\u2592\u2592\u2592\u2592] 0 tokens (bucket empty)\nTime 0.7s:[\u2588\u2592\u2592\u2592\u2592\u2592] 1 token (refilled: 0.1 * 10 = 1)\n</code></pre>"},{"location":"explanation/rate-limiting/#acquiring-tokens","title":"Acquiring Tokens","text":"<p>When a request needs to be made:</p> <pre><code>async def acquire(self, tokens: int = 1):\n    while True:\n        self._refill_tokens()\n        if self._tokens &gt;= tokens:\n            self._tokens -= tokens\n            return  # Proceed with request\n\n        # Not enough tokens, wait for refill\n        wait_time = (tokens - self._tokens) / self.requests_per_second\n        await asyncio.sleep(wait_time)\n</code></pre> <p>If tokens are available, they're consumed immediately. Otherwise, the request waits until enough tokens are refilled.</p>"},{"location":"explanation/rate-limiting/#burst-handling","title":"Burst Handling","text":"<p>Burst capability is a key advantage of the token bucket algorithm. It allows temporary spikes in request rate as long as the average rate stays within limits.</p>"},{"location":"explanation/rate-limiting/#burst-example","title":"Burst Example","text":"<p>With <code>rate_limit=10</code> and <code>rate_limit_burst=5</code>:</p> <pre><code>Rate: 10 requests/second\nBurst: 5 tokens\n\nTime 0.00s: Request 1 \u2192 4 tokens left (\u2588\u2588\u2588\u2588)\nTime 0.01s: Request 2 \u2192 3 tokens left (\u2588\u2588\u2588\u2592)\nTime 0.02s: Request 3 \u2192 2 tokens left (\u2588\u2588\u2592\u2592)\nTime 0.03s: Request 4 \u2192 1 token left (\u2588\u2592\u2592\u2592)\nTime 0.04s: Request 5 \u2192 0 tokens left (\u2592\u2592\u2592\u2592)  \u2190 Burst exhausted\n\nTime 0.10s: Request 6 \u2192 0 tokens left (bucket refilled 1 token)\nTime 0.11s: Request 7 \u2192 0 tokens left\nTime 0.20s: Request 8 \u2192 0 tokens left\n</code></pre> <p>After the burst is exhausted, requests are throttled to the refill rate (10 requests/second).</p>"},{"location":"explanation/rate-limiting/#why-burst-matters","title":"Why Burst Matters","text":"<p>Without burst (fixed rate): Maximum 10 requests/second, even if server can handle more With burst: Send 5 requests instantly, then 10 requests/second thereafter</p> <p>Burst is useful for: - Initial data fetching: Get multiple pages quickly - Recovering from downtime: Catch up on queued work - Flexible rate limits: Some APIs allow short bursts</p>"},{"location":"explanation/rate-limiting/#concurrency-control","title":"Concurrency Control","text":"<p>The library uses a semaphore to control the maximum number of concurrent requests, separate from rate limiting.</p>"},{"location":"explanation/rate-limiting/#semaphore-operation","title":"Semaphore Operation","text":"<pre><code>class AsyncRateLimiter:\n    def __init__(self, config: RateLimitConfig):\n        self._bucket = TokenBucket(\n            config.requests_per_second,\n            config.burst\n        )\n        self._semaphore = asyncio.Semaphore(\n            config.max_concurrency\n        )\n\n    async def acquire(self):\n        async with self._semaphore:      # Limit concurrency\n            await self._bucket.acquire()  # Limit rate\n            yield                         # Make request\n</code></pre>"},{"location":"explanation/rate-limiting/#combined-controls","title":"Combined Controls","text":"<p>The rate limiter uses both mechanisms:</p> <pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502              Rate Limiting Controls                   \u2502\n\u2502                                                       \u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510         \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510       \u2502\n\u2502  \u2502  Semaphore   \u2502         \u2502   Token Bucket   \u2502       \u2502\n\u2502  \u2502              \u2502         \u2502                  \u2502       \u2502\n\u2502  \u2502  Max: 20     \u2502\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u25b6\u2502  Rate: 10/s      \u2502       \u2502\n\u2502  \u2502  Concurrent  \u2502         \u2502  Burst: 5        \u2502       \u2502\n\u2502  \u2502  Requests    \u2502         \u2502                  \u2502       \u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518         \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518       \u2502\n\u2502         \u2502                          \u2502                  \u2502\n\u2502         \u25bc                          \u25bc                  \u2502\n\u2502  Limits simultaneous    Controls request rate       \u2502\n\u2502  connections             (with burst capability)    \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"explanation/rate-limiting/#example-rate-limit-vs-concurrency","title":"Example: Rate Limit vs Concurrency","text":"<p>With <code>rate_limit=10</code>, <code>rate_limit_burst=5</code>, <code>concurrency=20</code>:</p> <pre><code>Scenario: Need to make 100 requests\n\nConcurrency limit: 20 simultaneous connections\nRate limit: 10 requests/second average\nBurst: Can send 5 immediately, then 10/second\n\nTimeline:\n0.0s:  5 requests (burst) \u2500\u2500\u2500\u2500\u2510\n0.1s:  5 requests (burst)     \u2502\n0.2s:  5 requests (burst)     \u2502   20 concurrent connections\n0.3s:  5 requests (burst) \u2500\u2500\u2500\u2500\u2518\n0.4s:  10 requests (sustained rate)\n0.5s:  10 requests\n...\n9.5s:  Final request completed\n\nTotal time: ~10 seconds\n</code></pre>"},{"location":"explanation/rate-limiting/#why-token-bucket-vs-other-algorithms","title":"Why Token Bucket vs Other Algorithms?","text":""},{"location":"explanation/rate-limiting/#comparison-with-other-algorithms","title":"Comparison with Other Algorithms","text":"Algorithm Burst Support Complexity Use Case Token Bucket \u2713 Low General purpose, flexible Leaky Bucket \u2717 Medium Network traffic shaping Fixed Window \u2717 Very Low Simple rate limits Sliding Window Limited High Precise rate limiting"},{"location":"explanation/rate-limiting/#advantages-of-token-bucket","title":"Advantages of Token Bucket","text":"<p>1. Burst Capability - Allows temporary spikes - Suitable for real-world usage patterns - More flexible than fixed limits</p> <p>2. Smooth Request Distribution - Unlike leaky bucket (which regulates outflow) - Token bucket regulates requests directly</p> <p>3. Simplicity - Easy to understand and implement - Minimal state tracking (tokens, last refill time) - Low computational overhead</p> <p>4. Predictable Behavior - Maximum burst size is known - Average rate is guaranteed - Easy to tune for specific requirements</p>"},{"location":"explanation/rate-limiting/#when-token-bucket-is-not-ideal","title":"When Token Bucket Is Not Ideal","text":"<ul> <li>Precise per-second limits: Sliding window is more accurate</li> <li>Network traffic shaping: Leaky bucket is designed for this</li> <li>Distributed systems: Requires distributed coordination</li> </ul>"},{"location":"explanation/rate-limiting/#rate-limiting-use-cases","title":"Rate Limiting Use Cases","text":""},{"location":"explanation/rate-limiting/#api-rate-limits","title":"API Rate Limits","text":"<p>Many APIs enforce rate limits (e.g., GitHub: 5000 requests/hour):</p> <pre><code># GitHub API: 5,000 requests/hour \u2248 1.4 requests/second\nclient = FastRequests(\n    rate_limit=1.4,\n    rate_limit_burst=5,  # Allow bursts\n    concurrency=10,\n)\n</code></pre>"},{"location":"explanation/rate-limiting/#preventing-server-overload","title":"Preventing Server Overload","text":"<p>Protect your own servers from excessive requests:</p> <pre><code># Self-imposed limit: 100 requests/second\nclient = FastRequests(\n    rate_limit=100,\n    rate_limit_burst=20,\n    concurrency=50,\n)\n</code></pre>"},{"location":"explanation/rate-limiting/#avoiding-ip-blocking","title":"Avoiding IP Blocking","text":"<p>When scraping, stay under radar:</p> <pre><code># Conservative scraping: 1 request/second\nclient = FastRequests(\n    rate_limit=1,\n    rate_limit_burst=3,  # Small burst\n    concurrency=5,\n)\n</code></pre>"},{"location":"explanation/rate-limiting/#cost-management","title":"Cost Management","text":"<p>Some APIs charge per request:</p> <pre><code># Stay within budget: 10,000 requests/day \u2248 0.12 requests/second\nclient = FastRequests(\n    rate_limit=0.12,\n    rate_limit_burst=10,\n)\n</code></pre>"},{"location":"explanation/rate-limiting/#practical-examples","title":"Practical Examples","text":""},{"location":"explanation/rate-limiting/#example-1-basic-rate-limiting","title":"Example 1: Basic Rate Limiting","text":"<pre><code>from fastreq import fastreq\n\n# Limit to 5 requests/second, burst of 2\nresults = fastreq(\n    urls=[url] * 50,\n    rate_limit=5,\n    rate_limit_burst=2,\n    concurrency=10,\n)\n</code></pre> <p>Behavior: - First 2 requests execute immediately (burst) - Remaining requests at ~5/second - Up to 10 concurrent connections</p>"},{"location":"explanation/rate-limiting/#example-2-high-burst-scenario","title":"Example 2: High-Burst Scenario","text":"<pre><code># Large burst for initial fetch\nresults = fastreq(\n    urls=[url] * 100,\n    rate_limit=10,\n    rate_limit_burst=50,  # Can send 50 immediately\n    concurrency=50,\n)\n</code></pre> <p>Behavior: - First 50 requests execute immediately - Remaining 50 at ~10/second - All 100 complete in ~10 seconds</p>"},{"location":"explanation/rate-limiting/#example-3-tight-rate-limiting","title":"Example 3: Tight Rate Limiting","text":"<pre><code># Strict API limit: 1 request/second\nresults = fastreq(\n    urls=[url] * 10,\n    rate_limit=1,\n    rate_limit_burst=1,  # No real burst\n    concurrency=3,\n)\n</code></pre> <p>Behavior: - 1 request per second - Up to 3 requests queued/concurrent - All 10 complete in ~10 seconds</p>"},{"location":"explanation/rate-limiting/#performance-considerations","title":"Performance Considerations","text":""},{"location":"explanation/rate-limiting/#overhead","title":"Overhead","text":"<p>Rate limiting adds minimal overhead:</p> <pre><code># Token bucket operations\n_refill_tokens(): O(1)  # Simple arithmetic\navailable(): O(1)      # Simple arithmetic\nacquire(): O(1)        # May wait, but constant time check\n</code></pre>"},{"location":"explanation/rate-limiting/#wait-time-calculation","title":"Wait Time Calculation","text":"<p>When tokens are insufficient, wait time is calculated:</p> <pre><code>wait_time = (tokens_needed - tokens_available) / refill_rate\n</code></pre> <p>For example, with 0 tokens and 10 tokens/second: - Need 1 token: wait 0.1 seconds - Need 5 tokens: wait 0.5 seconds</p>"},{"location":"explanation/rate-limiting/#memory-usage","title":"Memory Usage","text":"<p>Rate limiting state is minimal: - <code>_tokens</code>: One float - <code>_last_update</code>: One float (timestamp) - Per limiter: ~16 bytes</p>"},{"location":"explanation/rate-limiting/#troubleshooting","title":"Troubleshooting","text":""},{"location":"explanation/rate-limiting/#requests-slower-than-expected","title":"Requests Slower Than Expected","text":"<p>Problem: Requests taking longer than <code>rate_limit</code> suggests</p> <p>Possible Causes: 1. Network latency: Rate limiting doesn't account for network time 2. Backend limitations: Some backends have inherent overhead 3. Server processing time: Server may take time to process requests</p> <p>Solution: Measure actual throughput and adjust accordingly.</p>"},{"location":"explanation/rate-limiting/#burst-not-working","title":"Burst Not Working","text":"<p>Problem: Requests not being sent in bursts</p> <p>Cause: <code>rate_limit_burst</code> too low or already exhausted</p> <p>Solution: Increase <code>rate_limit_burst</code> or wait for refill: <pre><code>client = FastRequests(\n    rate_limit=10,\n    rate_limit_burst=20,  # Larger burst\n)\n</code></pre></p>"},{"location":"explanation/rate-limiting/#concurrency-exceeded","title":"Concurrency Exceeded","text":"<p>Problem: More concurrent requests than <code>concurrency</code> setting</p> <p>Cause: Rate limiting and concurrency are separate controls</p> <p>Solution: Remember that both limits apply: - <code>concurrency</code>: Max simultaneous connections - <code>rate_limit</code>: Max requests per second</p>"},{"location":"explanation/rate-limiting/#related-documentation","title":"Related Documentation","text":"<ul> <li>Architecture - How rate limiting integrates with other components</li> <li>Retry Strategy - How retries interact with rate limiting</li> <li>How-to: Limit Request Rate - Practical usage guide</li> </ul>"},{"location":"explanation/retry-strategy/","title":"Retry Strategy","text":"<p>Retry strategies determine how the library handles failed requests. The fastreq library implements exponential backoff with jitter to balance resilience with efficiency.</p>"},{"location":"explanation/retry-strategy/#exponential-backoff-algorithm","title":"Exponential Backoff Algorithm","text":"<p>Exponential backoff is a standard technique for handling transient failures by increasing the wait time between retries.</p>"},{"location":"explanation/retry-strategy/#the-algorithm","title":"The Algorithm","text":"<p>The retry strategy calculates delay using this formula:</p> <pre><code>delay = backoff_multiplier \u00d7 (2^attempt) \u00b1 jitter\n</code></pre> <p>Where: - <code>attempt</code>: Retry attempt number (0-indexed) - <code>backoff_multiplier</code>: Base delay in seconds (default: 1.0) - <code>jitter</code>: Random variation as fraction of base delay (default: 10%)</p>"},{"location":"explanation/retry-strategy/#delay-calculation","title":"Delay Calculation","text":"<pre><code>def _calculate_delay(self, attempt: int) -&gt; float:\n    base_delay = self.config.backoff_multiplier * (2 ** attempt)\n    jitter_amount = self.config.jitter * base_delay\n    jittered_delay = base_delay + random.uniform(-jitter_amount, jitter_amount)\n    return float(max(0, jittered_delay))\n</code></pre>"},{"location":"explanation/retry-strategy/#example-calculations","title":"Example Calculations","text":"<p>With <code>backoff_multiplier=1.0</code> and <code>jitter=0.1</code> (10%):</p> Attempt Base Delay Jitter Range Possible Delay 0 1.0s \u00b10.10s 0.90s - 1.10s 1 2.0s \u00b10.20s 1.80s - 2.20s 2 4.0s \u00b10.40s 3.60s - 4.40s 3 8.0s \u00b10.80s 7.20s - 8.80s"},{"location":"explanation/retry-strategy/#why-exponential-backoff","title":"Why Exponential Backoff?","text":""},{"location":"explanation/retry-strategy/#benefits","title":"Benefits","text":"<p>1. Reduces Server Load - Failed requests are retried with increasing delays - Gives failing service time to recover - Prevents immediate retry storms</p> <p>2. Transient Failure Handling - Network glitches often resolve quickly - Temporary overload clears with time - Database locks release</p> <p>3. Resource Efficiency - Fewer retries on persistent failures - Faster failure detection - Better use of limited resources</p>"},{"location":"explanation/retry-strategy/#alternative-strategies","title":"Alternative Strategies","text":"Strategy Advantages Disadvantages Exponential Backoff Balances speed and load Can be slow for many retries Linear Backoff Predictable delay Doesn't adapt quickly Fixed Delay Simple Inefficient for many failures No Backoff Fastest Overwhelms failing services"},{"location":"explanation/retry-strategy/#comparison-example","title":"Comparison Example","text":"<p>Request that fails 3 times:</p> <p>Fixed 1-second delay: <pre><code>Attempt 0: Fail \u2192 Wait 1s \u2192 Retry\nAttempt 1: Fail \u2192 Wait 1s \u2192 Retry\nAttempt 2: Fail \u2192 Wait 1s \u2192 Retry\nTotal wait: 3 seconds\n</code></pre></p> <p>Exponential backoff (1x, 10% jitter): <pre><code>Attempt 0: Fail \u2192 Wait ~1s \u2192 Retry\nAttempt 1: Fail \u2192 Wait ~2s \u2192 Retry\nAttempt 2: Fail \u2192 Wait ~4s \u2192 Retry\nTotal wait: ~7 seconds\n</code></pre></p> <p>Exponential backoff waits longer but is much gentler on failing services.</p>"},{"location":"explanation/retry-strategy/#jitter-random-variation","title":"Jitter (Random Variation)","text":"<p>Jitter adds randomness to retry delays to prevent synchronization issues.</p>"},{"location":"explanation/retry-strategy/#why-jitter-is-needed","title":"Why Jitter Is Needed","text":"<p>Without jitter, multiple clients might retry at the same time:</p> <pre><code>Without Jitter:\nClient A: [Retry]\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2192[Retry]\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2192[Retry]\nClient B: [Retry]\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2192[Retry]\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2192[Retry]\nClient C: [Retry]\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2192[Retry]\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2192[Retry]\n           \u2191 All retry at same time\n\nWith Jitter:\nClient A: [Retry]\u2500\u2500\u2500\u2500\u2500\u2500\u2192[Retry]\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2192[Retry]\nClient B: [Retry]\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2192[Retry]\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2192[Retry]\nClient C: [Retry]\u2500\u2500\u2500\u2500\u2500\u2192[Retry]\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2192[Retry]\n           \u2191 Distributed over time\n</code></pre>"},{"location":"explanation/retry-strategy/#jitter-formula","title":"Jitter Formula","text":"<pre><code>jitter_amount = base_delay * jitter_fraction\nrandom_delay = base_delay + random.uniform(-jitter_amount, +jitter_amount)\n</code></pre> <p>With <code>jitter=0.1</code> (10%), delays vary by \u00b110% around the base.</p>"},{"location":"explanation/retry-strategy/#thundering-herd-problem","title":"Thundering Herd Problem","text":"<p>The thundering herd occurs when many clients retry a failing service simultaneously:</p> <pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502              Failing Service                    \u2502\n\u2502                                                \u2502\n\u2502  Time 0s:  [\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588] 100 requests        \u2502\n\u2502           Service crashes!                      \u2502\n\u2502                                                \u2502\n\u2502  Time 1s:  [\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588] 100 clients retry   \u2502\n\u2502           Service still overwhelmed            \u2502\n\u2502                                                \u2502\n\u2502  Time 2s:  [\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588] 100 clients retry   \u2502\n\u2502           Service never recovers               \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre> <p>With jitter, retries are distributed:</p> <pre><code>Time 1s:  [\u2588\u2588] 10 clients retry\nTime 1.1s:[\u2588\u2588] 10 clients retry\nTime 1.2s:[\u2588\u2588] 10 clients retry\n...\nTime 2s:  [\u2588\u2588] Remaining clients retry\n\nService has time to recover between retry waves\n</code></pre>"},{"location":"explanation/retry-strategy/#retry-logic-flow","title":"Retry Logic Flow","text":""},{"location":"explanation/retry-strategy/#decision-process","title":"Decision Process","text":"<pre><code>Request Failed\n      \u2502\n      \u25bc\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502  Should retry?              \u2502\n\u2502  - Check dont_retry_on      \u2502\n\u2502  - Check retry_on           \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n      \u2502\n      \u251c\u2500\u2500\u25ba No \u2192 Raise error\n      \u2502\n      \u25bc\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502  Attempts &lt; max_retries?    \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n      \u2502\n      \u251c\u2500\u2500\u25ba No \u2192 Raise RetryExhaustedError\n      \u2502\n      \u25bc\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502  Calculate delay             \u2502\n\u2502  - Exponential backoff      \u2502\n\u2502  - Add jitter                \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n      \u2502\n      \u25bc\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502  Wait for delay              \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n      \u2502\n      \u25bc\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502  Retry request               \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"explanation/retry-strategy/#selective-retry-logic","title":"Selective Retry Logic","text":"<p>The library supports selective retrying:</p> <pre><code>@dataclass\nclass RetryConfig:\n    max_retries: int = 3\n    backoff_multiplier: float = 1.0\n    jitter: float = 0.1\n    retry_on: set[type[Exception]] | None = None\n    dont_retry_on: set[type[Exception]] | None = None\n</code></pre> <p>Retry on specific errors: <pre><code>config = RetryConfig(\n    retry_on={TimeoutError, ConnectionError},\n    # Only retry timeout and connection errors\n)\n</code></pre></p> <p>Don't retry specific errors: <pre><code>config = RetryConfig(\n    dont_retry_on={AuthenticationError, PermissionError},\n    # Don't retry auth/permission errors\n)\n</code></pre></p>"},{"location":"explanation/retry-strategy/#retry-decision-logic","title":"Retry Decision Logic","text":"<pre><code>def _should_retry(self, error: Exception) -&gt; bool:\n    # Never retry if error is in dont_retry_on\n    if self.config.dont_retry_on and isinstance(\n        error, tuple(self.config.dont_retry_on)\n    ):\n        return False\n\n    # Only retry if error is in retry_on (if specified)\n    if self.config.retry_on:\n        return isinstance(error, tuple(self.config.retry_on))\n\n    # Default: retry all errors\n    return True\n</code></pre>"},{"location":"explanation/retry-strategy/#configuration-examples","title":"Configuration Examples","text":""},{"location":"explanation/retry-strategy/#default-configuration","title":"Default Configuration","text":"<pre><code># Default: 3 retries, 1s base delay, 10% jitter\nclient = FastRequests(max_retries=3)\n</code></pre> <p>Retry delays (with 10% jitter): - Attempt 0: ~1s wait - Attempt 1: ~2s wait - Attempt 2: ~4s wait - After 3 failures: raise error</p>"},{"location":"explanation/retry-strategy/#aggressive-retries","title":"Aggressive Retries","text":"<pre><code># More retries, faster initial delay\nclient = FastRequests(\n    max_retries=5,\n    # Default backoff_multiplier=1.0\n)\n</code></pre> <p>Retry delays: - Attempt 0: ~1s - Attempt 1: ~2s - Attempt 2: ~4s - Attempt 3: ~8s - Attempt 4: ~16s</p>"},{"location":"explanation/retry-strategy/#conservative-retries","title":"Conservative Retries","text":"<pre><code># Fewer retries, slower backoff, more jitter\nclient = FastRequests(\n    max_retries=2,\n    backoff_multiplier=2.0,  # Slower backoff\n)\n</code></pre> <p>Note: Jitter is not configurable in current API (fixed at 10%).</p> <p>Retry delays (with 10% jitter): - Attempt 0: ~2s - Attempt 1: ~4s</p>"},{"location":"explanation/retry-strategy/#no-jitter-not-recommended","title":"No Jitter (Not Recommended)","text":"<p>Jitter is currently fixed at 10% in the implementation. If you need to disable jitter, you would need to modify the <code>RetryStrategy</code> class:</p> <pre><code># In RetryStrategy._calculate_delay():\n# Original:\njittered_delay = base_delay + random.uniform(-jitter_amount, jitter_amount)\n\n# Without jitter:\njittered_delay = base_delay\n</code></pre> <p>Warning: Disabling jitter can cause thundering herd problems.</p>"},{"location":"explanation/retry-strategy/#integration-with-other-features","title":"Integration with Other Features","text":""},{"location":"explanation/retry-strategy/#retry-and-rate-limiting","title":"Retry and Rate Limiting","text":"<p>Retries respect rate limiting:</p> <pre><code>client = FastRequests(\n    max_retries=3,\n    rate_limit=10,\n    rate_limit_burst=5,\n)\n</code></pre> <p>Flow: 1. Request fails 2. Calculate retry delay (e.g., 1s) 3. Wait 1s 4. Acquire rate limit token 5. Retry request</p>"},{"location":"explanation/retry-strategy/#retry-and-concurrency","title":"Retry and Concurrency","text":"<p>Retries don't increase concurrency:</p> <pre><code>client = FastRequests(\n    max_retries=3,\n    concurrency=10,\n)\n</code></pre> <p>If request fails, retry doesn't use additional concurrency slot. The original slot is held during retry.</p>"},{"location":"explanation/retry-strategy/#retry-and-timeouts","title":"Retry and Timeouts","text":"<p>Retries are separate from timeouts:</p> <pre><code>client = FastRequests(\n    max_retries=3,\n    timeout=5,  # Per-request timeout\n)\n</code></pre> <ul> <li>Each retry attempt has a 5-second timeout</li> <li>Total max time: 3 retries \u00d7 (5s timeout + backoff delay)</li> </ul>"},{"location":"explanation/retry-strategy/#best-practices","title":"Best Practices","text":""},{"location":"explanation/retry-strategy/#choosing-retry-settings","title":"Choosing Retry Settings","text":"<p>For API calls: <pre><code># API calls: moderate retries\nFastRequests(\n    max_retries=3,\n    backoff_multiplier=1.0,\n)\n</code></pre></p> <p>For long-running downloads: <pre><code># Downloads: fewer retries, longer timeout\nFastRequests(\n    max_retries=2,\n    backoff_multiplier=2.0,\n    timeout=30,\n)\n</code></pre></p> <p>For unreliable networks: <pre><code># Unstable network: more retries\nFastRequests(\n    max_retries=5,\n    backoff_multiplier=1.0,\n)\n</code></pre></p>"},{"location":"explanation/retry-strategy/#handling-specific-errors","title":"Handling Specific Errors","text":"<p>Never retry authorization errors: <pre><code># Auth errors won't be fixed by retrying\n# The library handles common non-retryable errors automatically\n</code></pre></p> <p>Always retry timeout errors: <pre><code># Timeouts are often transient\n# Retried by default unless configured otherwise\n</code></pre></p>"},{"location":"explanation/retry-strategy/#monitoring-retries","title":"Monitoring Retries","text":"<p>Enable debug logging to see retry behavior:</p> <pre><code>client = FastRequests(\n    max_retries=3,\n    debug=True,\n)\n</code></pre> <p>Output: <pre><code>Retry attempt 1/3, waiting 1.05s\nRetry attempt 2/3, waiting 2.12s\nRetry attempt 3/3, waiting 4.08s\n</code></pre></p>"},{"location":"explanation/retry-strategy/#performance-considerations","title":"Performance Considerations","text":""},{"location":"explanation/retry-strategy/#total-wait-time","title":"Total Wait Time","text":"<p>With <code>max_retries=3</code> and <code>backoff_multiplier=1.0</code>:</p> <pre><code>Maximum total wait time on failure:\n= 1s + 2s + 4s = 7 seconds\n</code></pre> <p>With <code>max_retries=5</code>: <pre><code>Maximum total wait time:\n= 1s + 2s + 4s + 8s + 16s = 31 seconds\n</code></pre></p>"},{"location":"explanation/retry-strategy/#resource-usage","title":"Resource Usage","text":"<p>Retries hold resources during backoff:</p> <ul> <li>Semaphore slot: Held during retry wait</li> <li>Memory: Retry state is minimal (~32 bytes)</li> <li>CPU: Minimal during sleep</li> </ul>"},{"location":"explanation/retry-strategy/#timeout-vs-retry-timeout","title":"Timeout vs Retry Timeout","text":"<pre><code>Per-request timeout: How long to wait for response\nRetry delay: How long to wait between retries\n\nExample with timeout=5, max_retries=3:\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2510 5s   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2510 1s   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2510 2s   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2510 4s\n\u2502 Req  \u2502\u2500\u2500\u2500\u2500\u2500\u2500\u25b6\u2502Wait  \u2502\u2500\u2500\u2500\u2500\u2500\u2500\u25b6\u2502Retry \u2502\u2500\u2500\u2500\u2500\u2500\u2500\u25b6\u2502Wait  \u2502\u2500\u2500\u2500\u2500\u2500\u25b6...\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2518       \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2518       \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2518       \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n\nMax time per URL: 3 \u00d7 (5s timeout + avg 2.33s delay) = ~22s\n</code></pre>"},{"location":"explanation/retry-strategy/#troubleshooting","title":"Troubleshooting","text":""},{"location":"explanation/retry-strategy/#too-many-retries","title":"Too Many Retries","text":"<p>Problem: Application hanging due to excessive retries</p> <p>Solution: Reduce <code>max_retries</code>: <pre><code>FastRequests(max_retries=1)  # Only retry once\n</code></pre></p>"},{"location":"explanation/retry-strategy/#retries-too-slow","title":"Retries Too Slow","text":"<p>Problem: Recoverable errors taking too long to retry</p> <p>Solution: Reduce <code>backoff_multiplier</code> (not currently configurable via main API): <pre><code># Would require custom RetryConfig\n# Or accept current default of 1.0\n</code></pre></p>"},{"location":"explanation/retry-strategy/#retries-not-working","title":"Retries Not Working","text":"<p>Problem: Errors not being retried</p> <p>Cause: Error might be non-retryable (e.g., authentication)</p> <p>Solution: Check error type or configure <code>retry_on</code>: <pre><code># Current API doesn't expose retry_on configuration\n# Future enhancement may allow this\n</code></pre></p>"},{"location":"explanation/retry-strategy/#related-documentation","title":"Related Documentation","text":"<ul> <li>Architecture - How retry integrates with other components</li> <li>Rate Limiting - How retries interact with rate limiting</li> <li>How-to: Handle Retries - Practical usage guide</li> </ul>"},{"location":"how-to-guides/","title":"How-to Guides","text":"<p>This section contains practical guides for solving common tasks with fastreq. Each guide provides step-by-step instructions and code examples to help you implement specific features.</p>"},{"location":"how-to-guides/#available-guides","title":"Available Guides","text":""},{"location":"how-to-guides/#request-basics","title":"Request Basics","text":"<ul> <li>Make Parallel Requests - Create parallel requests with various configurations</li> <li>Post JSON Data - Handle POST, PUT, and PATCH requests</li> </ul>"},{"location":"how-to-guides/#configuration","title":"Configuration","text":"<ul> <li>Limit Request Rate - Implement rate limiting with token bucket algorithm</li> <li>Handle Retries - Configure retry logic with exponential backoff</li> <li>Select Backend - Choose between niquests, aiohttp, and requests</li> </ul>"},{"location":"how-to-guides/#advanced-features","title":"Advanced Features","text":"<ul> <li>Use Proxies - Configure proxy rotation and proxy providers</li> <li>Stream Large Files - Download large files with streaming</li> <li>Handle Cookies - Manage session cookies and authentication</li> </ul>"},{"location":"how-to-guides/#troubleshooting","title":"Troubleshooting","text":"<ul> <li>Debug Issues - Troubleshoot common problems and enable debug logging</li> </ul>"},{"location":"how-to-guides/#getting-help","title":"Getting Help","text":"<ul> <li>Tutorials - Start here for step-by-step learning</li> <li>API Reference - Complete API documentation</li> <li>GitHub Issues - Report bugs or request features</li> </ul>"},{"location":"how-to-guides/debug-issues/","title":"Debug Issues","text":"<p>Learn how to troubleshoot common problems and enable debug logging.</p>"},{"location":"how-to-guides/debug-issues/#enabling-debug-logging","title":"Enabling Debug Logging","text":"<p>Use <code>debug=True</code> to enable verbose logging:</p> <pre><code>from fastreq import fastreq\n\nresults = fastreq(\n    urls=[\"https://httpbin.org/get\"] * 5,\n    debug=True,  # Enable debug logging\n)\n</code></pre> <p>Debug output includes: - Backend selection - Request start/stop times - Retry attempts - Rate limiting info - Proxy usage - Error details</p>"},{"location":"how-to-guides/debug-issues/#disabling-progress-bars","title":"Disabling Progress Bars","text":"<p>Use <code>verbose=False</code> to disable progress bars:</p> <pre><code>from fastreq import fastreq\n\nresults = fastreq(\n    urls=[\"https://httpbin.org/get\"] * 100,\n    verbose=False,  # Quiet mode, no progress bar\n)\n</code></pre>"},{"location":"how-to-guides/debug-issues/#checking-backend-availability","title":"Checking Backend Availability","text":"<p>Verify which backends are installed:</p> <pre><code>from fastreq.backends import get_available_backends\n\navailable = get_available_backends()\nprint(f\"Available backends: {available}\")\n\n# Expected output: ['niquests', 'aiohttp', 'requests']\n</code></pre>"},{"location":"how-to-guides/debug-issues/#testing-backend-connectivity","title":"Testing Backend Connectivity","text":"<p>Test if a backend works:</p> <pre><code>from fastreq import fastreq\n\ndef test_backend(backend_name):\n    try:\n        results = fastreq(\n            urls=[\"https://httpbin.org/get\"],\n            backend=backend_name,\n            timeout=5,\n            debug=True,\n        )\n        print(f\"{backend_name}: OK\")\n        return True\n    except Exception as e:\n        print(f\"{backend_name}: FAILED - {e}\")\n        return False\n\nfor backend in [\"niquests\", \"aiohttp\", \"requests\"]:\n    test_backend(backend)\n</code></pre>"},{"location":"how-to-guides/debug-issues/#debugging-rate-limiting","title":"Debugging Rate Limiting","text":"<p>See rate limiting behavior:</p> <pre><code>from fastreq import fastreq\n\nresults = fastreq(\n    urls=[\"https://api.example.com/data\"] * 20,\n    rate_limit=5,\n    rate_limit_burst=10,\n    debug=True,  # Shows rate limiting logs\n)\n</code></pre> <p>Example output: <pre><code>[DEBUG] Rate limit: 5.0 req/s, burst: 10\n[DEBUG] Request 1: immediate (bucket: 9/10)\n[DEBUG] Request 2: immediate (bucket: 8/10)\n...\n[DEBUG] Request 11: waiting 0.2s for token\n</code></pre></p>"},{"location":"how-to-guides/debug-issues/#debugging-retry-attempts","title":"Debugging Retry Attempts","text":"<p>Monitor retry behavior:</p> <pre><code>from fastreq import fastreq\n\nresults = fastreq(\n    urls=[\"https://api.example.com/unstable\"],\n    max_retries=3,\n    debug=True,\n)\n</code></pre> <p>Example output: <pre><code>[DEBUG] Request 1: failed with 500, retry 1/3\n[DEBUG] Request 1: failed with 500, retry 2/3\n[DEBUG] Request 1: failed with 500, retry 3/3\n[DEBUG] Request 1: exhausted retries\n</code></pre></p>"},{"location":"how-to-guides/debug-issues/#debugging-proxy-issues","title":"Debugging Proxy Issues","text":"<p>See which proxy is being used:</p> <pre><code>from fastreq import fastreq\n\nresults = fastreq(\n    urls=[\"https://httpbin.org/ip\"] * 5,\n    proxies=[\n        \"http://proxy1:8080\",\n        \"http://proxy2:8080\",\n    ],\n    debug=True,\n)\n</code></pre>"},{"location":"how-to-guides/debug-issues/#common-issues-and-solutions","title":"Common Issues and Solutions","text":""},{"location":"how-to-guides/debug-issues/#issue-backend-not-available","title":"Issue: Backend Not Available","text":"<p>Error: <code>BackendError: No suitable backend found</code></p> <p>Solution: Install backend dependencies:</p> <pre><code>pip install fastreq[all]\n</code></pre> <p>Or install specific backend:</p> <pre><code>pip install fastreq[niquests]\npip install fastreq[aiohttp]\npip install fastreq[requests]\n</code></pre>"},{"location":"how-to-guides/debug-issues/#issue-requests-timing-out","title":"Issue: Requests Timing Out","text":"<p>Error: <code>TimeoutError</code> or <code>ReadTimeout</code></p> <p>Solution: Increase timeout or check network:</p> <pre><code>from fastreq import fastreq\n\n# Increase timeout\nresults = fastreq(\n    urls=[\"https://httpbin.org/delay/10\"],\n    timeout=15,  # Increase from default\n)\n\n# Test network connectivity\nimport requests\nrequests.get(\"https://httpbin.org/get\", timeout=5)\n</code></pre>"},{"location":"how-to-guides/debug-issues/#issue-rate-limit-exceeded","title":"Issue: Rate Limit Exceeded","text":"<p>Error: <code>RateLimitExceededError</code> or HTTP 429</p> <p>Solution: Adjust rate limiting:</p> <pre><code>from fastreq import fastreq\n\n# Lower rate limit\nresults = fastreq(\n    urls=[\"https://api.example.com/data\"] * 100,\n    rate_limit=5,           # Reduce from 10\n    rate_limit_burst=5,      # Reduce from 10\n    dont_retry_on=[429],     # Don't retry rate limit\n)\n</code></pre>"},{"location":"how-to-guides/debug-issues/#issue-proxy-connection-failed","title":"Issue: Proxy Connection Failed","text":"<p>Error: <code>ProxyError</code> or <code>ConnectionError</code></p> <p>Solution: Test proxy configuration:</p> <pre><code>import requests\n\n# Test proxy manually\ntry:\n    response = requests.get(\n        \"https://httpbin.org/ip\",\n        proxies={\"http\": \"http://proxy1:8080\"},\n        timeout=10,\n    )\n    print(f\"Proxy working: {response.json()['origin']}\")\nexcept Exception as e:\n    print(f\"Proxy failed: {e}\")\n</code></pre>"},{"location":"how-to-guides/debug-issues/#issue-http2-not-working","title":"Issue: HTTP/2 Not Working","text":"<p>Error: HTTP/2 not available</p> <p>Solution: Ensure niquests is installed:</p> <pre><code># Install niquests\npip install fastreq[niquests]\n\n# Verify\npython -c \"import niquests; print('niquests installed')\"\n</code></pre> <pre><code>from fastreq import fastreq\n\n# Force niquests backend\nresults = fastreq(\n    urls=[\"https://httpbin.org/get\"],\n    backend=\"niquests\",\n    debug=True,\n)\n</code></pre>"},{"location":"how-to-guides/debug-issues/#issue-ssl-certificate-errors","title":"Issue: SSL Certificate Errors","text":"<p>Error: <code>SSLError</code> or certificate validation failed</p> <p>Solution: Verify SSL certificates or disable (not recommended for production):</p> <pre><code>from fastreq import fastreq\n\n# Note: Disabling SSL verification is not recommended for production\n# This is for debugging only\nimport ssl\nimport urllib3\nurllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)\n</code></pre>"},{"location":"how-to-guides/debug-issues/#issue-partial-failures","title":"Issue: Partial Failures","text":"<p>Error: <code>PartialFailureError</code></p> <p>Solution: Handle partial failures gracefully:</p> <pre><code>from fastreq import fastreq, PartialFailureError\n\nurls = [\n    \"https://api.github.com/repos/python/cpython\",\n    \"https://invalid-url.com\",\n    \"https://api.github.com/repos/python/pypy\",\n]\n\ntry:\n    results = fastreq(urls=urls)\nexcept PartialFailureError as e:\n    print(f\"Partial failure: {e.successes}/{e.total}\")\n    print(f\"Failed URLs: {e.get_failed_urls()}\")\n\n    # Optionally retry failed URLs\n    failed_urls = list(e.get_failed_urls())\n    if failed_urls:\n        print(f\"Retrying {len(failed_urls)} failed URLs...\")\n        results = fastreq(urls=failed_urls)\n</code></pre>"},{"location":"how-to-guides/debug-issues/#issue-high-memory-usage","title":"Issue: High Memory Usage","text":"<p>Error: Out of memory or slow performance</p> <p>Solution: Use streaming for large files:</p> <pre><code>from fastreq import fastreq\n\n# Use streaming instead of loading entire response\ndef stream_handler(response, url):\n    with open(f\"output_{url.split('/')[-1]}\", \"wb\") as f:\n        for chunk in response.iter_content(chunk_size=8192):\n            if chunk:\n                f.write(chunk)\n\nresults = fastreq(\n    urls=[\"https://example.com/large-file.zip\"],\n    return_type=\"stream\",\n    stream_callback=stream_handler,\n)\n</code></pre>"},{"location":"how-to-guides/debug-issues/#debugging-with-context-manager","title":"Debugging with Context Manager","text":"<p>Use context manager for better debugging:</p> <pre><code>import asyncio\nfrom fastreq import FastRequests\n\nasync def debug_with_context():\n    async with FastRequests(debug=True) as client:\n        # First batch\n        results1 = await client.request(\n            urls=[\"https://api.github.com/repos/python/cpython\"],\n        )\n\n        # Second batch (reuses session)\n        results2 = await client.request(\n            urls=[\"https://api.github.com/repos/python/pypy\"],\n        )\n\n        return results1, results2\n\nresults1, results2 = asyncio.run(debug_with_context())\n</code></pre>"},{"location":"how-to-guides/debug-issues/#logging-configuration","title":"Logging Configuration","text":"<p>Use Python logging for custom logging:</p> <pre><code>import logging\nfrom fastreq import fastreq\n\n# Configure logging\nlogging.basicConfig(\n    level=logging.DEBUG,\n    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'\n)\n\n# Make requests\nresults = fastreq(\n    urls=[\"https://httpbin.org/get\"] * 5,\n    debug=True,\n)\n</code></pre>"},{"location":"how-to-guides/debug-issues/#debug-checklist","title":"Debug Checklist","text":"<p>Use this checklist when debugging:</p> <ol> <li> <p>Backend Available? <pre><code>from fastreq.backends import get_available_backends\nprint(get_available_backends())\n</code></pre></p> </li> <li> <p>Network Working? <pre><code>import requests\nrequests.get(\"https://httpbin.org/get\", timeout=5)\n</code></pre></p> </li> <li> <p>URLs Valid? <pre><code>from urllib.parse import urlparse\nfor url in urls:\n    parsed = urlparse(url)\n    print(f\"{url}: {parsed.scheme}, {parsed.netloc}\")\n</code></pre></p> </li> <li> <p>Proxy Working? <pre><code>import requests\nrequests.get(\"https://httpbin.org/ip\", proxies={\"http\": \"http://proxy:8080\"})\n</code></pre></p> </li> <li> <p>Rate Limits Correct? <pre><code># Check API documentation for rate limits\n# Use rate_limit below documented limit\n</code></pre></p> </li> </ol>"},{"location":"how-to-guides/debug-issues/#best-practices","title":"Best Practices","text":"<ol> <li> <p>Enable Debug Logging Early: Turn on debug when troubleshooting    <pre><code>debug=True\n</code></pre></p> </li> <li> <p>Test Simple Cases First: Start with a single URL    <pre><code>fastreq(urls=[\"https://httpbin.org/get\"])\n</code></pre></p> </li> <li> <p>Check Dependencies: Verify all backends are installed    <pre><code>pip install fastreq[all]\n</code></pre></p> </li> <li> <p>Monitor Memory: Use streaming for large responses    <pre><code>return_type=\"stream\"\n</code></pre></p> </li> <li> <p>Handle Errors Gracefully: Use try-except blocks    <pre><code>except Exception as e:\n    print(f\"Error: {e}\")\n</code></pre></p> </li> </ol>"},{"location":"how-to-guides/debug-issues/#see-also","title":"See Also","text":"<ul> <li>Handling Errors - Complete error handling guide</li> <li>Handle Retries - Configure retry logic</li> <li>API Reference - Configuration options</li> </ul>"},{"location":"how-to-guides/handle-cookies/","title":"Handle Cookies","text":"<p>Learn how to manage session cookies and authentication.</p>"},{"location":"how-to-guides/handle-cookies/#setting-initial-cookies","title":"Setting Initial Cookies","text":"<p>Use the <code>cookies</code> parameter to send cookies with requests:</p> <pre><code>from fastreq import fastreq\n\n# Send cookies with request\nresults = fastreq(\n    urls=[\"https://httpbin.org/cookies\"],\n    cookies={\n        \"session_id\": \"abc123\",\n        \"user_token\": \"xyz789\",\n    },\n)\n\nfor result in results:\n    print(f\"Cookies: {result['cookies']}\")\n</code></pre>"},{"location":"how-to-guides/handle-cookies/#session-cookies-with-context-manager","title":"Session Cookies with Context Manager","text":"<p>Use a context manager to maintain cookies across multiple request batches:</p> <pre><code>import asyncio\nfrom fastreq import FastRequests\n\nasync def session_example():\n    async with FastRequests() as client:\n        # First request - receives session cookie\n        results1 = await client.request(\n            urls=[\"https://httpbin.org/cookies/set/session/abc123\"],\n            return_type=\"response\",\n        )\n\n        # Second request - cookie is sent automatically\n        results2 = await client.request(\n            urls=[\"https://httpbin.org/cookies\"],\n        )\n\n        # Third request - cookie persists\n        results3 = await client.request(\n            urls=[\"https://httpbin.org/cookies\"],\n        )\n\n        return results2, results3\n\nresults2, results3 = asyncio.run(session_example())\nprint(f\"Session maintained: {results2}\")\n</code></pre>"},{"location":"how-to-guides/handle-cookies/#adding-cookies-with-set_cookies","title":"Adding Cookies with <code>set_cookies()</code>","text":"<p>Add cookies to an existing session:</p> <pre><code>import asyncio\nfrom fastreq import FastRequests\n\nasync def add_cookies_example():\n    async with FastRequests() as client:\n        # Add cookies to session\n        client.set_cookies({\n            \"auth_token\": \"secret_token_123\",\n            \"user_id\": \"456\",\n        })\n\n        # Request includes cookies\n        results = await client.request(\n            urls=[\"https://httpbin.org/cookies\"],\n        )\n\n        return results\n\nresults = asyncio.run(add_cookies_example())\nprint(f\"Cookies sent: {results[0]}\")\n</code></pre>"},{"location":"how-to-guides/handle-cookies/#clearing-cookies-with-reset_cookies","title":"Clearing Cookies with <code>reset_cookies()</code>","text":"<p>Clear all cookies from the session:</p> <pre><code>import asyncio\nfrom fastreq import FastRequests\n\nasync def clear_cookies_example():\n    async with FastRequests() as client:\n        # Set cookies\n        client.set_cookies({\"session\": \"abc123\"})\n\n        # First request - has cookies\n        results1 = await client.request(\n            urls=[\"https://httpbin.org/cookies\"],\n        )\n\n        # Clear cookies\n        client.reset_cookies()\n\n        # Second request - no cookies\n        results2 = await client.request(\n            urls=[\"https://httpbin.org/cookies\"],\n        )\n\n        return results1, results2\n\nresults1, results2 = asyncio.run(clear_cookies_example())\nprint(f\"Before reset: {results1[0]}\")\nprint(f\"After reset: {results2[0]}\")\n</code></pre>"},{"location":"how-to-guides/handle-cookies/#authentication-with-session-cookies","title":"Authentication with Session Cookies","text":"<p>Authenticate and maintain session across requests:</p> <pre><code>import asyncio\nfrom fastreq import FastRequests\n\nasync def authenticated_session():\n    async with FastRequests() as client:\n        # Login request - receives session cookie\n        login_response = await client.request(\n            urls=[\"https://httpbin.org/cookies/set/session/logged_in\"],\n            return_type=\"response\",\n        )\n\n        # Subsequent authenticated requests\n        profile = await client.request(\n            urls=[\"https://httpbin.org/cookies\"],\n        )\n\n        # Another authenticated request\n        dashboard = await client.request(\n            urls=[\"https://httpbin.org/cookies\"],\n        )\n\n        return profile, dashboard\n\nprofile, dashboard = asyncio.run(authenticated_session())\nprint(f\"Authenticated session: {profile[0]}\")\n</code></pre>"},{"location":"how-to-guides/handle-cookies/#real-world-example-api-authentication","title":"Real-World Example: API Authentication","text":"<p>Authenticate with an API and maintain session:</p> <pre><code>import asyncio\nfrom fastreq import FastRequests\n\nasync def api_session():\n    async with FastRequests() as client:\n        # Login endpoint\n        login_data = await client.request(\n            urls=[\"https://api.example.com/login\"],\n            method=\"POST\",\n            json={\"username\": \"user\", \"password\": \"pass\"},\n            headers={\"Content-Type\": \"application/json\"},\n        )\n\n        # Authenticated requests\n        profile = await client.request(\n            urls=[\"https://api.example.com/profile\"],\n        )\n\n        # More authenticated requests\n        posts = await client.request(\n            urls=[\"https://api.example.com/posts\"],\n        )\n\n        return profile, posts\n\nprofile, posts = asyncio.run(api_session())\n</code></pre>"},{"location":"how-to-guides/handle-cookies/#cookie-persistence-across-multiple-batches","title":"Cookie Persistence Across Multiple Batches","text":"<p>Use context manager to persist cookies:</p> <pre><code>import asyncio\nfrom fastreq import FastRequests\n\nasync def persistent_session():\n    async with FastRequests() as client:\n        # Batch 1\n        batch1 = await client.request(\n            urls=[\n                \"https://httpbin.org/cookies/set/session/abc123\",\n                \"https://httpbin.org/cookies/set/token/xyz789\",\n            ],\n        )\n\n        # Batch 2 - cookies are sent automatically\n        batch2 = await client.request(\n            urls=[\n                \"https://httpbin.org/cookies\",\n                \"https://httpbin.org/cookies\",\n            ],\n        )\n\n        # Batch 3 - cookies still persist\n        batch3 = await client.request(\n            urls=[\n                \"https://httpbin.org/cookies\",\n            ],\n        )\n\n        return batch1, batch2, batch3\n\nresults = asyncio.run(persistent_session())\n</code></pre>"},{"location":"how-to-guides/handle-cookies/#different-cookies-for-different-requests","title":"Different Cookies for Different Requests","text":"<p>Set cookies per request:</p> <pre><code>import asyncio\nfrom fastreq import FastRequests\n\nasync def different_cookies():\n    async with FastRequests() as client:\n        # First request with specific cookies\n        results1 = await client.request(\n            urls=[\"https://httpbin.org/cookies\"],\n            cookies={\"request_id\": \"123\"},\n        )\n\n        # Second request with different cookies\n        results2 = await client.request(\n            urls=[\"https://httpbin.org/cookies\"],\n            cookies={\"request_id\": \"456\"},\n        )\n\n        return results1, results2\n\nresults1, results2 = asyncio.run(different_cookies())\nprint(f\"Request 1: {results1[0]}\")\nprint(f\"Request 2: {results2[0]}\")\n</code></pre>"},{"location":"how-to-guides/handle-cookies/#updating-cookies-incrementally","title":"Updating Cookies Incrementally","text":"<p>Add more cookies to existing session:</p> <pre><code>import asyncio\nfrom fastreq import FastRequests\n\nasync def update_cookies():\n    async with FastRequests() as client:\n        # Initial cookies\n        client.set_cookies({\"session\": \"abc123\"})\n\n        # Add more cookies\n        client.set_cookies({\"user_id\": \"456\"})\n\n        # Both cookies are sent\n        results = await client.request(\n            urls=[\"https://httpbin.org/cookies\"],\n        )\n\n        return results\n\nresults = asyncio.run(update_cookies())\nprint(f\"All cookies: {results[0]}\")\n</code></pre>"},{"location":"how-to-guides/handle-cookies/#cookie-expiration-and-handling","title":"Cookie Expiration and Handling","text":"<p>Check cookie status:</p> <pre><code>import asyncio\nfrom fastreq import FastRequests\n\nasync def cookie_status():\n    async with FastRequests() as client:\n        # Set cookies\n        client.set_cookies({\"session\": \"abc123\"})\n\n        # Make request\n        results = await client.request(\n            urls=[\"https://httpbin.org/cookies\"],\n        )\n\n        # Check response cookies\n        for result in results:\n            if \"cookies\" in result:\n                print(f\"Cookies received: {result['cookies']}\")\n\n        return results\n\nresults = asyncio.run(cookie_status())\n</code></pre>"},{"location":"how-to-guides/handle-cookies/#handling-cookie-errors","title":"Handling Cookie Errors","text":"<p>Handle cookie-related errors:</p> <pre><code>from fastreq import fastreq\n\ntry:\n    results = fastreq(\n        urls=[\"https://httpbin.org/cookies\"],\n        cookies={\n            \"invalid_cookie\": \"value\",\n        },\n    )\nexcept Exception as e:\n    print(f\"Cookie error: {e}\")\n</code></pre>"},{"location":"how-to-guides/handle-cookies/#combining-cookies-with-headers","title":"Combining Cookies with Headers","text":"<p>Send both cookies and headers:</p> <pre><code>from fastreq import fastreq\n\nresults = fastreq(\n    urls=[\"https://httpbin.org/cookies\"],\n    cookies={\"session\": \"abc123\"},\n    headers={\n        \"User-Agent\": \"MyApp/1.0\",\n        \"Accept\": \"application/json\",\n    },\n)\n</code></pre>"},{"location":"how-to-guides/handle-cookies/#debugging-cookie-issues","title":"Debugging Cookie Issues","text":"<p>Enable debug logging to see cookie handling:</p> <pre><code>from fastreq import fastreq\n\nresults = fastreq(\n    urls=[\"https://httpbin.org/cookies/set/session/test\"],\n    debug=True,\n)\n\nresults = fastreq(\n    urls=[\"https://httpbin.org/cookies\"],\n    debug=True,\n)\n</code></pre>"},{"location":"how-to-guides/handle-cookies/#best-practices","title":"Best Practices","text":"<ol> <li> <p>Use Context Manager: Maintain cookies across requests    <pre><code>async with FastRequests() as client:\n    await client.request(urls=urls)\n</code></pre></p> </li> <li> <p>Set Cookies Before Requests: Call <code>set_cookies()</code> first    <pre><code>client.set_cookies({\"session\": \"abc\"})\nresults = await client.request(urls=urls)\n</code></pre></p> </li> <li> <p>Clear Sensitive Cookies: Use <code>reset_cookies()</code> when done    <pre><code>client.reset_cookies()\n</code></pre></p> </li> <li> <p>Test Cookie Behavior: Verify cookies are sent/received    <pre><code>results = await client.request(urls=[\"https://httpbin.org/cookies\"])\n</code></pre></p> </li> <li> <p>Handle Cookie Expiration: Check response for new cookies    <pre><code>if 'set-cookie' in response.headers:\n    # Update session cookies\n</code></pre></p> </li> </ol>"},{"location":"how-to-guides/handle-cookies/#see-also","title":"See Also","text":"<ul> <li>Make Parallel Requests - Request configuration</li> <li>Post JSON Data - Authentication examples</li> <li>API Reference - Client documentation</li> </ul>"},{"location":"how-to-guides/handle-retries/","title":"Handle Retries","text":"<p>Learn how to configure automatic retries with exponential backoff and selective retry logic.</p>"},{"location":"how-to-guides/handle-retries/#basic-retry-configuration","title":"Basic Retry Configuration","text":"<p>Use <code>max_retries</code> to automatically retry failed requests:</p> <pre><code>from fastreq import fastreq\n\n# Retry up to 3 times (default)\nresults = fastreq(\n    urls=[\"https://api.example.com/unstable\"],\n    max_retries=3,\n)\n\n# Disable retries\nresults = fastreq(\n    urls=[\"https://api.example.com/unstable\"],\n    max_retries=0,\n)\n\n# Increase retries for unreliable services\nresults = fastreq(\n    urls=[\"https://api.example.com/unstable\"],\n    max_retries=5,\n)\n</code></pre>"},{"location":"how-to-guides/handle-retries/#exponential-backoff-with-jitter","title":"Exponential Backoff with Jitter","text":"<p>The library uses exponential backoff with random jitter:</p> <pre><code>from fastreq import fastreq\n\n# Retry behavior with max_retries=3\n# Attempt 0: immediate\n# Attempt 1: wait ~1s (1.0 * 2^1 + jitter)\n# Attempt 2: wait ~2s (1.0 * 2^2 + jitter)\n# Attempt 3: wait ~4s (1.0 * 2^3 + jitter)\n# Failed after 4 total attempts\n\nresults = fastreq(\n    urls=[\"https://api.example.com/unstable\"],\n    max_retries=3,\n)\n</code></pre> <p>Why Jitter? Random variation prevents \"thundering herd\" problems where all retries happen simultaneously.</p>"},{"location":"how-to-guides/handle-retries/#selective-retry-with-retry_on","title":"Selective Retry with <code>retry_on</code>","text":"<p>Only retry on specific HTTP status codes:</p> <pre><code>from fastreq import fastreq\n\n# Retry only on 5xx server errors\nresults = fastreq(\n    urls=[\"https://api.example.com/endpoint\"],\n    max_retries=3,\n    retry_on=[500, 502, 503, 504],  # Server errors\n)\n\n# Retry on connection errors and server errors\nresults = fastreq(\n    urls=[\"https://api.example.com/endpoint\"],\n    max_retries=3,\n    retry_on=[500, 502, 503, 504, \"timeout\", \"connection\"],\n)\n</code></pre>"},{"location":"how-to-guides/handle-retries/#dont-retry-with-dont_retry_on","title":"Don't Retry with <code>dont_retry_on</code>","text":"<p>Never retry on specific status codes:</p> <pre><code>from fastreq import fastreq\n\n# Don't retry on 4xx client errors\nresults = fastreq(\n    urls=[\"https://api.example.com/endpoint\"],\n    max_retries=3,\n    dont_retry_on=[400, 401, 403, 404, 429],  # Client errors\n)\n</code></pre>"},{"location":"how-to-guides/handle-retries/#example-retry-only-on-server-errors","title":"Example: Retry Only on Server Errors","text":"<pre><code>from fastreq import fastreq\n\n# Retry only when server is having issues\nresults = fastreq(\n    urls=[\n        \"https://api.example.com/endpoint1\",\n        \"https://api.example.com/endpoint2\",\n    ],\n    max_retries=3,\n    retry_on=[500, 502, 503, 504],  # Only server errors\n)\n\n# 4xx errors fail immediately without retry\n</code></pre>"},{"location":"how-to-guides/handle-retries/#example-dont-retry-on-validation-errors","title":"Example: Don't Retry on Validation Errors","text":"<pre><code>from fastreq import fastreq\n\n# Don't retry on validation errors (4xx)\nresults = fastreq(\n    urls=[\"https://api.example.com/users\"],\n    method=\"POST\",\n    json={\"name\": \"John\"},\n    max_retries=3,\n    dont_retry_on=[400, 401, 403, 404],  # Client errors\n)\n\n# Invalid data returns 400 and fails immediately\n</code></pre>"},{"location":"how-to-guides/handle-retries/#combining-retry_on-and-dont_retry_on","title":"Combining <code>retry_on</code> and <code>dont_retry_on</code>","text":"<p>Both parameters can be used together:</p> <pre><code>from fastreq import fastreq\n\nresults = fastreq(\n    urls=[\"https://api.example.com/endpoint\"],\n    max_retries=3,\n    retry_on=[500, 502, 503, 504],           # Retry server errors\n    dont_retry_on=[429],                      # Don't retry rate limit\n)\n</code></pre>"},{"location":"how-to-guides/handle-retries/#handling-retry-exhaustion","title":"Handling Retry Exhaustion","text":"<p>Catch <code>RetryExhaustedError</code> when all retries fail:</p> <pre><code>from fastreq import fastreq, RetryExhaustedError\n\ntry:\n    results = fastreq(\n        urls=[\"https://api.example.com/unreliable\"],\n        max_retries=3,\n    )\nexcept RetryExhaustedError as e:\n    print(f\"Retries exhausted after {e.attempts} attempts\")\n    print(f\"Last error: {e.last_error}\")\n</code></pre>"},{"location":"how-to-guides/handle-retries/#retry-with-custom-error-handling","title":"Retry with Custom Error Handling","text":"<pre><code>from fastreq import fastreq, RetryExhaustedError\n\ndef fetch_with_fallback(urls):\n    try:\n        return fastreq(\n            urls=urls,\n            max_retries=3,\n            retry_on=[500, 502, 503, 504],\n        )\n    except RetryExhaustedError as e:\n        print(f\"Retries failed: {e.last_error}\")\n        # Fallback: try again with different parameters\n        return fastreq(\n            urls=urls,\n            max_retries=1,\n            timeout=30,  # Longer timeout\n        )\n\nresults = fetch_with_fallback(\n    urls=[\"https://api.example.com/endpoint\"],\n)\n</code></pre>"},{"location":"how-to-guides/handle-retries/#retry-and-partial-failures","title":"Retry and Partial Failures","text":"<p>Handle retries with partial failures:</p> <pre><code>from fastreq import fastreq, PartialFailureError, RetryExhaustedError\n\nurls = [\n    \"https://api.example.com/endpoint1\",\n    \"https://api.example.com/endpoint2\",\n    \"https://api.example.com/endpoint3\",\n]\n\ntry:\n    results = fastreq(\n        urls=urls,\n        max_retries=3,\n    )\nexcept PartialFailureError as e:\n    print(f\"Partial failure: {e.successes}/{e.total}\")\n    # Some succeeded, some failed even after retries\n</code></pre>"},{"location":"how-to-guides/handle-retries/#retry-configuration-by-backend","title":"Retry Configuration by Backend","text":"<p>Different backends handle retries differently:</p> <pre><code>from fastreq import fastreq\n\n# niquests: HTTP/2 retries, connection pooling\nresults = fastreq(\n    urls=[\"https://api.example.com/endpoint\"],\n    max_retries=3,\n    backend=\"niquests\",\n)\n\n# aiohttp: Async retries\nresults = fastreq(\n    urls=[\"https://api.example.com/endpoint\"],\n    max_retries=3,\n    backend=\"aiohttp\",\n)\n\n# requests: Sync retries via threading\nresults = fastreq(\n    urls=[\"https://api.example.com/endpoint\"],\n    max_retries=3,\n    backend=\"requests\",\n)\n</code></pre>"},{"location":"how-to-guides/handle-retries/#monitoring-retry-behavior","title":"Monitoring Retry Behavior","text":"<p>Enable debug logging to see retry attempts:</p> <pre><code>from fastreq import fastreq\n\nresults = fastreq(\n    urls=[\"https://api.example.com/unstable\"],\n    max_retries=3,\n    debug=True,\n)\n</code></pre> <p>Example output: <pre><code>[DEBUG] Request 1: failed with 500, retry 1/3\n[DEBUG] Request 1: failed with 500, retry 2/3\n[DEBUG] Request 1: failed with 500, retry 3/3\n[DEBUG] Request 1: exhausted retries\n</code></pre></p>"},{"location":"how-to-guides/handle-retries/#retry-patterns","title":"Retry Patterns","text":""},{"location":"how-to-guides/handle-retries/#pattern-1-conservative-retry","title":"Pattern 1: Conservative Retry","text":"<p>For rate-limited APIs:</p> <pre><code>results = fastreq(\n    urls=[\"https://api.example.com/data\"],\n    max_retries=2,\n    dont_retry_on=[429],  # Don't retry rate limit\n)\n</code></pre>"},{"location":"how-to-guides/handle-retries/#pattern-2-aggressive-retry","title":"Pattern 2: Aggressive Retry","text":"<p>For critical operations:</p> <pre><code>results = fastreq(\n    urls=[\"https://api.example.com/payment\"],\n    max_retries=5,\n    retry_on=[500, 502, 503, 504],\n    dont_retry_on=[400, 401],  # Don't retry client errors\n)\n</code></pre>"},{"location":"how-to-guides/handle-retries/#pattern-3-timeout-retry","title":"Pattern 3: Timeout Retry","text":"<p>Retry only on timeouts:</p> <pre><code>results = fastreq(\n    urls=[\"https://api.example.com/slow\"],\n    max_retries=3,\n    retry_on=[\"timeout\"],\n    dont_retry_on=[400, 401, 403, 404, 429, 500],\n)\n</code></pre>"},{"location":"how-to-guides/handle-retries/#combining-retries-with-other-features","title":"Combining Retries with Other Features","text":""},{"location":"how-to-guides/handle-retries/#retries-rate-limiting","title":"Retries + Rate Limiting","text":"<pre><code>results = fastreq(\n    urls=[\"https://api.example.com/data\"] * 50,\n    max_retries=3,\n    rate_limit=10,  # 10 req/s\n    dont_retry_on=[429],  # Don't retry rate limit\n)\n</code></pre>"},{"location":"how-to-guides/handle-retries/#retries-proxies","title":"Retries + Proxies","text":"<pre><code>results = fastreq(\n    urls=[\"https://api.example.com/data\"] * 20,\n    max_retries=2,\n    proxies=[\"http://proxy1:8080\", \"http://proxy2:8080\"],\n    retry_on=[500, 502, 503, 504],\n)\n</code></pre>"},{"location":"how-to-guides/handle-retries/#retries-timeout","title":"Retries + Timeout","text":"<pre><code>results = fastreq(\n    urls=[\"https://api.example.com/slow\"],\n    max_retries=3,\n    timeout=5,\n    retry_on=[\"timeout\"],\n)\n</code></pre>"},{"location":"how-to-guides/handle-retries/#best-practices","title":"Best Practices","text":"<ol> <li> <p>Set Appropriate Retry Limits: Don't retry indefinitely    <pre><code>max_retries=3  # Good default\n</code></pre></p> </li> <li> <p>Don't Retry Client Errors: 4xx errors indicate client issues    <pre><code>dont_retry_on=[400, 401, 403, 404]\n</code></pre></p> </li> <li> <p>Use Selective Retries: Retry only on recoverable errors    <pre><code>retry_on=[500, 502, 503, 504]\n</code></pre></p> </li> <li> <p>Handle Rate Limits: Don't retry on 429    <pre><code>dont_retry_on=[429]\n</code></pre></p> </li> <li> <p>Monitor Retry Exhaustion: Catch and log retry failures    <pre><code>except RetryExhaustedError as e:\n    logger.error(f\"Retries failed: {e.last_error}\")\n</code></pre></p> </li> </ol>"},{"location":"how-to-guides/handle-retries/#see-also","title":"See Also","text":"<ul> <li>Limit Request Rate - Control request frequency</li> <li>Debug Issues - Enable debug logging</li> <li>Handling Errors - Complete error handling guide</li> <li>API Reference - Configuration options</li> </ul>"},{"location":"how-to-guides/limit-request-rate/","title":"Limit Request Rate","text":"<p>Learn how to control request rate to avoid API quotas and be a good citizen.</p>"},{"location":"how-to-guides/limit-request-rate/#token-bucket-algorithm","title":"Token Bucket Algorithm","text":"<p>The library uses a token bucket algorithm for rate limiting:</p> <ul> <li>Tokens: A bucket fills with tokens at a constant rate (<code>rate_limit</code>)</li> <li>Requests: Each request consumes one token from the bucket</li> <li>Burst: The bucket can hold a maximum of <code>rate_limit_burst</code> tokens</li> <li>Wait: If bucket is empty, requests wait until tokens are available</li> </ul> <p>This allows for smooth rate limiting while accommodating short bursts of traffic.</p>"},{"location":"how-to-guides/limit-request-rate/#basic-rate-limiting","title":"Basic Rate Limiting","text":"<p>Set <code>rate_limit</code> to control requests per second:</p> <pre><code>from fastreq import fastreq\n\n# Limit to 10 requests per second\nresults = fastreq(\n    urls=[\"https://api.example.com/endpoint\"] * 50,\n    rate_limit=10,  # 10 requests/second\n)\n</code></pre>"},{"location":"how-to-guides/limit-request-rate/#configuring-burst-capacity","title":"Configuring Burst Capacity","text":"<p>Use <code>rate_limit_burst</code> to allow temporary spikes in traffic:</p> <pre><code>from fastreq import fastreq\n\n# Allow bursts of 20 requests, then sustain 10 requests/second\nresults = fastreq(\n    urls=[\"https://api.example.com/endpoint\"] * 100,\n    rate_limit=10,           # 10 requests/second sustained\n    rate_limit_burst=20,     # Allow bursts of 20\n)\n</code></pre> <p>With this configuration: - First 20 requests execute immediately - Subsequent requests execute at ~10 requests/second - Bucket refills at 10 tokens/second</p>"},{"location":"how-to-guides/limit-request-rate/#example-github-api-rate-limiting","title":"Example: GitHub API Rate Limiting","text":"<p>GitHub API has a limit of 5,000 requests per hour (~1.4 requests/second):</p> <pre><code>from fastreq import fastreq\n\n# Safe rate limiting for GitHub API\nresults = fastreq(\n    urls=[f\"https://api.github.com/repos/{repo}\" for repo in my_repos],\n    rate_limit=1,            # Conservative rate\n    rate_limit_burst=5,      # Allow small bursts\n    headers={\n        \"Accept\": \"application/vnd.github.v3+json\",\n    },\n)\n</code></pre>"},{"location":"how-to-guides/limit-request-rate/#example-peak-load-handling","title":"Example: Peak Load Handling","text":"<p>Handle peak loads with burst capacity:</p> <pre><code>from fastreq import fastreq\n\n# Allow bursts during peak traffic, sustain rate otherwise\nresults = fastreq(\n    urls=[\"https://api.example.com/data\"] * 100,\n    rate_limit=20,           # Sustain 20 req/s\n    rate_limit_burst=50,     # Allow bursts of 50\n    concurrency=30,           # Max 30 concurrent\n)\n</code></pre>"},{"location":"how-to-guides/limit-request-rate/#burst-behavior-explained","title":"Burst Behavior Explained","text":""},{"location":"how-to-guides/limit-request-rate/#without-burst-rate_limit_burst1","title":"Without Burst (rate_limit_burst=1)","text":"<pre><code>results = fastreq(\n    urls=[\"https://api.example.com/data\"] * 10,\n    rate_limit=5,              # 5 req/s\n    rate_limit_burst=1,       # No burst capacity\n)\n</code></pre> <p>Timing: - Request 1: 0s - Request 2: 0.2s - Request 3: 0.4s - ...smooth ~0.2s between requests</p>"},{"location":"how-to-guides/limit-request-rate/#with-burst-rate_limit_burst5","title":"With Burst (rate_limit_burst=5)","text":"<pre><code>results = fastreq(\n    urls=[\"https://api.example.com/data\"] * 10,\n    rate_limit=5,              # 5 req/s\n    rate_limit_burst=5,       # Allow burst of 5\n)\n</code></pre> <p>Timing: - Request 1-5: ~0s (burst) - Request 6: ~0.2s (bucket refilling) - Request 7: ~0.4s - ...smooth after burst is exhausted</p>"},{"location":"how-to-guides/limit-request-rate/#combining-rate-limiting-with-concurrency","title":"Combining Rate Limiting with Concurrency","text":"<p>Rate limiting works together with concurrency limits:</p> <pre><code>results = fastreq(\n    urls=[\"https://api.example.com/data\"] * 100,\n    concurrency=20,           # Max 20 concurrent requests\n    rate_limit=10,            # 10 requests/second\n    rate_limit_burst=15,      # Burst of 15\n)\n</code></pre> <p>In this example: - Up to 20 requests can start immediately (limited by concurrency) - Only 10 requests/second complete (limited by rate limit) - Burst of 15 allows initial spike</p>"},{"location":"how-to-guides/limit-request-rate/#rate-limiting-vs-concurrency","title":"Rate Limiting vs Concurrency","text":"<p>Understanding the difference:</p> Parameter Purpose Example <code>concurrency</code> Max requests running at once Don't overwhelm server <code>rate_limit</code> Requests per second Respect API quotas <code>rate_limit_burst</code> Allow temporary spikes Handle peak loads <pre><code># Example: High concurrency, low rate limit\nresults = fastreq(\n    urls=[\"https://api.example.com/data\"] * 100,\n    concurrency=50,           # Many concurrent connections\n    rate_limit=5,             # But only 5 complete per second\n    rate_limit_burst=10,      # Allow initial burst\n)\n</code></pre>"},{"location":"how-to-guides/limit-request-rate/#disabling-rate-limiting","title":"Disabling Rate Limiting","text":"<p>Set <code>rate_limit=None</code> to disable rate limiting:</p> <pre><code>results = fastreq(\n    urls=[\"https://api.example.com/data\"] * 50,\n    rate_limit=None,  # No rate limiting (use with caution!)\n)\n</code></pre> <p>Warning: Only disable rate limiting when you control the target server and can handle the load.</p>"},{"location":"how-to-guides/limit-request-rate/#monitoring-rate-limiting","title":"Monitoring Rate Limiting","text":"<p>Enable debug logging to see rate limiting in action:</p> <pre><code>results = fastreq(\n    urls=[\"https://api.example.com/data\"] * 20,\n    rate_limit=5,\n    rate_limit_burst=10,\n    debug=True,  # See rate limiting logs\n)\n</code></pre> <p>Example output: <pre><code>[DEBUG] Rate limit: 5.0 req/s, burst: 10\n[DEBUG] Request 1: immediate (bucket: 9/10)\n[DEBUG] Request 2: immediate (bucket: 8/10)\n...\n[DEBUG] Request 11: waiting 0.2s for token\n</code></pre></p>"},{"location":"how-to-guides/limit-request-rate/#best-practices","title":"Best Practices","text":"<ol> <li> <p>Know Your API Limits: Check documentation for rate limits    <pre><code># GitHub: 5000 requests/hour ~ 1.4 req/s\nrate_limit=1\n</code></pre></p> </li> <li> <p>Use Burst for Initialization: Allow burst when starting up    <pre><code>rate_limit=10\nrate_limit_burst=20  # Warm-up burst\n</code></pre></p> </li> <li> <p>Stay Conservative: Set rate limit slightly below documented limits    <pre><code># API says 10 req/s, use 8 to be safe\nrate_limit=8\n</code></pre></p> </li> <li> <p>Test Different Values: Find optimal rate for your use case    <pre><code># Start conservative, increase if needed\nrate_limit=5  # Test this first\n</code></pre></p> </li> </ol>"},{"location":"how-to-guides/limit-request-rate/#see-also","title":"See Also","text":"<ul> <li>Handle Retries - Automatic retry configuration</li> <li>Debug Issues - Enable debug logging</li> <li>API Reference - Configuration options</li> </ul>"},{"location":"how-to-guides/make-parallel-requests/","title":"Make Parallel Requests","text":"<p>Learn how to create parallel HTTP requests with different configurations and return types.</p>"},{"location":"how-to-guides/make-parallel-requests/#basic-parallel-requests","title":"Basic Parallel Requests","text":"<p>Make multiple requests to the same or different URLs:</p> <pre><code>from fastreq import fastreq\n\n# Single URL repeated\nresults = fastreq(\n    urls=[\"https://httpbin.org/get\"] * 5,\n    concurrency=3,\n)\n\n# Multiple different URLs\nresults = fastreq(\n    urls=[\n        \"https://api.github.com/repos/python/cpython\",\n        \"https://api.github.com/repos/python/pypy\",\n        \"https://api.github.com/repos/legout/fastreq\",\n    ],\n)\n</code></pre>"},{"location":"how-to-guides/make-parallel-requests/#named-results-with-keys","title":"Named Results with Keys","text":"<p>Use the <code>keys</code> parameter to return a dictionary mapping names to results:</p> <pre><code>from fastreq import fastreq\n\nresults = fastreq(\n    urls=[\n        \"https://api.github.com/repos/python/cpython\",\n        \"https://api.github.com/repos/python/pypy\",\n    ],\n    keys=[\"cpython\", \"pypy\"],\n)\n\n# Access results by key\nprint(f\"CPython: {results['cpython']['name']}\")\nprint(f\"PyPy: {results['pypy']['name']}\")\n</code></pre> <p>The keys parameter is useful when you need to track which result corresponds to which request.</p>"},{"location":"how-to-guides/make-parallel-requests/#custom-response-transformation","title":"Custom Response Transformation","text":"<p>Use <code>parse_func</code> to apply custom transformation to each response:</p> <pre><code>from fastreq import fastreq\n\ndef extract_repo_info(response):\n    \"\"\"Extract only relevant fields from GitHub API response.\"\"\"\n    return {\n        \"name\": response.get(\"name\"),\n        \"stars\": response.get(\"stargazers_count\"),\n        \"language\": response.get(\"language\"),\n    }\n\nresults = fastreq(\n    urls=[\n        \"https://api.github.com/repos/python/cpython\",\n        \"https://api.github.com/repos/legout/fastreq\",\n    ],\n    parse_func=extract_repo_info,\n)\n\nfor repo in results:\n    print(f\"{repo['name']}: {repo['stars']} stars, {repo['language']}\")\n</code></pre>"},{"location":"how-to-guides/make-parallel-requests/#different-return-types","title":"Different Return Types","text":"<p>Control how responses are parsed with <code>return_type</code>:</p>"},{"location":"how-to-guides/make-parallel-requests/#json-response-default","title":"JSON Response (Default)","text":"<pre><code>from fastreq import fastreq\n\nresults = fastreq(\n    urls=[\"https://api.github.com/repos/python/cpython\"],\n    return_type=\"json\",\n)\n\nprint(results[0][\"name\"])  # Access JSON fields directly\n</code></pre>"},{"location":"how-to-guides/make-parallel-requests/#text-response","title":"Text Response","text":"<pre><code>results = fastreq(\n    urls=[\"https://httpbin.org/html\"],\n    return_type=\"text\",\n)\n\nprint(results[0])  # Raw HTML text\n</code></pre>"},{"location":"how-to-guides/make-parallel-requests/#binary-content","title":"Binary Content","text":"<pre><code>results = fastreq(\n    urls=[\"https://httpbin.org/bytes/1024\"],\n    return_type=\"content\",\n)\n\nprint(len(results[0]))  # Length in bytes\n</code></pre>"},{"location":"how-to-guides/make-parallel-requests/#full-response-object","title":"Full Response Object","text":"<pre><code>from fastreq import fastreq, ReturnType\n\nresults = fastreq(\n    urls=[\"https://httpbin.org/get\"],\n    return_type=ReturnType.RESPONSE,\n)\n\nresponse = results[0]\nprint(f\"Status: {response.status_code}\")\nprint(f\"Headers: {response.headers}\")\nprint(f\"Body: {response.json()}\")\n</code></pre>"},{"location":"how-to-guides/make-parallel-requests/#async-parallel-requests","title":"Async Parallel Requests","text":"<p>For async applications, use the async version:</p> <pre><code>import asyncio\nfrom fastreq import fastreq_async\n\nasync def fetch_data():\n    results = await fastreq_async(\n        urls=[\n            \"https://api.github.com/repos/python/cpython\",\n            \"https://api.github.com/repos/python/pypy\",\n        ],\n        concurrency=5,\n    )\n    return results\n\nresults = asyncio.run(fetch_data())\n</code></pre>"},{"location":"how-to-guides/make-parallel-requests/#using-a-context-manager","title":"Using a Context Manager","text":"<p>Reuse sessions across multiple request batches:</p> <pre><code>import asyncio\nfrom fastreq import FastRequests\n\nasync def fetch_with_session():\n    async with FastRequests(concurrency=5) as client:\n        # First batch\n        results1 = await client.request(\n            urls=[\"https://api.github.com/repos/python/cpython\"],\n        )\n\n        # Second batch (reuses session/cookies)\n        results2 = await client.request(\n            urls=[\"https://api.github.com/repos/python/pypy\"],\n        )\n\n        return results1, results2\n\nresults1, results2 = asyncio.run(fetch_with_session())\n</code></pre>"},{"location":"how-to-guides/make-parallel-requests/#mixing-url-parameters","title":"Mixing URL Parameters","text":"<p>Pass URL-specific parameters using dictionaries:</p> <pre><code>from fastreq import fastreq\n\nresults = fastreq(\n    urls=[\n        \"https://api.github.com/repos/python/cpython\",\n        \"https://api.github.com/repos/python/pypy\",\n    ],\n    params=[\n        {\"ref\": \"main\"},  # First URL params\n        {},               # Second URL params (empty)\n    ],\n)\n</code></pre>"},{"location":"how-to-guides/make-parallel-requests/#combining-with-other-options","title":"Combining with Other Options","text":"<p>Combine parallel requests with other features:</p> <pre><code>from fastreq import fastreq\n\nresults = fastreq(\n    urls=[\n        \"https://api.github.com/repos/python/cpython\",\n        \"https://api.github.com/repos/python/pypy\",\n    ],\n    keys=[\"cpython\", \"pypy\"],\n    concurrency=3,\n    max_retries=2,\n    timeout=10,\n    rate_limit=10,\n    headers={\n        \"User-Agent\": \"MyApp/1.0\",\n        \"Accept\": \"application/vnd.github.v3+json\",\n    },\n)\n</code></pre>"},{"location":"how-to-guides/make-parallel-requests/#see-also","title":"See Also","text":"<ul> <li>Limit Request Rate - Control request frequency</li> <li>Handle Retries - Configure retry logic</li> <li>API Reference - Complete function documentation</li> </ul>"},{"location":"how-to-guides/post-json-data/","title":"Post JSON Data","text":"<p>Learn how to handle POST, PUT, and PATCH requests with various data formats.</p>"},{"location":"how-to-guides/post-json-data/#post-requests-with-json","title":"POST Requests with JSON","text":"<p>Send JSON payloads using the <code>json</code> parameter:</p> <pre><code>from fastreq import fastreq\n\nresults = fastreq(\n    urls=[\"https://httpbin.org/post\"] * 3,\n    method=\"POST\",\n    json={\n        \"name\": \"John Doe\",\n        \"email\": \"john@example.com\",\n        \"age\": 30,\n    },\n    headers={\"Content-Type\": \"application/json\"},\n)\n\nfor result in results:\n    print(f\"Echo: {result['json']}\")\n</code></pre>"},{"location":"how-to-guides/post-json-data/#post-with-form-data","title":"POST with Form Data","text":"<p>Send form-encoded data using the <code>data</code> parameter:</p> <pre><code>from fastreq import fastreq\n\nresults = fastreq(\n    urls=[\"https://httpbin.org/post\"],\n    method=\"POST\",\n    data={\n        \"username\": \"john\",\n        \"password\": \"secret\",\n    },\n    headers={\"Content-Type\": \"application/x-www-form-urlencoded\"},\n)\n\nfor result in results:\n    print(f\"Form: {result['form']}\")\n</code></pre>"},{"location":"how-to-guides/post-json-data/#put-requests-for-updates","title":"PUT Requests for Updates","text":"<p>Use <code>method=\"PUT\"</code> to update resources:</p> <pre><code>from fastreq import fastreq\n\nresults = fastreq(\n    urls=[\"https://httpbin.org/put\"],\n    method=\"PUT\",\n    json={\n        \"id\": 123,\n        \"name\": \"Updated Name\",\n        \"status\": \"active\",\n    },\n)\n\nfor result in results:\n    print(f\"Updated: {result['json']}\")\n</code></pre>"},{"location":"how-to-guides/post-json-data/#patch-requests-for-partial-updates","title":"PATCH Requests for Partial Updates","text":"<p>Use <code>method=\"PATCH\"</code> for partial resource updates:</p> <pre><code>from fastreq import fastreq\n\nresults = fastreq(\n    urls=[\"https://httpbin.org/patch\"],\n    method=\"PATCH\",\n    json={\n        \"status\": \"completed\",  # Only update status\n    },\n)\n\nfor result in results:\n    print(f\"Patched: {result['json']}\")\n</code></pre>"},{"location":"how-to-guides/post-json-data/#delete-requests","title":"DELETE Requests","text":"<p>Use <code>method=\"DELETE\"</code> to remove resources:</p> <pre><code>from fastreq import fastreq\n\nresults = fastreq(\n    urls=[\"https://httpbin.org/delete\"],\n    method=\"DELETE\",\n)\n\nfor result in results:\n    print(f\"Deleted: {result.get('data')}\")\n</code></pre>"},{"location":"how-to-guides/post-json-data/#example-creating-resources-via-post","title":"Example: Creating Resources via POST","text":"<p>Create multiple resources in parallel:</p> <pre><code>from fastreq import fastreq\n\nusers = [\n    {\"name\": \"Alice\", \"email\": \"alice@example.com\"},\n    {\"name\": \"Bob\", \"email\": \"bob@example.com\"},\n    {\"name\": \"Charlie\", \"email\": \"charlie@example.com\"},\n]\n\nresults = fastreq(\n    urls=[\"https://api.example.com/users\"] * len(users),\n    method=\"POST\",\n    json=users,  # Each request gets one user\n    headers={\n        \"Authorization\": \"Bearer YOUR_TOKEN\",\n        \"Content-Type\": \"application/json\",\n    },\n)\n\nfor i, result in enumerate(results):\n    if result.get(\"id\"):\n        print(f\"Created user {i+1}: ID={result['id']}\")\n</code></pre>"},{"location":"how-to-guides/post-json-data/#example-updating-resources-via-putpatch","title":"Example: Updating Resources via PUT/PATCH","text":"<p>Update multiple resources:</p> <pre><code>from fastreq import fastreq\n\nuser_ids = [1, 2, 3]\nupdates = [\n    {\"status\": \"active\"},\n    {\"status\": \"inactive\"},\n    {\"status\": \"pending\"},\n]\n\nresults = fastreq(\n    urls=[f\"https://api.example.com/users/{uid}\" for uid in user_ids],\n    method=\"PATCH\",\n    json=updates,\n    headers={\n        \"Authorization\": \"Bearer YOUR_TOKEN\",\n    },\n)\n\nfor i, result in enumerate(results):\n    print(f\"Updated user {user_ids[i]}: {result.get('status')}\")\n</code></pre>"},{"location":"how-to-guides/post-json-data/#different-data-per-request","title":"Different Data per Request","text":"<p>Send different data for each URL using a list:</p> <pre><code>from fastreq import fastreq\n\nurls = [\n    \"https://api.example.com/users/1\",\n    \"https://api.example.com/users/2\",\n    \"https://api.example.com/users/3\",\n]\n\ndata_list = [\n    {\"name\": \"Alice\", \"status\": \"active\"},\n    {\"name\": \"Bob\", \"status\": \"inactive\"},\n    {\"name\": \"Charlie\", \"status\": \"pending\"},\n]\n\nresults = fastreq(\n    urls=urls,\n    method=\"PATCH\",\n    json=data_list,  # List of data dicts\n)\n\nfor url, result in zip(urls, results):\n    print(f\"{url}: {result}\")\n</code></pre>"},{"location":"how-to-guides/post-json-data/#sending-files-as-multipartform-data","title":"Sending Files as multipart/form-data","text":"<p>Upload files using <code>files</code> parameter:</p> <pre><code>from fastreq import fastreq\n\nresults = fastreq(\n    urls=[\"https://httpbin.org/post\"],\n    method=\"POST\",\n    files={\n        \"file\": (\"document.txt\", b\"File content here\"),\n    },\n)\n\nfor result in results:\n    print(f\"Uploaded: {result.get('files')}\")\n</code></pre>"},{"location":"how-to-guides/post-json-data/#sending-multiple-files","title":"Sending Multiple Files","text":"<p>Upload multiple files:</p> <pre><code>from fastreq import fastreq\n\nresults = fastreq(\n    urls=[\"https://api.example.com/upload\"],\n    method=\"POST\",\n    files={\n        \"file1\": (\"doc1.txt\", b\"Content 1\"),\n        \"file2\": (\"doc2.txt\", b\"Content 2\"),\n        \"metadata\": (\"info.json\", b'{\"key\": \"value\"}', \"application/json\"),\n    },\n)\n\nfor result in results:\n    print(f\"Uploaded files: {result.get('files')}\")\n</code></pre>"},{"location":"how-to-guides/post-json-data/#custom-headers-for-different-requests","title":"Custom Headers for Different Requests","text":"<p>Set headers per request using a list:</p> <pre><code>from fastreq import fastreq\n\nurls = [\n    \"https://api.example.com/users\",\n    \"https://api.example.com/posts\",\n]\n\nheaders_list = [\n    {\"Authorization\": \"Bearer USER_TOKEN\"},\n    {\"Authorization\": \"Bearer POST_TOKEN\"},\n]\n\nresults = fastreq(\n    urls=urls,\n    method=\"POST\",\n    json=[{}, {}],\n    headers=headers_list,\n)\n</code></pre>"},{"location":"how-to-guides/post-json-data/#sending-raw-request-bodies","title":"Sending Raw Request Bodies","text":"<p>Send raw request bodies with <code>data</code> parameter:</p> <pre><code>from fastreq import fastreq\n\n# Send raw text\nresults = fastreq(\n    urls=[\"https://httpbin.org/post\"],\n    method=\"POST\",\n    data=\"raw text body\",\n    headers={\"Content-Type\": \"text/plain\"},\n)\n\n# Send raw bytes\nresults = fastreq(\n    urls=[\"https://httpbin.org/post\"],\n    method=\"POST\",\n    data=b\"binary data\",\n    headers={\"Content-Type\": \"application/octet-stream\"},\n)\n</code></pre>"},{"location":"how-to-guides/post-json-data/#query-parameters-with-post","title":"Query Parameters with POST","text":"<p>Combine query parameters with POST body:</p> <pre><code>from fastreq import fastreq\n\nresults = fastreq(\n    urls=[\"https://httpbin.org/post\"],\n    method=\"POST\",\n    params={\"token\": \"secret\"},  # Query params\n    json={\"key\": \"value\"},      # POST body\n)\n\nfor result in results:\n    print(f\"Args: {result['args']}\")\n    print(f\"JSON: {result['json']}\")\n</code></pre>"},{"location":"how-to-guides/post-json-data/#authentication-with-post","title":"Authentication with POST","text":"<p>Include authentication in headers:</p> <pre><code>from fastreq import fastreq\n\n# Bearer token\nresults = fastreq(\n    urls=[\"https://api.example.com/data\"],\n    method=\"POST\",\n    json={\"query\": \"SELECT *\"},\n    headers={\n        \"Authorization\": \"Bearer YOUR_ACCESS_TOKEN\",\n    },\n)\n\n# API key\nresults = fastreq(\n    urls=[\"https://api.example.com/data\"],\n    method=\"POST\",\n    json={\"query\": \"SELECT *\"},\n    headers={\n        \"X-API-Key\": \"your-api-key\",\n    },\n)\n</code></pre>"},{"location":"how-to-guides/post-json-data/#handling-post-response-codes","title":"Handling POST Response Codes","text":"<p>Check response status codes:</p> <pre><code>from fastreq import fastreq, ReturnType\n\nresults = fastreq(\n    urls=[\"https://httpbin.org/status/201\"],\n    method=\"POST\",\n    json={\"key\": \"value\"},\n    return_type=ReturnType.RESPONSE,\n)\n\nfor response in results:\n    print(f\"Status: {response.status_code}\")\n    print(f\"Headers: {response.headers}\")\n    if response.status_code in [200, 201]:\n        print(\"Success!\")\n</code></pre>"},{"location":"how-to-guides/post-json-data/#error-handling-for-failed-post-requests","title":"Error Handling for Failed POST Requests","text":"<pre><code>from fastreq import fastreq, PartialFailureError\n\ntry:\n    results = fastreq(\n        urls=[\n            \"https://api.example.com/users\",\n            \"https://invalid-url.com/users\",\n        ],\n        method=\"POST\",\n        json=[{\"name\": \"Alice\"}, {\"name\": \"Bob\"}],\n    )\nexcept PartialFailureError as e:\n    print(f\"Partial failure: {e.successes}/{e.total}\")\n    for url, details in e.failures.items():\n        print(f\"Failed: {url} - {details.error}\")\n</code></pre>"},{"location":"how-to-guides/post-json-data/#best-practices","title":"Best Practices","text":"<ol> <li> <p>Set Content-Type Headers: Always specify content type    <pre><code>headers={\"Content-Type\": \"application/json\"}\n</code></pre></p> </li> <li> <p>Use Correct Method: Choose POST, PUT, or PATCH appropriately</p> </li> <li>POST: Create new resources</li> <li>PUT: Replace entire resource</li> <li> <p>PATCH: Partial update</p> </li> <li> <p>Handle Errors: Check status codes or catch exceptions    <pre><code>except PartialFailureError as e:\n    print(f\"Failed: {e.failures}\")\n</code></pre></p> </li> <li> <p>Authenticate Properly: Include auth headers    <pre><code>headers={\"Authorization\": \"Bearer YOUR_TOKEN\"}\n</code></pre></p> </li> <li> <p>Validate Responses: Check response structure    <pre><code>if result.get(\"id\"):\n    print(f\"Created: {result['id']}\")\n</code></pre></p> </li> </ol>"},{"location":"how-to-guides/post-json-data/#see-also","title":"See Also","text":"<ul> <li>Make Parallel Requests - Basic request configuration</li> <li>Handle Retries - Configure retry logic for POST requests</li> <li>Debug Issues - Troubleshoot request problems</li> <li>API Reference - Configuration options</li> </ul>"},{"location":"how-to-guides/select-backend/","title":"Select Backend","text":"<p>Learn how to choose and configure HTTP backends (niquests, httpx, aiohttp, requests).</p>"},{"location":"how-to-guides/select-backend/#backend-auto-detection","title":"Backend Auto-Detection","text":"<p>The library automatically selects the best available backend:</p> <pre><code>from fastreq import fastreq\n\n# Auto-detection (default)\nresults = fastreq(\n    urls=[\"https://httpbin.org/get\"],\n    backend=\"auto\",  # Default behavior\n)\n</code></pre> <p>Detection Order: 1. niquests - HTTP/2 support, streaming, async native 2. httpx - HTTP/2 support (with h2 extra), modern API, async native 3. aiohttp - Streaming support, async native 4. requests - Sync-first, streaming via thread wrapper</p>"},{"location":"how-to-guides/select-backend/#explicit-backend-selection","title":"Explicit Backend Selection","text":"<p>Force a specific backend:</p> <pre><code>from fastreq import fastreq\n\n# Use niquests (recommended)\nresults = fastreq(\n    urls=[\"https://httpbin.org/get\"],\n    backend=\"niquests\",\n)\n\n# Use httpx (modern async API with HTTP/2 support)\nresults = fastreq(\n    urls=[\"https://httpbin.org/get\"],\n    backend=\"httpx\",\n)\n\n# Use aiohttp\nresults = fastreq(\n    urls=[\"https://httpbin.org/get\"],\n    backend=\"aiohttp\",\n)\n\n# Use requests\nresults = fastreq(\n    urls=[\"https://httpbin.org/get\"],\n    backend=\"requests\",\n)\n</code></pre>"},{"location":"how-to-guides/select-backend/#backend-feature-comparison","title":"Backend Feature Comparison","text":"Feature niquests httpx aiohttp requests HTTP/2 Support \u2705 Yes \u2705 Yes* \u274c No \u274c No Streaming \u2705 Yes \u2705 Yes \u2705 Yes \u2705 Yes Async Native \u2705 Yes \u2705 Yes \u2705 Yes \u274c No Sync Native \u2705 Yes \u274c No \u274c No \u2705 Yes Connection Pooling \u2705 Yes \u2705 Yes \u2705 Yes \u2705 Yes Cookies \u2705 Yes \u2705 Yes \u2705 Yes \u2705 Yes Proxies \u2705 Yes \u2705 Yes \u2705 Yes \u2705 Yes Session Reuse \u2705 Yes \u2705 Yes \u2705 Yes \u2705 Yes <p>*HTTP/2 requires <code>pip install httpx[http2]</code> (installs the <code>h2</code> extra)</p>"},{"location":"how-to-guides/select-backend/#when-to-use-each-backend","title":"When to Use Each Backend","text":""},{"location":"how-to-guides/select-backend/#use-niquests-when","title":"Use niquests When:","text":"<ul> <li>You need HTTP/2 support</li> <li>You want the best performance</li> <li>You need both sync and async compatibility</li> </ul> <pre><code>from fastreq import fastreq\n\n# Best for modern APIs with HTTP/2\nresults = fastreq(\n    urls=[\"https://api.example.com/data\"] * 100,\n    backend=\"niquests\",\n    concurrency=50,\n)\n</code></pre>"},{"location":"how-to-guides/select-backend/#use-httpx-when","title":"Use httpx When:","text":"<ul> <li>You prefer httpx's modern API</li> <li>You need HTTP/2 with aio-like async interface</li> <li>You're already using httpx in your project</li> </ul> <pre><code>import asyncio\nfrom fastreq import fastreq_async\n\nasync def fetch_with_httpx():\n    results = await fastreq_async(\n        urls=[\"https://api.example.com/data\"] * 100,\n        backend=\"httpx\",\n        concurrency=50,\n    )\n    return results\n\n# HTTP/2 requires httpx[http2] extra\nresults = asyncio.run(fetch_with_httpx())\n</code></pre>"},{"location":"how-to-guides/select-backend/#use-aiohttp-when","title":"Use aiohttp When:","text":"<ul> <li>You're building async/await applications</li> <li>You need efficient async I/O</li> <li>You're already using aiohttp</li> </ul> <pre><code>import asyncio\nfrom fastreq import fastreq_async\n\nasync def async_fetch():\n    results = await fastreq_async(\n        urls=[\"https://api.example.com/data\"] * 100,\n        backend=\"aiohttp\",\n        concurrency=50,\n    )\n    return results\n\nresults = asyncio.run(async_fetch())\n</code></pre>"},{"location":"how-to-guides/select-backend/#use-requests-when","title":"Use requests When:","text":"<ul> <li>You need synchronous code</li> <li>You're working with existing requests-based code</li> <li>Compatibility is more important than performance</li> </ul> <pre><code>from fastreq import fastreq\n\n# Simple synchronous use\nresults = fastreq(\n    urls=[\"https://api.example.com/data\"] * 50,\n    backend=\"requests\",\n)\n</code></pre>"},{"location":"how-to-guides/select-backend/#http2-support-example","title":"HTTP/2 Support Example","text":"<p>niquests and httpx support HTTP/2 for better performance:</p> <pre><code>from fastreq import fastreq\n\n# HTTP/2 with niquests\nresults = fastreq(\n    urls=[\"https://httpbin.org/get\"] * 10,\n    backend=\"niquests\",\n    debug=True,\n)\n\n# HTTP/2 with httpx (requires httpx[http2] extra)\nresults = fastreq(\n    urls=[\"https://httpbin.org/get\"] * 10,\n    backend=\"httpx\",\n)\n\n# Other backends use HTTP/1.1\nresults = fastreq(\n    urls=[\"https://httpbin.org/get\"] * 10,\n    backend=\"aiohttp\",  # HTTP/1.1 only\n)\n</code></pre> <p>Benefits of HTTP/2: - Multiplexing: Multiple requests over single connection - Header compression: Reduced bandwidth - Server push: Optional optimization</p>"},{"location":"how-to-guides/select-backend/#backend-performance-comparison","title":"Backend Performance Comparison","text":"<p>Benchmark different backends:</p> <pre><code>import time\nfrom fastreq import fastreq\n\nurls = [\"https://httpbin.org/get\"] * 100\n\nfor backend in [\"niquests\", \"httpx\", \"aiohttp\", \"requests\"]:\n    start = time.time()\n    results = fastreq(\n        urls=urls,\n        backend=backend,\n        concurrency=20,\n    )\n    elapsed = time.time() - start\n    print(f\"{backend}: {elapsed:.2f}s\")\n</code></pre>"},{"location":"how-to-guides/select-backend/#installing-backend-specific-dependencies","title":"Installing Backend-Specific Dependencies","text":"<p>Install with specific backend support:</p> <pre><code># All backends (recommended)\npip install fastreq[all]\n\n# niquests only (HTTP/2 support)\npip install fastreq[niquests]\n\n# httpx only (HTTP/2 support with h2 extra)\npip install fastreq[httpx]\n\n# aiohttp only\npip install fastreq[aiohttp]\n\n# requests only\npip install fastreq[requests]\n</code></pre>"},{"location":"how-to-guides/select-backend/#checking-backend-availability","title":"Checking Backend Availability","text":"<p>Check which backends are available:</p> <pre><code>from fastreq.backends import get_available_backends\n\navailable = get_available_backends()\nprint(f\"Available backends: {available}\")\n</code></pre>"},{"location":"how-to-guides/select-backend/#backend-specific-configuration","title":"Backend-Specific Configuration","text":"<p>Some backends support additional configuration:</p> <pre><code>from fastreq import fastreq\n\n# niquests-specific options\nresults = fastreq(\n    urls=[\"https://httpbin.org/get\"],\n    backend=\"niquests\",\n    # Backend can expose additional options\n)\n\n# httpx-specific options\nresults = fastreq(\n    urls=[\"https://httpbin.org/get\"],\n    backend=\"httpx\",\n    # Backend can expose additional options\n)\n\n# aiohttp-specific options\nresults = fastreq(\n    urls=[\"https://httpbin.org/get\"],\n    backend=\"aiohttp\",\n    # Backend can expose additional options\n)\n</code></pre>"},{"location":"how-to-guides/select-backend/#connection-pooling-by-backend","title":"Connection Pooling by Backend","text":"<p>All backends support connection pooling:</p> <pre><code>from fastreq import fastreq\n\n# Connection pooling is automatic\nresults = fastreq(\n    urls=[\"https://api.example.com/data\"] * 100,\n    concurrency=20,\n    backend=\"niquests\",\n)\n\n# Same request reuses connections (if using context manager)\n</code></pre>"},{"location":"how-to-guides/select-backend/#session-reuse-with-context-manager","title":"Session Reuse with Context Manager","text":"<p>Reuse sessions across multiple batches:</p> <pre><code>import asyncio\nfrom fastreq import FastRequests\n\nasync def reuse_session():\n    async with FastRequests(backend=\"niquests\") as client:\n        # First batch\n        results1 = await client.request(\n            urls=[\"https://api.github.com/repos/python/cpython\"],\n        )\n\n        # Second batch (reuses session)\n        results2 = await client.request(\n            urls=[\"https://api.github.com/repos/python/pypy\"],\n        )\n\n        return results1, results2\n\nresults1, results2 = asyncio.run(reuse_session())\n</code></pre>"},{"location":"how-to-guides/select-backend/#error-handling-by-backend","title":"Error Handling by Backend","text":"<p>Different backends handle errors differently:</p> <pre><code>from fastreq import fastreq\n\ntry:\n    results = fastreq(\n        urls=[\"https://invalid-url.com\"],\n        backend=\"niquests\",\n    )\nexcept Exception as e:\n    print(f\"niquests error: {e}\")\n\ntry:\n    results = fastreq(\n        urls=[\"https://invalid-url.com\"],\n        backend=\"aiohttp\",\n    )\nexcept Exception as e:\n    print(f\"aiohttp error: {e}\")\n</code></pre>"},{"location":"how-to-guides/select-backend/#backend-specific-timeout-handling","title":"Backend-Specific Timeout Handling","text":"<p>Timeouts work consistently across backends:</p> <pre><code>from fastreq import fastreq\n\n# Timeout works the same for all backends\nresults = fastreq(\n    urls=[\"https://httpbin.org/delay/5\"],\n    timeout=3,  # 3 second timeout\n    backend=\"niquests\",  # or httpx, aiohttp, requests\n)\n</code></pre>"},{"location":"how-to-guides/select-backend/#backend-selection-strategy","title":"Backend Selection Strategy","text":""},{"location":"how-to-guides/select-backend/#production-recommendation","title":"Production Recommendation","text":"<pre><code>from fastreq import fastreq\n\n# Use auto-detection for production\nresults = fastreq(\n    urls=[\"https://api.example.com/data\"] * 100,\n    backend=\"auto\",  # Will pick niquests if available\n    concurrency=20,\n)\n</code></pre>"},{"location":"how-to-guides/select-backend/#development-strategy","title":"Development Strategy","text":"<pre><code># During development, test with multiple backends\nfor backend in [\"niquests\", \"httpx\", \"aiohttp\", \"requests\"]:\n    try:\n        results = fastreq(\n            urls=test_urls,\n            backend=backend,\n        )\n        print(f\"{backend}: OK\")\n    except Exception as e:\n        print(f\"{backend}: FAILED - {e}\")\n</code></pre>"},{"location":"how-to-guides/select-backend/#best-practices","title":"Best Practices","text":"<ol> <li> <p>Use Auto-Detection: Let the library choose the best backend    <pre><code>backend=\"auto\"  # Default\n</code></pre></p> </li> <li> <p>Prefer niquests or httpx: For HTTP/2 support and modern async API    <pre><code>backend=\"niquests\"  # or \"httpx\"\n</code></pre></p> </li> <li> <p>Test All Backends: Verify compatibility during development    <pre><code>for backend in [\"niquests\", \"httpx\", \"aiohttp\", \"requests\"]:\n    # Test code\n</code></pre></p> </li> <li> <p>Handle Backend Errors: Catch backend-specific errors    <pre><code>except Exception as e:\n    print(f\"Backend error: {e}\")\n</code></pre></p> </li> <li> <p>Use Context Managers: Reuse sessions for better performance    <pre><code>async with ParallelRequests() as client:\n    await client.request(urls=urls)\n</code></pre></p> </li> </ol>"},{"location":"how-to-guides/select-backend/#see-also","title":"See Also","text":"<ul> <li>Make Parallel Requests - Request configuration</li> <li>Stream Large Files - Backend streaming differences</li> <li>API Reference - Backend documentation</li> </ul>"},{"location":"how-to-guides/stream-large-files/","title":"Stream Large Files","text":"<p>Learn how to download large files efficiently using streaming to save memory.</p>"},{"location":"how-to-guides/stream-large-files/#streaming-basics","title":"Streaming Basics","text":"<p>Use <code>return_type=\"stream\"</code> with <code>stream_callback</code> to process responses incrementally:</p> <pre><code>from fastreq import fastreq\n\ndef stream_handler(response, url):\n    \"\"\"Handle streaming response.\"\"\"\n    content_length = int(response.headers.get('content-length', 0))\n    downloaded = 0\n\n    with open(f\"output_{url.split('/')[-1]}\", \"wb\") as f:\n        for chunk in response.iter_content(chunk_size=8192):\n            if chunk:\n                f.write(chunk)\n                downloaded += len(chunk)\n                print(f\"Downloaded: {downloaded}/{content_length} bytes\")\n\nresults = fastreq(\n    urls=[\n        \"https://httpbin.org/bytes/10240\",\n        \"https://httpbin.org/bytes/20480\",\n    ],\n    return_type=\"stream\",\n    stream_callback=stream_handler,\n)\n</code></pre>"},{"location":"how-to-guides/stream-large-files/#downloading-with-progress-tracking","title":"Downloading with Progress Tracking","text":"<p>Track download progress for multiple files:</p> <pre><code>from fastreq import fastreq\nimport os\n\ndef download_with_progress(response, url):\n    filename = os.path.basename(url)\n    total_size = int(response.headers.get('content-length', 0))\n    downloaded = 0\n\n    print(f\"Starting: {filename} ({total_size} bytes)\")\n\n    with open(filename, \"wb\") as f:\n        for chunk in response.iter_content(chunk_size=8192):\n            if chunk:\n                f.write(chunk)\n                downloaded += len(chunk)\n\n                if total_size &gt; 0:\n                    percent = (downloaded / total_size) * 100\n                    print(f\"{filename}: {percent:.1f}%\")\n\n    print(f\"Completed: {filename}\")\n\nresults = fastreq(\n    urls=[\n        \"https://httpbin.org/bytes/10485760\",  # 10 MB\n        \"https://httpbin.org/bytes/20971520\",  # 20 MB\n    ],\n    return_type=\"stream\",\n    stream_callback=download_with_progress,\n)\n</code></pre>"},{"location":"how-to-guides/stream-large-files/#processing-streaming-responses-line-by-line","title":"Processing Streaming Responses Line by Line","text":"<p>Process large responses line by line (e.g., CSV, JSON lines):</p> <pre><code>from fastreq import fastreq\n\ndef process_jsonl(response, url):\n    \"\"\"Process JSON Lines format.\"\"\"\n    line_count = 0\n\n    for line in response.iter_lines():\n        if line:\n            import json\n            data = json.loads(line)\n            line_count += 1\n            print(f\"Line {line_count}: {data}\")\n\n    print(f\"Processed {line_count} lines from {url}\")\n\nresults = fastreq(\n    urls=[\n        \"https://api.example.com/data.jsonl\",\n    ],\n    return_type=\"stream\",\n    stream_callback=process_jsonl,\n)\n</code></pre>"},{"location":"how-to-guides/stream-large-files/#memory-efficiency-comparison","title":"Memory Efficiency Comparison","text":""},{"location":"how-to-guides/stream-large-files/#non-streaming-high-memory-usage","title":"Non-Streaming (High Memory Usage)","text":"<pre><code>from fastreq import fastreq\n\n# Loads entire response into memory\nresults = fastreq(\n    urls=[\"https://example.com/large-file.zip\"],  # 1 GB file\n    return_type=\"content\",\n)\n\n# Memory: ~1 GB\n</code></pre>"},{"location":"how-to-guides/stream-large-files/#streaming-low-memory-usage","title":"Streaming (Low Memory Usage)","text":"<pre><code>from fastreq import fastreq\n\ndef save_stream(response, url):\n    with open(\"large-file.zip\", \"wb\") as f:\n        for chunk in response.iter_content(chunk_size=8192):\n            if chunk:\n                f.write(chunk)\n\n# Processes in 8KB chunks\nresults = fastreq(\n    urls=[\"https://example.com/large-file.zip\"],\n    return_type=\"stream\",\n    stream_callback=save_stream,\n)\n\n# Memory: ~8 KB (chunk size)\n</code></pre>"},{"location":"how-to-guides/stream-large-files/#parallel-file-downloads","title":"Parallel File Downloads","text":"<p>Download multiple files simultaneously with progress tracking:</p> <pre><code>from fastreq import fastreq\nfrom tqdm import tqdm  # pip install tqdm\nimport os\n\nfiles = [\n    \"https://httpbin.org/bytes/10485760\",  # 10 MB\n    \"https://httpbin.org/bytes/20971520\",  # 20 MB\n    \"https://httpbin.org/bytes/52428800\",  # 50 MB\n]\n\ndef download_with_tqdm(response, url):\n    filename = f\"download_{os.path.basename(url)}\"\n    total_size = int(response.headers.get('content-length', 0))\n\n    with tqdm(\n        total=total_size,\n        unit='B',\n        unit_scale=True,\n        desc=filename,\n    ) as pbar, open(filename, \"wb\") as f:\n        for chunk in response.iter_content(chunk_size=8192):\n            if chunk:\n                f.write(chunk)\n                pbar.update(len(chunk))\n\nresults = fastreq(\n    urls=files,\n    concurrency=3,\n    return_type=\"stream\",\n    stream_callback=download_with_tqdm,\n    verbose=False,  # Disable default progress bar\n)\n</code></pre>"},{"location":"how-to-guides/stream-large-files/#filtering-streaming-content","title":"Filtering Streaming Content","text":"<p>Filter content while streaming:</p> <pre><code>from fastreq import fastreq\n\ndef filter_lines(response, url):\n    \"\"\"Filter lines containing 'error' keyword.\"\"\"\n    with open(f\"filtered_{os.path.basename(url)}\", \"w\") as f:\n        for line in response.iter_lines():\n            if line:\n                text = line.decode('utf-8')\n                if 'error' in text.lower():\n                    f.write(text + '\\n')\n\nresults = fastreq(\n    urls=[\"https://api.example.com/logs.txt\"],\n    return_type=\"stream\",\n    stream_callback=filter_lines,\n)\n</code></pre>"},{"location":"how-to-guides/stream-large-files/#resumable-downloads","title":"Resumable Downloads","text":"<p>Implement resumable downloads with Range headers:</p> <pre><code>from fastreq import fastreq\nimport os\n\ndef resumable_download(response, url):\n    filename = \"large-file.bin\"\n    downloaded_size = 0\n\n    # Check if file exists and get size\n    if os.path.exists(filename):\n        downloaded_size = os.path.getsize(filename)\n\n    print(f\"Resuming from {downloaded_size} bytes\")\n\n    mode = 'ab' if downloaded_size &gt; 0 else 'wb'\n\n    with open(filename, mode) as f:\n        for chunk in response.iter_content(chunk_size=8192):\n            if chunk:\n                f.write(chunk)\n\n    print(f\"Download complete: {os.path.getsize(filename)} bytes\")\n\n# Note: Range headers must be set in request configuration\nresults = fastreq(\n    urls=[\"https://example.com/large-file.bin\"],\n    return_type=\"stream\",\n    stream_callback=resumable_download,\n)\n</code></pre>"},{"location":"how-to-guides/stream-large-files/#chunked-upload-with-streaming","title":"Chunked Upload with Streaming","text":"<p>Stream large files during upload:</p> <pre><code>from fastreq import fastreq\n\ndef stream_large_file(filepath):\n    \"\"\"Generator for streaming file chunks.\"\"\"\n    with open(filepath, 'rb') as f:\n        while chunk := f.read(8192):\n            yield chunk\n\n# Note: This requires backend-specific implementation\n# Check documentation for chunked upload support\n</code></pre>"},{"location":"how-to-guides/stream-large-files/#error-handling-with-streaming","title":"Error Handling with Streaming","text":"<p>Handle errors during streaming:</p> <pre><code>from fastreq import fastreq\n\ndef safe_stream(response, url):\n    try:\n        with open(f\"output_{os.path.basename(url)}\", \"wb\") as f:\n            for chunk in response.iter_content(chunk_size=8192):\n                if chunk:\n                    f.write(chunk)\n        print(f\"Downloaded: {url}\")\n    except Exception as e:\n        print(f\"Error downloading {url}: {e}\")\n        raise\n\nresults = fastreq(\n    urls=[\"https://httpbin.org/bytes/10240\"],\n    return_type=\"stream\",\n    stream_callback=safe_stream,\n)\n</code></pre>"},{"location":"how-to-guides/stream-large-files/#streaming-with-different-backends","title":"Streaming with Different Backends","text":""},{"location":"how-to-guides/stream-large-files/#niquests-recommended","title":"niquests (Recommended)","text":"<pre><code>results = fastreq(\n    urls=[\"https://example.com/large-file.zip\"],\n    backend=\"niquests\",\n    return_type=\"stream\",\n    stream_callback=lambda r, u: save_stream(r, u),\n)\n</code></pre>"},{"location":"how-to-guides/stream-large-files/#aiohttp","title":"aiohttp","text":"<pre><code>results = fastreq(\n    urls=[\"https://example.com/large-file.zip\"],\n    backend=\"aiohttp\",\n    return_type=\"stream\",\n    stream_callback=lambda r, u: save_stream(r, u),\n)\n</code></pre>"},{"location":"how-to-guides/stream-large-files/#requests","title":"requests","text":"<pre><code>results = fastreq(\n    urls=[\"https://example.com/large-file.zip\"],\n    backend=\"requests\",\n    return_type=\"stream\",\n    stream_callback=lambda r, u: save_stream(r, u),\n)\n</code></pre>"},{"location":"how-to-guides/stream-large-files/#best-practices","title":"Best Practices","text":"<ol> <li> <p>Use Appropriate Chunk Sizes: 8KB - 64KB is typical    <pre><code>response.iter_content(chunk_size=8192)  # 8 KB\n</code></pre></p> </li> <li> <p>Check Content-Length: Get file size for progress tracking    <pre><code>total_size = int(response.headers.get('content-length', 0))\n</code></pre></p> </li> <li> <p>Handle Empty Chunks: Filter out keep-alive chunks    <pre><code>for chunk in response.iter_content():\n    if chunk:  # Filter out keep-alive chunks\n        f.write(chunk)\n</code></pre></p> </li> <li> <p>Use Streaming for Large Files: Only use streaming for files &gt; 1MB    <pre><code>return_type=\"stream\"  # For large files\nreturn_type=\"content\"  # For small files\n</code></pre></p> </li> <li> <p>Close Resources: Always close file handles    <pre><code>with open(filename, \"wb\") as f:\n    for chunk in response.iter_content():\n        f.write(chunk)\n</code></pre></p> </li> </ol>"},{"location":"how-to-guides/stream-large-files/#see-also","title":"See Also","text":"<ul> <li>Make Parallel Requests - Basic request configuration</li> <li>Limit Request Rate - Control download rate</li> <li>API Reference - Configuration options</li> </ul>"},{"location":"how-to-guides/use-proxies/","title":"Use Proxies","text":"<p>Learn how to configure proxy rotation and integrate with proxy providers.</p>"},{"location":"how-to-guides/use-proxies/#setting-up-proxies","title":"Setting Up Proxies","text":"<p>Proxies can be configured via environment variable or code:</p>"},{"location":"how-to-guides/use-proxies/#using-environment-variables","title":"Using Environment Variables","text":"<p>Set the <code>PARALLEL_REQUESTS_PROXIES</code> environment variable:</p> <pre><code>export PARALLEL_REQUESTS_PROXIES=\"http://proxy1:8080,http://proxy2:8080,socks5://proxy3:1080\"\n</code></pre>"},{"location":"how-to-guides/use-proxies/#using-env-file","title":"Using .env File","text":"<p>Create a <code>.env</code> file:</p> <pre><code># .env\nPARALLEL_REQUESTS_PROXIES=http://proxy1:8080,http://proxy2:8080,socks5://proxy3:1080\n</code></pre> <p>Load with python-dotenv:</p> <pre><code>from dotenv import load_dotenv\nfrom fastreq import fastreq\n\nload_dotenv()\n\nresults = fastreq(\n    urls=[\"https://httpbin.org/ip\"] * 5,\n)\n</code></pre>"},{"location":"how-to-guides/use-proxies/#using-code-configuration","title":"Using Code Configuration","text":"<p>Pass <code>proxies</code> directly:</p> <pre><code>from fastreq import fastreq\n\nproxies = [\n    \"http://proxy1.example.com:8080\",\n    \"http://proxy2.example.com:8080\",\n    \"socks5://proxy3.example.com:1080\",\n]\n\nresults = fastreq(\n    urls=[\"https://httpbin.org/ip\"] * 10,\n    proxies=proxies,\n)\n</code></pre>"},{"location":"how-to-guides/use-proxies/#proxy-rotation","title":"Proxy Rotation","text":"<p>The library automatically rotates through the proxy list:</p> <pre><code>from fastreq import fastreq\n\nproxies = [\n    \"http://proxy1:8080\",\n    \"http://proxy2:8080\",\n    \"http://proxy3:8080\",\n]\n\nresults = fastreq(\n    urls=[\"https://httpbin.org/ip\"] * 9,\n    proxies=proxies,\n)\n\n# Requests are distributed across proxies\n# proxy1: requests 1, 4, 7\n# proxy2: requests 2, 5, 8\n# proxy3: requests 3, 6, 9\n</code></pre>"},{"location":"how-to-guides/use-proxies/#webshareio-integration","title":"WebShare.io Integration","text":"<p>Use WebShare.io rotating proxies:</p> <pre><code>import os\nfrom fastreq import fastreq\n\n# Set WebShare.io proxy (or use environment variable)\nwebshare_proxy = f\"http://{os.getenv('WEBSHARE_USERNAME')}:{os.getenv('WEBSHARE_PASSWORD')}@p.webshare.io:80\"\n\nresults = fastreq(\n    urls=[\"https://httpbin.org/ip\"] * 10,\n    proxies=[webshare_proxy],\n)\n</code></pre>"},{"location":"how-to-guides/use-proxies/#webshareio-in-env-file","title":"WebShare.io in .env File","text":"<pre><code># .env\nWEBSHARE_USERNAME=your_username\nWEBSHARE_PASSWORD=your_password\nPARALLEL_REQUESTS_PROXIES=http://${WEBSHARE_USERNAME}:${WEBSHARE_PASSWORD}@p.webshare.io:80\n</code></pre>"},{"location":"how-to-guides/use-proxies/#verifying-proxy-usage","title":"Verifying Proxy Usage","text":"<p>Use httpbin.org to verify which proxy was used:</p> <pre><code>from fastreq import fastreq\n\nproxies = [\n    \"http://proxy1.example.com:8080\",\n    \"http://proxy2.example.com:8080\",\n]\n\nresults = fastreq(\n    urls=[\"https://httpbin.org/ip\"] * 6,\n    proxies=proxies,\n)\n\nfor result in results:\n    print(f\"IP: {result['origin']}\")\n</code></pre>"},{"location":"how-to-guides/use-proxies/#proxy-authentication","title":"Proxy Authentication","text":"<p>Use authenticated proxies:</p> <pre><code>from fastreq import fastreq\n\nproxies = [\n    \"http://user:pass@proxy1.example.com:8080\",\n    \"http://user:pass@proxy2.example.com:8080\",\n]\n\nresults = fastreq(\n    urls=[\"https://httpbin.org/ip\"] * 5,\n    proxies=proxies,\n)\n</code></pre> <p>Security Note: Avoid hardcoding credentials. Use environment variables instead:</p> <pre><code>import os\nfrom fastreq import fastreq\n\nproxies = [\n    f\"http://{os.getenv('PROXY_USER')}:{os.getenv('PROXY_PASS')}@proxy1:8080\",\n]\n\nresults = fastreq(\n    urls=[\"https://httpbin.org/ip\"] * 5,\n    proxies=proxies,\n)\n</code></pre>"},{"location":"how-to-guides/use-proxies/#different-proxy-types","title":"Different Proxy Types","text":"<p>The library supports HTTP, HTTPS, and SOCKS5 proxies:</p> <pre><code>from fastreq import fastreq\n\nproxies = [\n    \"http://proxy.example.com:8080\",      # HTTP proxy\n    \"https://secure-proxy.com:443\",        # HTTPS proxy\n    \"socks5://socks-proxy.com:1080\",      # SOCKS5 proxy\n]\n\nresults = fastreq(\n    urls=[\"https://httpbin.org/ip\"] * 6,\n    proxies=proxies,\n)\n</code></pre>"},{"location":"how-to-guides/use-proxies/#proxy-specific-urls","title":"Proxy-Specific URLs","text":"<p>Route specific URLs through different proxies:</p> <pre><code>from fastreq import fastreq\n\nresults = fastreq(\n    urls=[\n        \"https://api.github.com/repos/python/cpython\",\n        \"https://api.github.com/repos/python/pypy\",\n    ],\n    proxies=[\n        \"http://proxy-github:8080\",  # First URL\n        \"http://proxy-github:8080\",  # Second URL\n    ],\n)\n</code></pre>"},{"location":"how-to-guides/use-proxies/#no-proxy-configuration","title":"No Proxy Configuration","text":"<p>To bypass proxy for specific domains:</p> <pre><code>import os\nos.environ['NO_PROXY'] = 'localhost,127.0.0.1,.local'\n\nfrom fastreq import fastreq\n\nresults = fastreq(\n    urls=[\"https://httpbin.org/ip\"],\n)\n</code></pre>"},{"location":"how-to-guides/use-proxies/#troubleshooting-proxy-issues","title":"Troubleshooting Proxy Issues","text":""},{"location":"how-to-guides/use-proxies/#test-proxy-connectivity","title":"Test Proxy Connectivity","text":"<p>Test if a proxy works:</p> <pre><code>import requests\n\ntry:\n    response = requests.get(\n        \"https://httpbin.org/ip\",\n        proxies={\"http\": \"http://proxy.example.com:8080\"},\n        timeout=10,\n    )\n    print(f\"Proxy working: {response.json()['origin']}\")\nexcept Exception as e:\n    print(f\"Proxy failed: {e}\")\n</code></pre>"},{"location":"how-to-guides/use-proxies/#enable-debug-logging","title":"Enable Debug Logging","text":"<p>See which proxy is being used:</p> <pre><code>from fastreq import fastreq\n\nresults = fastreq(\n    urls=[\"https://httpbin.org/ip\"] * 3,\n    proxies=[\"http://proxy1:8080\", \"http://proxy2:8080\"],\n    debug=True,\n)\n</code></pre>"},{"location":"how-to-guides/use-proxies/#common-proxy-errors","title":"Common Proxy Errors","text":"<pre><code>from fastreq import fastreq, ProxyError\n\ntry:\n    results = fastreq(\n        urls=[\"https://httpbin.org/ip\"],\n        proxies=[\"http://invalid-proxy:8080\"],\n    )\nexcept ProxyError as e:\n    print(f\"Proxy error: {e}\")\n    # Check proxy address, port, and authentication\n</code></pre>"},{"location":"how-to-guides/use-proxies/#free-proxies-experimental","title":"Free Proxies (Experimental)","text":"<p>The library has experimental support for fetching free proxies, but this feature is not fully implemented yet.</p> <pre><code>from fastreq import fastreq\n\n# This is experimental and may not work\nresults = fastreq(\n    urls=[\"https://httpbin.org/ip\"] * 5,\n    use_free_proxies=True,  # Experimental\n)\n</code></pre> <p>Warning: Free proxies are unreliable and slow. Use a paid proxy service like WebShare.io for production use.</p>"},{"location":"how-to-guides/use-proxies/#best-practices","title":"Best Practices","text":"<ol> <li>Use Environment Variables: Store proxy URLs in <code>.env</code> files</li> <li>Monitor Proxy Health: Check proxy status before large batches</li> <li>Handle Failures: Use <code>return_none_on_failure</code> for unreliable proxies</li> <li>Rotate Properly: Use enough proxies to distribute load</li> <li>Use Paid Services: Free proxies are unreliable for production</li> </ol>"},{"location":"how-to-guides/use-proxies/#example-robust-proxy-configuration","title":"Example: Robust Proxy Configuration","text":"<pre><code>import os\nfrom dotenv import load_dotenv\nfrom fastreq import fastreq\n\nload_dotenv()\n\n# Load proxies from environment\nproxies_str = os.getenv(\"PARALLEL_REQUESTS_PROXIES\", \"\")\nproxies = [p.strip() for p in proxies_str.split(\",\") if p.strip()]\n\n# Add authenticated proxy if configured\nwebshare_user = os.getenv(\"WEBSHARE_USERNAME\")\nwebshare_pass = os.getenv(\"WEBSHARE_PASSWORD\")\nif webshare_user and webshare_pass:\n    webshare_proxy = f\"http://{webshare_user}:{webshare_pass}@p.webshare.io:80\"\n    proxies.append(webshare_proxy)\n\n# Make requests with fallback\nresults = fastreq(\n    urls=[\"https://httpbin.org/ip\"] * 10,\n    proxies=proxies if proxies else None,\n    max_retries=2,\n    return_none_on_failure=True,\n    debug=True,\n)\n\n# Filter successful results\nsuccessful = [r for r in results if r is not None]\nprint(f\"Successful requests: {len(successful)}/{len(results)}\")\n</code></pre>"},{"location":"how-to-guides/use-proxies/#see-also","title":"See Also","text":"<ul> <li>Debug Issues - Troubleshoot proxy problems</li> <li>Handle Retries - Configure retry logic for unreliable proxies</li> <li>API Reference - Configuration options</li> </ul>"},{"location":"reference/","title":"Reference","text":"<p>Complete API reference and technical documentation for fastreq.</p>"},{"location":"reference/#core-api","title":"Core API","text":"<p>Auto-generated API documentation using mkdocstrings:</p> <ul> <li>ParallelRequests Class - Main client class</li> <li>fastreq() - Synchronous convenience function</li> <li>fastreq_async() - Async convenience function</li> <li>ReturnType - Response parsing options</li> <li>GlobalConfig - Global configuration</li> </ul>"},{"location":"reference/#key-components","title":"Key Components","text":"<ul> <li>Return Types - JSON, TEXT, CONTENT, RESPONSE, STREAM</li> <li>Configuration - Client parameters and environment variables</li> <li>Exceptions - Exception hierarchy and error handling</li> <li>Backend Interface - Backend abstraction and dataclasses</li> </ul>"},{"location":"reference/#features","title":"Features","text":"<ul> <li>Rate Limiting - Token bucket algorithm</li> <li>Retry Strategy - Exponential backoff with jitter</li> <li>Proxy Rotation - Proxy management and validation</li> <li>Header Management - User-agent rotation</li> <li>Validation - Input validation functions</li> </ul>"},{"location":"reference/backend/","title":"Backend Interface","text":"<p>The backend abstraction provides a consistent interface across different HTTP client libraries.</p>"},{"location":"reference/backend/#backend-base-class","title":"Backend Base Class","text":"<p>All backends must inherit from <code>Backend</code> and implement its abstract methods.</p> <pre><code>from fastreq.backends.base import Backend\n\nclass CustomBackend(Backend):\n    @property\n    def name(self) -&gt; str:\n        return \"custom\"\n\n    async def request(self, config: RequestConfig) -&gt; NormalizedResponse:\n        # Implementation\n        pass\n\n    async def close(self) -&gt; None:\n        # Cleanup\n        pass\n\n    async def __aenter__(self) -&gt; \"Backend\":\n        return self\n\n    async def __aexit__(self, *args: Any) -&gt; None:\n        await self.close()\n\n    def supports_http2(self) -&gt; bool:\n        return False\n</code></pre>"},{"location":"reference/backend/#backend-methods","title":"Backend Methods","text":"Method Return Type Description <code>name</code> <code>str</code> Backend identifier <code>request()</code> <code>NormalizedResponse</code> Execute HTTP request <code>close()</code> <code>None</code> Clean up resources <code>__aenter__()</code> <code>Backend</code> Initialize backend <code>__aexit__()</code> <code>None</code> Cleanup on exit <code>supports_http2()</code> <code>bool</code> HTTP/2 support"},{"location":"reference/backend/#requestconfig","title":"RequestConfig","text":"<p>Configuration for a single HTTP request. Used internally by backends.</p> <pre><code>from fastreq.backends.base import RequestConfig\n\nconfig = RequestConfig(\n    url=\"https://example.com\",\n    method=\"GET\",\n    params={\"key\": \"value\"},\n    data=b\"raw data\",\n    json={\"key\": \"value\"},\n    headers={\"Authorization\": \"Bearer token\"},\n    cookies={\"session\": \"abc123\"},\n    timeout=30.0,\n    proxy=\"http://proxy:8080\",\n    http2=True,\n    stream=False,\n    follow_redirects=True,\n    verify_ssl=True,\n)\n</code></pre>"},{"location":"reference/backend/#requestconfig-attributes","title":"RequestConfig Attributes","text":"Attribute Type Default Description <code>url</code> <code>str</code> required Request URL <code>method</code> <code>str</code> <code>\"GET\"</code> HTTP method <code>params</code> <code>dict[str, Any] \\| None</code> <code>None</code> Query parameters <code>data</code> <code>Any</code> <code>None</code> Request body data <code>json</code> <code>Any</code> <code>None</code> JSON body <code>headers</code> <code>dict[str, str] \\| None</code> <code>None</code> Request headers <code>cookies</code> <code>dict[str, str] \\| None</code> <code>None</code> Request cookies <code>timeout</code> <code>float \\| None</code> <code>None</code> Timeout in seconds <code>proxy</code> <code>str \\| None</code> <code>None</code> Proxy URL <code>http2</code> <code>bool</code> <code>True</code> Enable HTTP/2 <code>stream</code> <code>bool</code> <code>False</code> Enable streaming <code>follow_redirects</code> <code>bool</code> <code>True</code> Follow redirects <code>verify_ssl</code> <code>bool</code> <code>True</code> Verify SSL"},{"location":"reference/backend/#normalizedresponse","title":"NormalizedResponse","text":"<p>Normalized response from HTTP backends with a consistent interface.</p> <pre><code>from fastreq.backends.base import NormalizedResponse\n\nresponse = NormalizedResponse(\n    status_code=200,\n    headers={\"content-type\": \"application/json\"},\n    content=b'{\"key\": \"value\"}',\n    text='{\"key\": \"value\"}',\n    json_data={\"key\": \"value\"},\n    url=\"https://example.com\",\n    is_json=True,\n)\n</code></pre>"},{"location":"reference/backend/#normalizedresponse-attributes","title":"NormalizedResponse Attributes","text":"Attribute Type Description <code>status_code</code> <code>int</code> HTTP status code <code>headers</code> <code>dict[str, str]</code> Response headers (lowercase keys) <code>content</code> <code>bytes</code> Raw response body <code>text</code> <code>str</code> Decoded response body <code>json_data</code> <code>Any</code> Parsed JSON data <code>url</code> <code>str</code> Final URL (after redirects) <code>is_json</code> <code>bool</code> Whether response is valid JSON"},{"location":"reference/backend/#normalizedresponse-methods","title":"NormalizedResponse Methods","text":""},{"location":"reference/backend/#from_backend","title":"from_backend()","text":"<p>Create <code>NormalizedResponse</code> from backend response.</p> <pre><code>response = NormalizedResponse.from_backend(\n    status_code=200,\n    headers={\"Content-Type\": \"application/json\"},\n    content=b'{\"key\": \"value\"}',\n    url=\"https://example.com\",\n    is_json=True,\n)\n</code></pre>"},{"location":"reference/backend/#_normalize_headers","title":"_normalize_headers()","text":"<p>Normalize headers by converting all keys to lowercase.</p> <pre><code>headers = NormalizedResponse._normalize_headers({\n    \"Content-Type\": \"application/json\",\n    \"Authorization\": \"Bearer token\"\n})\n# Returns: {'content-type': '...', 'authorization': '...'}\n</code></pre>"},{"location":"reference/backend/#backend-implementations","title":"Backend Implementations","text":""},{"location":"reference/backend/#available-backends","title":"Available Backends","text":"Backend HTTP/2 Description <code>niquests</code> \u2705 Recommended,\u9ad8\u6027\u80fd <code>aiohttp</code> \u2705 Native async <code>requests</code> \u274c Synchronous"},{"location":"reference/backend/#using-backends","title":"Using Backends","text":"<pre><code># Auto-select (recommended)\nclient = ParallelRequests(backend=\"auto\")\n\n# Specific backend\nclient = ParallelRequests(backend=\"niquests\")\n</code></pre>"},{"location":"reference/backend/#backend-initialization","title":"Backend Initialization","text":"<p>Backends are initialized with HTTP/2 configuration:</p> <pre><code>from fastreq.backends.niquests import NiquestsBackend\n\nbackend = NiquestsBackend(http2_enabled=True)\n\nasync with backend:\n    response = await backend.request(config)\n</code></pre>"},{"location":"reference/backend/#custom-backend-implementation","title":"Custom Backend Implementation","text":"<p>Create a custom backend:</p> <pre><code>from fastreq.backends.base import Backend, RequestConfig, NormalizedResponse\nimport httpx\n\nclass HttpxBackend(Backend):\n    def __init__(self, http2_enabled: bool = True):\n        super().__init__(http2_enabled)\n        self._client = None\n\n    @property\n    def name(self) -&gt; str:\n        return \"httpx\"\n\n    async def __aenter__(self) -&gt; \"Backend\":\n        self._client = httpx.AsyncClient(http2=self._http2_enabled)\n        return self\n\n    async def __aexit__(self, *args: Any) -&gt; None:\n        if self._client:\n            await self._client.aclose()\n\n    async def close(self) -&gt; None:\n        if self._client:\n            await self._client.aclose()\n\n    async def request(self, config: RequestConfig) -&gt; NormalizedResponse:\n        if not self._client:\n            raise RuntimeError(\"Backend not initialized\")\n\n        response = await self._client.request(\n            method=config.method,\n            url=config.url,\n            params=config.params,\n            data=config.data,\n            json=config.json,\n            headers=config.headers,\n            cookies=config.cookies,\n            timeout=config.timeout,\n            proxy=config.proxy,\n            follow_redirects=config.follow_redirects,\n            verify=config.verify_ssl,\n        )\n\n        return NormalizedResponse(\n            status_code=response.status_code,\n            headers=dict(response.headers),\n            content=response.content,\n            url=str(response.url),\n            is_json=response.headers.get(\"content-type\", \"\").startswith(\"application/json\"),\n        )\n\n    def supports_http2(self) -&gt; bool:\n        return True\n</code></pre>"},{"location":"reference/backend/#see-also","title":"See Also","text":"<ul> <li>How-to: Select a Backend</li> </ul>"},{"location":"reference/configuration/","title":"Configuration","text":"<p>Configure fastreq using client parameters, environment variables, or global config.</p>"},{"location":"reference/configuration/#fastrequests-parameters","title":"FastRequests Parameters","text":"<p>Configure the <code>FastRequests</code> client with these parameters:</p> <pre><code>from fastreq import FastRequests\n\nclient = FastRequests(\n    backend=\"auto\",\n    concurrency=20,\n    max_retries=3,\n    rate_limit=10.0,\n    rate_limit_burst=5,\n    http2=True,\n    follow_redirects=True,\n    verify_ssl=True,\n    timeout=30.0,\n    cookies={\"session\": \"abc123\"},\n    random_user_agent=True,\n    random_proxy=False,\n    debug=False,\n    verbose=True,\n    return_none_on_failure=False,\n)\n</code></pre>"},{"location":"reference/configuration/#parameters","title":"Parameters","text":"Parameter Type Default Description <code>backend</code> <code>str</code> <code>\"auto\"</code> Backend to use: <code>\"auto\"</code>, <code>\"niquests\"</code>, <code>\"aiohttp\"</code>, or <code>\"requests\"</code> <code>concurrency</code> <code>int</code> <code>20</code> Maximum concurrent requests <code>max_retries</code> <code>int</code> <code>3</code> Maximum retry attempts per request <code>rate_limit</code> <code>float \\| None</code> <code>None</code> Requests per second (None = no limit) <code>rate_limit_burst</code> <code>int</code> <code>5</code> Burst size for rate limiter <code>http2</code> <code>bool</code> <code>True</code> Enable HTTP/2 (if supported by backend) <code>follow_redirects</code> <code>bool</code> <code>True</code> Follow HTTP redirects <code>verify_ssl</code> <code>bool</code> <code>True</code> Verify SSL certificates <code>timeout</code> <code>float \\| None</code> <code>None</code> Default timeout per request (seconds) <code>cookies</code> <code>dict[str, str] \\| None</code> <code>None</code> Initial session cookies <code>random_user_agent</code> <code>bool</code> <code>True</code> Rotate user agents <code>random_proxy</code> <code>bool</code> <code>False</code> Enable proxy rotation <code>debug</code> <code>bool</code> <code>False</code> Enable debug logging <code>verbose</code> <code>bool</code> <code>True</code> Enable verbose output <code>return_none_on_failure</code> <code>bool</code> <code>False</code> Return None on failure instead of raising"},{"location":"reference/configuration/#request-level-overrides","title":"Request-Level Overrides","text":"<p>Override client settings per request:</p> <pre><code>async with FastRequests(\n    timeout=30,\n    follow_redirects=True\n) as client:\n    # Override timeout for this request\n    result1 = await client.request(\n        \"https://example.com/1\",\n        timeout=60\n    )\n\n    # Override follow_redirects for this request\n    result2 = await client.request(\n        \"https://example.com/2\",\n        follow_redirects=False\n    )\n</code></pre> <p>Overrideable parameters: - <code>timeout</code> - <code>follow_redirects</code> - <code>verify_ssl</code></p>"},{"location":"reference/configuration/#environment-variables","title":"Environment Variables","text":"<p>Set defaults using environment variables:</p> Variable Type Default Description <code>PARALLEL_BACKEND</code> <code>str</code> <code>\"auto\"</code> Default backend selection <code>PARALLEL_CONCURRENCY</code> <code>int</code> <code>20</code> Default concurrency limit <code>PARALLEL_MAX_RETRIES</code> <code>int</code> <code>3</code> Default max retries <code>PARALLEL_RATE_LIMIT</code> <code>float \\| None</code> <code>None</code> Default rate limit (requests/sec) <code>PARALLEL_RATE_LIMIT_BURST</code> <code>int</code> <code>5</code> Rate limit burst size <code>PARALLEL_HTTP2</code> <code>bool</code> <code>true</code> Enable HTTP/2 <code>PARALLEL_RANDOM_USER_AGENT</code> <code>bool</code> <code>true</code> Rotate user agents <code>PARALLEL_RANDOM_PROXY</code> <code>bool</code> <code>false</code> Enable proxy rotation <code>PARALLEL_PROXY_ENABLED</code> <code>bool</code> <code>false</code> Enable proxy usage <code>PARALLEL_FREE_PROXIES</code> <code>bool</code> <code>false</code> Enable free proxy fetching"},{"location":"reference/configuration/#using-environment-variables","title":"Using Environment Variables","text":"<p>Create a <code>.env</code> file:</p> <pre><code># .env\nPARALLEL_BACKEND=niquests\nPARALLEL_CONCURRENCY=10\nPARALLEL_RATE_LIMIT=5.0\nPARALLEL_RATE_LIMIT_BURST=3\nPARALLEL_DEBUG=false\n</code></pre> <p>Load in your application:</p> <pre><code>from dotenv import load_dotenv\nfrom fastreq.config import GlobalConfig\n\nload_dotenv()\nconfig = GlobalConfig.load_from_env()\n</code></pre>"},{"location":"reference/configuration/#globalconfig","title":"GlobalConfig","text":"<p>Use <code>GlobalConfig</code> for programmatic configuration:</p> <pre><code>from fastreq.config import GlobalConfig\n\n# Create config programmatically\nconfig = GlobalConfig(\n    backend=\"niquests\",\n    default_concurrency=10,\n    rate_limit=5.0,\n)\n\n# Load from environment\nconfig = GlobalConfig.load_from_env()\n\n# Save to environment file\nconfig.save_to_env(\".env\")\n\n# Convert to dict\nenv_dict = config.to_env()\n</code></pre>"},{"location":"reference/configuration/#globalconfig-attributes","title":"GlobalConfig Attributes","text":"Attribute Type Default <code>backend</code> <code>str</code> <code>\"auto\"</code> <code>default_concurrency</code> <code>int</code> <code>20</code> <code>default_max_retries</code> <code>int</code> <code>3</code> <code>rate_limit</code> <code>float \\| None</code> <code>None</code> <code>rate_limit_burst</code> <code>int</code> <code>5</code> <code>http2_enabled</code> <code>bool</code> <code>True</code> <code>random_user_agent</code> <code>bool</code> <code>True</code> <code>random_proxy</code> <code>bool</code> <code>False</code> <code>proxy_enabled</code> <code>bool</code> <code>False</code> <code>free_proxies_enabled</code> <code>bool</code> <code>False</code>"},{"location":"reference/configuration/#backend-selection","title":"Backend Selection","text":"<p>Choose a backend based on your needs:</p>"},{"location":"reference/configuration/#auto-default","title":"Auto (default)","text":"<p>Automatically selects the best available backend: 1. <code>niquests</code> (if installed) - Recommended 2. <code>aiohttp</code> (if installed) 3. <code>requests</code> (if installed)</p> <pre><code>client = FastRequests(backend=\"auto\")\n</code></pre>"},{"location":"reference/configuration/#niquests-recommended","title":"Niquests (Recommended)","text":"<p>Best performance with HTTP/2 support: <pre><code>client = FastRequests(backend=\"niquests\")\n</code></pre></p> <p>Install: <code>pip install niquests</code></p>"},{"location":"reference/configuration/#aiohttp","title":"Aiohttp","text":"<p>Native async backend: <pre><code>client = FastRequests(backend=\"aiohttp\")\n</code></pre></p> <p>Install: <code>pip install aiohttp</code></p>"},{"location":"reference/configuration/#requests","title":"Requests","text":"<p>Synchronous backend (uses <code>asyncio</code> wrapper): <pre><code>client = FastRequests(backend=\"requests\")\n</code></pre></p> <p>Install: <code>pip install requests</code></p>"},{"location":"reference/configuration/#cookie-management","title":"Cookie Management","text":"<p>Manage session cookies:</p> <pre><code>async with FastRequests(cookies={\"session\": \"abc123\"}) as client:\n    # Add cookies\n    client.set_cookies({\"user_id\": \"456\"})\n\n    # Make request (cookies sent automatically)\n    result = await client.request(\"https://example.com/api\")\n\n    # Clear all cookies\n    client.reset_cookies()\n</code></pre>"},{"location":"reference/configuration/#see-also","title":"See Also","text":"<ul> <li>API Reference: FastRequests</li> <li>API Reference: GlobalConfig</li> <li>How-to: Select a Backend</li> </ul>"},{"location":"reference/exceptions/","title":"Exceptions","text":"<p>All fastreq exceptions inherit from <code>ParallelRequestsError</code>.</p>"},{"location":"reference/exceptions/#exception-hierarchy","title":"Exception Hierarchy","text":"<pre><code>ParallelRequestsError\n\u251c\u2500\u2500 BackendError\n\u251c\u2500\u2500 ProxyError\n\u251c\u2500\u2500 RetryExhaustedError\n\u251c\u2500\u2500 RateLimitExceededError\n\u251c\u2500\u2500 ValidationError\n\u251c\u2500\u2500 ConfigurationError\n\u2514\u2500\u2500 PartialFailureError\n</code></pre>"},{"location":"reference/exceptions/#exception-types","title":"Exception Types","text":""},{"location":"reference/exceptions/#parallelrequestserror","title":"ParallelRequestsError","text":"<p>Base exception for all fastreq errors.</p> <pre><code>from fastreq.exceptions import ParallelRequestsError\n\ntry:\n    await client.request(url)\nexcept ParallelRequestsError as e:\n    print(f\"Parallel-requests error: {e}\")\n</code></pre>"},{"location":"reference/exceptions/#backenderror","title":"BackendError","text":"<p>Raised when a backend operation fails.</p> <pre><code>from fastreq.exceptions import BackendError\n\ntry:\n    await client.request(url)\nexcept BackendError as e:\n    print(f\"Backend {e.backend_name} failed: {e}\")\n</code></pre> <p>Attributes: - <code>backend_name: str | None</code> - Name of the backend that failed</p> <p>Raised when: - Backend cannot be loaded - Backend encounters an error during request execution</p>"},{"location":"reference/exceptions/#proxyerror","title":"ProxyError","text":"<p>Raised when a proxy operation fails.</p> <pre><code>from fastreq.exceptions import ProxyError\n\ntry:\n    await client.request(url, proxy=\"http://invalid:8080\")\nexcept ProxyError as e:\n    print(f\"Proxy error: {e}\")\n    print(f\"Failed proxy: {e.proxy_url}\")\n</code></pre> <p>Attributes: - <code>proxy_url: str | None</code> - Proxy URL that failed</p> <p>Raised when: - Proxy connection fails - Proxy validation fails - Proxy rotation encounters errors</p>"},{"location":"reference/exceptions/#retryexhaustederror","title":"RetryExhaustedError","text":"<p>Raised when all retry attempts are exhausted.</p> <pre><code>from fastreq.exceptions import RetryExhaustedError\n\ntry:\n    await client.request(url)\nexcept RetryExhaustedError as e:\n    print(f\"Retries exhausted after {e.attempts} attempts\")\n    print(f\"Last error: {e.last_error}\")\n    print(f\"Failed URL: {e.url}\")\n</code></pre> <p>Attributes: - <code>attempts: int</code> - Number of retry attempts made - <code>last_error: Exception | None</code> - Last exception that occurred - <code>url: str | None</code> - URL that failed</p> <p>Raised when: - Request fails after <code>max_retries</code> attempts - Retryable error occurs repeatedly</p>"},{"location":"reference/exceptions/#ratelimitexceedederror","title":"RateLimitExceededError","text":"<p>Raised when rate limit is exceeded.</p> <pre><code>from fastreq.exceptions import RateLimitExceededError\n\ntry:\n    await client.request(url)\nexcept RateLimitExceededError as e:\n    print(f\"Rate limit exceeded\")\n    print(f\"Retry after: {e.retry_after}s\")\n</code></pre> <p>Attributes: - <code>retry_after: float | None</code> - Seconds to wait before retry</p> <p>Raised when: - Rate limiter blocks a request - Concurrent limit is reached</p>"},{"location":"reference/exceptions/#validationerror","title":"ValidationError","text":"<p>Raised when request validation fails.</p> <pre><code>from fastreq.exceptions import ValidationError\n\ntry:\n    validate_url(\"invalid-url\")\nexcept ValidationError as e:\n    print(f\"Validation failed for field '{e.field_name}': {e}\")\n</code></pre> <p>Attributes: - <code>field_name: str | None</code> - Name of the field that failed validation</p> <p>Raised when: - URL format is invalid - Headers are invalid - Parameters have incorrect types</p>"},{"location":"reference/exceptions/#configurationerror","title":"ConfigurationError","text":"<p>Raised when configuration is invalid.</p> <pre><code>from fastreq.exceptions import ConfigurationError\n\ntry:\n    client = ParallelRequests(backend=\"invalid\")\nexcept ConfigurationError as e:\n    print(f\"Configuration error: {e}\")\n    print(f\"Invalid config key: {e.config_key}\")\n</code></pre> <p>Attributes: - <code>config_key: str | None</code> - Name of the configuration key that failed</p> <p>Raised when: - Backend is not found - Configuration parameters are invalid - Backend is not initialized</p>"},{"location":"reference/exceptions/#partialfailureerror","title":"PartialFailureError","text":"<p>Raised when some requests succeed and others fail.</p> <p>Only raised when <code>return_none_on_failure=False</code> (default).</p> <pre><code>from fastreq.exceptions import PartialFailureError\n\ntry:\n    results = await client.request([\n        \"https://example.com/1\",\n        \"https://example.com/2\",\n        \"https://invalid-url\",\n    ])\nexcept PartialFailureError as e:\n    print(f\"Partial failure: {e.successes}/{e.total} succeeded\")\n    print(f\"Failed URLs: {e.get_failed_urls()}\")\n\n    # Inspect individual failures\n    for url, details in e.failures.items():\n        print(f\"{url}: {details.error}\")\n</code></pre> <p>Attributes: - <code>failures: dict[str, FailureDetails]</code> - Dictionary mapping URLs to <code>FailureDetails</code> - <code>successes: int</code> - Number of successful requests - <code>total: int</code> - Total number of requests</p> <p>Methods: - <code>get_failed_urls() -&gt; list[str]</code> - Returns list of URLs that failed</p> <p>Raised when: - Multiple requests are made and some fail - <code>return_none_on_failure=False</code> (default)</p>"},{"location":"reference/exceptions/#failuredetails","title":"FailureDetails","text":"<p>Details about a failed request.</p> <pre><code>@dataclass\nclass FailureDetails:\n    url: str\n    error: Exception\n    attempt: int = 0\n</code></pre> <p>Attributes: - <code>url: str</code> - URL that failed - <code>error: Exception</code> - Exception that occurred - <code>attempt: int</code> - Retry attempt number (0 = first attempt)</p>"},{"location":"reference/exceptions/#handling-failures-gracefully","title":"Handling Failures Gracefully","text":"<p>Use <code>return_none_on_failure=True</code> to avoid raising exceptions:</p> <pre><code>async with ParallelRequests(return_none_on_failure=True) as client:\n    results = await client.request([\n        \"https://example.com/1\",\n        \"https://invalid-url\",\n        \"https://example.com/2\",\n    ])\n\n    # Check for None values\n    for url, result in zip(urls, results):\n        if result is None:\n            print(f\"Request to {url} failed\")\n        else:\n            print(f\"Success: {result}\")\n</code></pre>"},{"location":"reference/exceptions/#see-also","title":"See Also","text":"<ul> <li>API Reference: ParallelRequests</li> <li>How-to: Handle Errors</li> <li>How-to: Debug Issues</li> </ul>"},{"location":"reference/header-management/","title":"Header Management","text":"<p>Manage HTTP headers with automatic user-agent rotation.</p>"},{"location":"reference/header-management/#headermanager","title":"HeaderManager","text":"<p>Main header manager class for automatic user-agent rotation.</p> <pre><code>from fastreq.utils.headers import HeaderManager\n\nmanager = HeaderManager(\n    random_user_agent=True,\n    user_agents=[\"Custom UA 1\", \"Custom UA 2\"],\n)\n\n# Get headers with random user-agent\nheaders = manager.get_headers({\"Authorization\": \"Bearer token\"})\nprint(headers[\"user-agent\"])  # Random from list\n</code></pre>"},{"location":"reference/header-management/#headermanager-methods","title":"HeaderManager Methods","text":"Method Return Type Description <code>get_headers(custom_headers)</code> <code>Dict[str, str]</code> Get headers with user-agent <code>update_agents_from_remote(url)</code> <code>None</code> Update user agents from URL <code>set_custom_user_agent(ua)</code> <code>None</code> Set fixed custom user-agent <code>get_user_agents()</code> <code>List[str]</code> Get current user agent list"},{"location":"reference/header-management/#headermanager-initialization","title":"HeaderManager Initialization","text":"<pre><code>from fastreq.utils.headers import HeaderManager\n\n# Default user-agent rotation\nmanager = HeaderManager(random_user_agent=True)\n\n# Custom user agents\nmanager = HeaderManager(\n    random_user_agent=True,\n    user_agents=[\"Custom UA 1\", \"Custom UA 2\"],\n)\n\n# Fixed user-agent (no rotation)\nmanager = HeaderManager(\n    random_user_agent=True,\n    custom_user_agent=\"MyBot/1.0\",\n)\n\n# Disable user-agent rotation\nmanager = HeaderManager(random_user_agent=False)\n</code></pre>"},{"location":"reference/header-management/#parameters","title":"Parameters","text":"Parameter Type Default Description <code>random_user_agent</code> <code>bool</code> <code>True</code> Enable random user-agent selection <code>user_agents</code> <code>List[str] \\| None</code> <code>None</code> Custom user agent list <code>custom_user_agent</code> <code>str \\| None</code> <code>None</code> Fixed user agent (overrides rotation)"},{"location":"reference/header-management/#user-agent-sources","title":"User Agent Sources","text":"<p>User agents are loaded in priority order:</p> <ol> <li>Custom user agent (set via <code>set_custom_user_agent</code>)</li> <li>Provided user_agents list (constructor parameter)</li> <li>USER_AGENTS environment variable (comma-separated)</li> <li>USER_AGENTS_URL environment variable (fetch from URL)</li> <li>Default user agents (built-in list)</li> </ol>"},{"location":"reference/header-management/#example-priority","title":"Example Priority","text":"<pre><code>import os\n\n# Set environment\nos.environ[\"USER_AGENTS\"] = \"Env UA 1,Env UA 2\"\n\n# Create manager\nmanager = HeaderManager(\n    user_agents=[\"Custom UA\"],  # Priority 2\n    random_user_agent=True,\n)\n\n# Gets random from \"Custom UA\" (priority 2 &gt; priority 3 env)\nheaders = manager.get_headers()\n\n# Set custom UA (priority 1)\nmanager.set_custom_user_agent(\"Fixed UA\")\n\n# Now always uses \"Fixed UA\"\nheaders = manager.get_headers()\n</code></pre>"},{"location":"reference/header-management/#default-user-agents","title":"Default User Agents","text":"<p>Built-in user agents covering major browsers and platforms:</p> <pre><code>DEFAULT_USER_AGENTS = [\n    \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36\",\n    \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36\",\n    \"Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:121.0) Gecko/20100101 Firefox/121.0\",\n    \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/17.2 Safari/605.1.15\",\n    \"Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36\",\n    \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/119.0.0.0 Safari/537.36 Edg/119.0.0.0\",\n    \"Mozilla/5.0 (iPhone; CPU iPhone OS 17_2 like Mac OS X) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/17.2 Mobile/15E148 Safari/604.1\",\n    \"Mozilla/5.0 (iPad; CPU OS 17_2 like Mac OS X) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/17.2 Mobile/15E148 Safari/604.1\",\n]\n</code></pre>"},{"location":"reference/header-management/#coverage","title":"Coverage","text":"<ul> <li>Desktop: Chrome (Windows, Mac, Linux), Firefox, Edge, Safari</li> <li>Mobile: iPhone, iPad</li> <li>OS: Windows 10, macOS 10.15+, Linux</li> </ul>"},{"location":"reference/header-management/#using-headers","title":"Using Headers","text":""},{"location":"reference/header-management/#get-headers-with-user-agent","title":"Get Headers with User-Agent","text":"<pre><code>manager = HeaderManager(random_user_agent=True)\n\n# Get headers with random user-agent\nheaders = manager.get_headers()\n# {\"user-agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) ...\"}\n\n# Get headers with custom headers\nheaders = manager.get_headers({\n    \"Authorization\": \"Bearer token\",\n    \"Content-Type\": \"application/json\",\n})\n# {\n#   \"user-agent\": \"Mozilla/5.0 ...\",\n#   \"authorization\": \"Bearer token\",\n#   \"content-type\": \"application/json\"\n# }\n</code></pre>"},{"location":"reference/header-management/#disable-user-agent","title":"Disable User-Agent","text":"<pre><code>manager = HeaderManager(random_user_agent=False)\n\n# No user-agent header\nheaders = manager.get_headers()\n# {}\n</code></pre>"},{"location":"reference/header-management/#fixed-user-agent","title":"Fixed User-Agent","text":"<pre><code>manager = HeaderManager(\n    random_user_agent=True,\n    custom_user_agent=\"MyBot/1.0\",\n)\n\n# Always uses fixed user-agent\nheaders = manager.get_headers()\n# {\"user-agent\": \"MyBot/1.0\"}\n</code></pre>"},{"location":"reference/header-management/#custom-user-agents","title":"Custom User Agents","text":""},{"location":"reference/header-management/#set-custom-list","title":"Set Custom List","text":"<pre><code>manager = HeaderManager(\n    random_user_agent=True,\n    user_agents=[\n        \"MyBot/1.0\",\n        \"MyBot/2.0\",\n        \"MyBot/3.0\",\n    ],\n)\n\nfor _ in range(3):\n    headers = manager.get_headers()\n    print(headers[\"user-agent\"])\n# Output: Random from MyBot/1.0, MyBot/2.0, MyBot/3.0\n</code></pre>"},{"location":"reference/header-management/#load-from-environment","title":"Load from Environment","text":"<pre><code># .env\nUSER_AGENTS=Bot1/1.0,Bot2/1.0,Bot3/1.0\n</code></pre> <pre><code>import os\nfrom dotenv import load_dotenv\n\nload_dotenv()\n\nmanager = HeaderManager(random_user_agent=True)\n# Loads from USER_AGENTS env var\n</code></pre>"},{"location":"reference/header-management/#load-from-remote-url","title":"Load from Remote URL","text":"<pre><code># .env\nUSER_AGENTS_URL=https://example.com/user-agents.txt\n</code></pre> <pre><code># user-agents.txt\nBot1/1.0\nBot2/1.0\nBot3/1.0\n</code></pre> <pre><code>manager = HeaderManager(random_user_agent=True)\n# Fetches from USER_AGENTS_URL\n</code></pre>"},{"location":"reference/header-management/#updating-user-agents","title":"Updating User Agents","text":""},{"location":"reference/header-management/#update-from-remote","title":"Update from Remote","text":"<pre><code>manager = HeaderManager(random_user_agent=True)\n\n# Fetch new user agents from URL\nmanager.update_agents_from_remote(\"https://example.com/agents.txt\")\n</code></pre> <p>Raises <code>ValueError</code> if fetch fails.</p>"},{"location":"reference/header-management/#set-custom-user-agent","title":"Set Custom User-Agent","text":"<pre><code>manager = HeaderManager(random_user_agent=True)\n\n# Set fixed user-agent (disables rotation)\nmanager.set_custom_user_agent(\"MyBot/1.0\")\n\nheaders = manager.get_headers()\nprint(headers[\"user-agent\"])  # \"MyBot/1.0\"\n</code></pre>"},{"location":"reference/header-management/#get-current-user-agents","title":"Get Current User Agents","text":"<pre><code>manager = HeaderManager(\n    random_user_agent=True,\n    user_agents=[\"UA1\", \"UA2\", \"UA3\"],\n)\n\nagents = manager.get_user_agents()\nprint(agents)  # [\"UA1\", \"UA2\", \"UA3\"]\n</code></pre> <p>Returns a copy of the list.</p>"},{"location":"reference/header-management/#using-in-parallelrequests","title":"Using in ParallelRequests","text":"<pre><code>from fastreq import ParallelRequests\n\n# Built-in user-agent rotation\nclient = ParallelRequests(random_user_agent=True)\n\nasync with client:\n    # User-agent added automatically\n    result = await client.request(\"https://example.com\")\n</code></pre>"},{"location":"reference/header-management/#see-also","title":"See Also","text":"<ul> <li>How-to: Handle Cookies</li> </ul>"},{"location":"reference/proxy-rotation/","title":"Proxy Rotation","text":"<p>Manage, validate, and rotate HTTP proxies with automatic health tracking.</p>"},{"location":"reference/proxy-rotation/#proxymanager","title":"ProxyManager","text":"<p>Main proxy manager class for proxy rotation and validation.</p> <pre><code>from fastreq.utils.proxies import ProxyManager, ProxyConfig\n\nconfig = ProxyConfig(\n    enabled=True,\n    list=[\n        \"192.168.1.1:8080\",\n        \"192.168.1.2:8080:user:pass\",\n    ],\n    retry_delay=60.0,\n    validation_timeout=5.0,\n)\n\nmanager = ProxyManager(config)\n\n# Get next available proxy\nproxy = await manager.get_next()\n\n# Mark proxy as failed\nawait manager.mark_failed(proxy)\n\n# Mark proxy as successful\nawait manager.mark_success(proxy)\n</code></pre>"},{"location":"reference/proxy-rotation/#proxymanager-methods","title":"ProxyManager Methods","text":"Method Return Type Description <code>get_next()</code> <code>Optional[str]</code> Get next available proxy <code>mark_failed(proxy)</code> <code>None</code> Mark proxy as failed <code>mark_success(proxy)</code> <code>None</code> Mark proxy as successful <code>count()</code> <code>int</code> Get total proxy count <code>count_available()</code> <code>int</code> Get available proxy count <code>validate(proxy)</code> <code>bool</code> Validate proxy format (class method)"},{"location":"reference/proxy-rotation/#proxyconfig","title":"ProxyConfig","text":"<p>Configuration for proxy rotation.</p> <pre><code>from fastreq.utils.proxies import ProxyConfig\n\nconfig = ProxyConfig(\n    enabled=True,                      # Enable proxy rotation\n    list=[\"192.168.1.1:8080\"],        # Proxy list\n    webshare_url=\"https://...\",       # Webshare proxy list URL\n    free_proxies=False,               # Fetch free proxies\n    retry_delay=60.0,                 # Seconds before retrying failed proxy\n    validation_timeout=5.0,           # Proxy validation timeout\n)\n</code></pre>"},{"location":"reference/proxy-rotation/#proxyconfig-attributes","title":"ProxyConfig Attributes","text":"Attribute Type Default Description <code>enabled</code> <code>bool</code> <code>False</code> Enable proxy rotation <code>list</code> <code>List[str] \\| None</code> <code>None</code> List of proxy URLs <code>webshare_url</code> <code>str \\| None</code> <code>None</code> Webshare proxy list URL <code>free_proxies</code> <code>bool</code> <code>False</code> Enable free proxy fetching <code>retry_delay</code> <code>float</code> <code>60.0</code> Seconds before retrying failed proxy <code>validation_timeout</code> <code>float</code> <code>5.0</code> Timeout for proxy validation"},{"location":"reference/proxy-rotation/#proxy-formats","title":"Proxy Formats","text":""},{"location":"reference/proxy-rotation/#supported-formats","title":"Supported Formats","text":"<ol> <li> <p>IP:PORT <pre><code>\"192.168.1.1:8080\"\n</code></pre></p> </li> <li> <p>IP:PORT:USER:PASS <pre><code>\"192.168.1.1:8080:admin:password\"\n</code></pre></p> </li> <li> <p>http://USER:PASS@HOST:PORT <pre><code>\"http://user:pass@proxy.example.com:8080\"\n</code></pre></p> </li> <li> <p>https://USER:PASS@HOST:PORT <pre><code>\"https://user:pass@proxy.example.com:8080\"\n</code></pre></p> </li> </ol>"},{"location":"reference/proxy-rotation/#proxy-validation","title":"Proxy Validation","text":"<pre><code>from fastreq.utils.proxies import ProxyManager\n\n# Validate proxy format\nis_valid = ProxyManager.validate(\"192.168.1.1:8080\")  # True\nis_valid = ProxyManager.validate(\"invalid-proxy\")     # False\n</code></pre>"},{"location":"reference/proxy-rotation/#ip-validation","title":"IP Validation","text":"<p>IP octets are validated to be in range 0-255:</p> <pre><code># Valid\n\"192.168.1.1:8080\"    # True\n\n# Invalid\n\"256.168.1.1:8080\"    # False (256 &gt; 255)\n\"192.168.1:8080\"      # False (missing octet)\n</code></pre>"},{"location":"reference/proxy-rotation/#loading-proxies","title":"Loading Proxies","text":""},{"location":"reference/proxy-rotation/#from-configuration","title":"From Configuration","text":"<pre><code>config = ProxyConfig(\n    enabled=True,\n    list=[\n        \"192.168.1.1:8080\",\n        \"192.168.1.2:8080:user:pass\",\n    ],\n)\nmanager = ProxyManager(config)\n</code></pre>"},{"location":"reference/proxy-rotation/#from-environment-variable","title":"From Environment Variable","text":"<pre><code># .env or environment\nPROXIES=192.168.1.1:8080,192.168.1.2:8080,http://user:pass@proxy:8080\n</code></pre> <pre><code>import os\nfrom fastreq.utils.proxies import ProxyConfig\n\nconfig = ProxyConfig(enabled=True)\nmanager = ProxyManager(config)  # Loads from PROXIES env var\n</code></pre>"},{"location":"reference/proxy-rotation/#from-webshare","title":"From Webshare","text":"<pre><code>config = ProxyConfig(\n    enabled=True,\n    webshare_url=\"https://proxy.webshare.io/api/v2/proxy/list\",\n)\nmanager = ProxyManager(config)\n</code></pre> <p>Webshare format: One per line, <code>IP:PORT:USER:PASS</code></p>"},{"location":"reference/proxy-rotation/#proxy-health-tracking","title":"Proxy Health Tracking","text":""},{"location":"reference/proxy-rotation/#failed-proxies","title":"Failed Proxies","text":"<p>Failed proxies are temporarily excluded from rotation:</p> <pre><code>config = ProxyConfig(\n    enabled=True,\n    list=[\"proxy1:8080\", \"proxy2:8080\", \"proxy3:8080\"],\n    retry_delay=60.0,  # Retry failed proxies after 60s\n)\n\nmanager = ProxyManager(config)\n\n# Proxy fails\nproxy = await manager.get_next()  # e.g., \"proxy1:8080\"\nawait manager.mark_failed(proxy)   # Excluded for 60s\n\n# Next request gets different proxy\nnext_proxy = await manager.get_next()  # \"proxy2:8080\" (not proxy1)\n\n# After 60s, proxy1 is available again\n</code></pre>"},{"location":"reference/proxy-rotation/#successful-proxies","title":"Successful Proxies","text":"<p>Successful proxies are cleared from failed state:</p> <pre><code>proxy = await manager.get_next()\n# Make request\ntry:\n    result = await make_request(proxy)\n    await manager.mark_success(proxy)  # Clear failed status\nexcept Exception:\n    await manager.mark_failed(proxy)\n</code></pre>"},{"location":"reference/proxy-rotation/#monitoring","title":"Monitoring","text":"<pre><code># Total proxies\ntotal = manager.count()\n\n# Available proxies (not failed)\navailable = manager.count_available()\n\n# Failed proxies\nfailed = total - available\n</code></pre>"},{"location":"reference/proxy-rotation/#using-proxy-rotation","title":"Using Proxy Rotation","text":""},{"location":"reference/proxy-rotation/#in-parallelrequests-client","title":"In ParallelRequests Client","text":"<pre><code>from fastreq import ParallelRequests\n\n# Enable proxy rotation\nclient = ParallelRequests(\n    random_proxy=True,\n    proxy=\"http://proxy:8080\",  # Base proxy\n)\n</code></pre>"},{"location":"reference/proxy-rotation/#standalone-usage","title":"Standalone Usage","text":"<pre><code>from fastreq.utils.proxies import ProxyManager, ProxyConfig\n\nconfig = ProxyConfig(\n    enabled=True,\n    list=[\"proxy1:8080\", \"proxy2:8080\"],\n)\nmanager = ProxyManager(config)\n\nasync def make_request(url):\n    proxy = await manager.get_next()\n    if not proxy:\n        raise Exception(\"No proxies available\")\n\n    try:\n        response = await fetch(url, proxy=proxy)\n        await manager.mark_success(proxy)\n        return response\n    except Exception as e:\n        await manager.mark_failed(proxy)\n        raise e\n\nresults = await asyncio.gather(*[make_request(url) for url in urls])\n</code></pre>"},{"location":"reference/proxy-rotation/#proxy-validation-patterns","title":"Proxy Validation Patterns","text":"<p>Regex patterns for proxy validation:</p> <pre><code>PROXY_PATTERNS = [\n    r\"^(\\d{1,3}\\.){3}\\d{1,3}:\\d{1,5}$\",                    # IP:PORT\n    r\"^(\\d{1,3}\\.){3}\\d{1,3}:\\d{1,5}:[^:]+:[^:]+$\",        # IP:PORT:USER:PASS\n    r\"^http://[^:]+:[^@]+@[^:]+:\\d+$\",                     # http://user:pass@host:port\n    r\"^https://[^:]+:[^@]+@[^:]+\\d+$\",                     # https://user:pass@host:port\n]\n</code></pre>"},{"location":"reference/proxy-rotation/#proxyvalidationerror","title":"ProxyValidationError","text":"<p>Raised when proxy validation or loading fails:</p> <pre><code>from fastreq.utils.proxies import ProxyValidationError\n\ntry:\n    config = ProxyConfig(webshare_url=\"https://invalid-url\")\n    manager = ProxyManager(config)\nexcept ProxyValidationError as e:\n    print(f\"Proxy validation error: {e}\")\n</code></pre>"},{"location":"reference/proxy-rotation/#see-also","title":"See Also","text":"<ul> <li>How-to: Use Proxies</li> <li>Reference: Exceptions</li> </ul>"},{"location":"reference/rate-limiting/","title":"Rate Limiting","text":"<p>Control request rate using the token bucket algorithm with burst capability.</p>"},{"location":"reference/rate-limiting/#asyncratelimiter","title":"AsyncRateLimiter","text":"<p>Main rate limiter class that combines token bucket rate limiting with semaphore-based concurrency control.</p> <pre><code>from fastreq.utils.rate_limiter import AsyncRateLimiter, RateLimitConfig\n\nconfig = RateLimitConfig(\n    requests_per_second=10,\n    burst=5,\n    max_concurrency=20,\n)\n\nlimiter = AsyncRateLimiter(config)\n\nasync with limiter.acquire():\n    # Make request here\n    pass\n</code></pre>"},{"location":"reference/rate-limiting/#asyncratelimiter-methods","title":"AsyncRateLimiter Methods","text":"Method Return Type Description <code>acquire()</code> <code>AsyncIterator[None]</code> Acquire rate limit token and concurrency slot <code>available()</code> <code>int</code> Get available tokens"},{"location":"reference/rate-limiting/#ratelimitconfig","title":"RateLimitConfig","text":"<p>Configuration for rate limiting.</p> <pre><code>from fastreq.utils.rate_limiter import RateLimitConfig\n\nconfig = RateLimitConfig(\n    requests_per_second=10.0,  # 10 requests per second\n    burst=5,                    # Allow bursts of up to 5\n    max_concurrency=20,         # Max 20 concurrent requests\n)\n</code></pre>"},{"location":"reference/rate-limiting/#ratelimitconfig-attributes","title":"RateLimitConfig Attributes","text":"Attribute Type Description <code>requests_per_second</code> <code>float</code> Token refill rate (requests/sec) <code>burst</code> <code>int</code> Maximum bucket size (tokens) <code>max_concurrency</code> <code>int</code> Maximum concurrent requests"},{"location":"reference/rate-limiting/#tokenbucket","title":"TokenBucket","text":"<p>Implements the token bucket algorithm for rate limiting.</p> <pre><code>from fastreq.utils.rate_limiter import TokenBucket\n\nbucket = TokenBucket(requests_per_second=10, burst=5)\n\n# Get available tokens\ntokens = bucket.available()\nprint(f\"Available: {tokens}\")\n\n# Acquire token (waits if needed)\nawait bucket.acquire()\n</code></pre>"},{"location":"reference/rate-limiting/#tokenbucket-methods","title":"TokenBucket Methods","text":"Method Return Type Description <code>available()</code> <code>int</code> Get available tokens <code>acquire(tokens)</code> <code>None</code> Acquire tokens, waiting if necessary"},{"location":"reference/rate-limiting/#tokenbucket-algorithm","title":"TokenBucket Algorithm","text":"<p>The token bucket algorithm works as follows:</p> <ol> <li>Bucket Size: Maximum number of tokens (<code>burst</code>)</li> <li>Refill Rate: Tokens added per second (<code>requests_per_second</code>)</li> <li>Token Acquisition: Wait if insufficient tokens available</li> </ol> <pre><code>Time 0s:    5 tokens (full bucket)\nTime 0.5s:  Request uses 1 token \u2192 4 tokens remain\n            Refill adds 0.5 * 10 = 5 tokens \u2192 5 tokens (capped at burst)\nTime 1s:    Request uses 3 tokens \u2192 2 tokens remain\n            Refill adds 0.5 * 10 = 5 tokens \u2192 5 tokens (capped at burst)\n</code></pre>"},{"location":"reference/rate-limiting/#refill-formula","title":"Refill Formula","text":"<pre><code>elapsed = current_time - last_update\ntokens = min(burst, tokens + elapsed * requests_per_second)\n</code></pre>"},{"location":"reference/rate-limiting/#using-rate-limiting","title":"Using Rate Limiting","text":""},{"location":"reference/rate-limiting/#in-parallelrequests-client","title":"In ParallelRequests Client","text":"<pre><code>from fastreq import ParallelRequests\n\nclient = ParallelRequests(\n    rate_limit=10.0,      # 10 requests per second\n    rate_limit_burst=5,   # Allow bursts of 5\n    concurrency=20,\n)\n\nasync with client:\n    results = await client.request(urls)\n</code></pre>"},{"location":"reference/rate-limiting/#standalone-usage","title":"Standalone Usage","text":"<pre><code>from fastreq.utils.rate_limiter import AsyncRateLimiter, RateLimitConfig\n\nconfig = RateLimitConfig(requests_per_second=10, burst=5, max_concurrency=20)\nlimiter = AsyncRateLimiter(config)\n\nasync def make_request(url):\n    async with limiter.acquire():\n        # Request is rate-limited\n        response = await fetch(url)\n        return response\n\nresults = await asyncio.gather(*[make_request(url) for url in urls])\n</code></pre>"},{"location":"reference/rate-limiting/#rate-limiting-behavior","title":"Rate Limiting Behavior","text":""},{"location":"reference/rate-limiting/#without-rate-limiting","title":"Without Rate Limiting","text":"<p>Requests execute immediately up to concurrency limit:</p> <pre><code>Time 0.0s:  Request 1 starts\nTime 0.0s:  Request 2 starts\nTime 0.0s:  Request 3 starts\nTime 0.1s:  Request 1 completes, Request 4 starts\n</code></pre>"},{"location":"reference/rate-limiting/#with-rate-limiting-10-reqs-burst5","title":"With Rate Limiting (10 req/s, burst=5)","text":"<p>Requests are throttled:</p> <pre><code>Time 0.0s:  Request 1 starts (tokens: 4)\nTime 0.0s:  Request 2 starts (tokens: 3)\nTime 0.0s:  Request 3 starts (tokens: 2)\nTime 0.0s:  Request 4 starts (tokens: 1)\nTime 0.0s:  Request 5 starts (tokens: 0)\nTime 0.1s:  Request 6 waits for refill (tokens: 0 \u2192 1)\nTime 0.2s:  Request 7 waits for refill (tokens: 0 \u2192 1)\n</code></pre>"},{"location":"reference/rate-limiting/#burst-behavior","title":"Burst Behavior","text":"<p>Burst allows short bursts above average rate:</p> <pre><code>config = RateLimitConfig(requests_per_second=2, burst=5)\n</code></pre> <pre><code>Time 0.0s:  5 requests start immediately (burst)\nTime 0.5s:  Request 6 waits (0.5s * 2 = 1 token available)\nTime 1.0s:  Request 7 waits (0.5s * 2 = 1 token available)\nTime 1.5s:  Request 8 waits (0.5s * 2 = 1 token available)\n</code></pre>"},{"location":"reference/rate-limiting/#concurrency-control","title":"Concurrency Control","text":"<p>The <code>max_concurrency</code> parameter limits simultaneous requests:</p> <pre><code>config = RateLimitConfig(\n    requests_per_second=10,  # Average 10 req/s\n    burst=5,                 # Burst up to 5\n    max_concurrency=3,       # Max 3 concurrent\n)\n</code></pre> <p>Behavior: - Rate limit controls average request rate - Concurrency limit controls simultaneous requests - Both limits must be satisfied</p>"},{"location":"reference/rate-limiting/#monitoring","title":"Monitoring","text":""},{"location":"reference/rate-limiting/#check-available-tokens","title":"Check Available Tokens","text":"<pre><code>async with limiter.acquire():\n    tokens = limiter.available()\n    print(f\"Tokens before request: {tokens}\")\n    await make_request()\n    tokens_after = limiter.available()\n    print(f\"Tokens after request: {tokens_after}\")\n</code></pre>"},{"location":"reference/rate-limiting/#see-also","title":"See Also","text":"<ul> <li>How-to: Limit Request Rate</li> <li>Reference: Retry Strategy</li> </ul>"},{"location":"reference/retry-strategy/","title":"Retry Strategy","text":"<p>Automatic retry with exponential backoff and jitter for resilient request handling.</p>"},{"location":"reference/retry-strategy/#retrystrategy","title":"RetryStrategy","text":"<p>Main retry strategy class.</p> <pre><code>from fastreq.utils.retry import RetryStrategy, RetryConfig\n\nconfig = RetryConfig(\n    max_retries=3,\n    backoff_multiplier=1.0,\n    jitter=0.1,\n)\n\nstrategy = RetryStrategy(config)\n\nresult = await strategy.execute(some_async_function)\n</code></pre>"},{"location":"reference/retry-strategy/#retrystrategy-methods","title":"RetryStrategy Methods","text":"Method Return Type Description <code>execute(func, *args, **kwargs)</code> <code>Any</code> Execute function with retry logic <code>_calculate_delay(attempt)</code> <code>float</code> Calculate delay for retry attempt <code>_should_retry(error)</code> <code>bool</code> Determine if error should trigger retry"},{"location":"reference/retry-strategy/#retryconfig","title":"RetryConfig","text":"<p>Configuration for retry strategy.</p> <pre><code>from fastreq.utils.retry import RetryConfig\n\nconfig = RetryConfig(\n    max_retries=3,              # Retry up to 3 times\n    backoff_multiplier=1.0,    # Base backoff in seconds\n    jitter=0.1,                # 10% jitter\n    retry_on=None,             # Retry on all errors (default)\n    dont_retry_on=None,        # Don't exclude any errors\n)\n</code></pre>"},{"location":"reference/retry-strategy/#retryconfig-attributes","title":"RetryConfig Attributes","text":"Attribute Type Default Description <code>max_retries</code> <code>int</code> <code>3</code> Maximum retry attempts <code>backoff_multiplier</code> <code>float</code> <code>1.0</code> Base backoff (seconds) <code>jitter</code> <code>float</code> <code>0.1</code> Jitter fraction (0.1 = 10%) <code>retry_on</code> <code>set[type[Exception]] \\| None</code> <code>None</code> Exception types to retry <code>dont_retry_on</code> <code>set[type[Exception]] \\| None</code> <code>None</code> Exceptions to never retry"},{"location":"reference/retry-strategy/#backoff-formula","title":"Backoff Formula","text":"<p>Exponential backoff with jitter:</p> <pre><code>delay = backoff_multiplier * (2^attempt) \u00b1 (jitter * delay)\n</code></pre>"},{"location":"reference/retry-strategy/#example-calculation","title":"Example Calculation","text":"<p>With <code>backoff_multiplier=1.0</code> and <code>jitter=0.1</code>:</p> Attempt Base Delay Jitter Range Actual Delay 0 1.0s \u00b10.1s 0.9s - 1.1s 1 2.0s \u00b10.2s 1.8s - 2.2s 2 4.0s \u00b10.4s 3.6s - 4.4s"},{"location":"reference/retry-strategy/#code-implementation","title":"Code Implementation","text":"<pre><code>def _calculate_delay(self, attempt: int) -&gt; float:\n    base_delay = self.config.backoff_multiplier * (2**attempt)\n    jitter_amount = self.config.jitter * base_delay\n    jittered_delay = base_delay + random.uniform(-jitter_amount, jitter_amount)\n    return float(max(0, jittered_delay))\n</code></pre>"},{"location":"reference/retry-strategy/#jitter-calculation","title":"Jitter Calculation","text":"<p>Jitter adds randomness to avoid \"thundering herd\" problems:</p> <pre><code>jittered_delay = base_delay + random.uniform(-jitter_amount, jitter_amount)\n</code></pre>"},{"location":"reference/retry-strategy/#why-jitter","title":"Why Jitter?","text":"<p>Without jitter, multiple failing requests retry simultaneously:</p> <pre><code>Time 0.0s:  All requests fail\nTime 1.0s:  All retry (thundering herd!)\nTime 2.0s:  All retry again\n</code></pre> <p>With jitter, retries are spread out:</p> <pre><code>Time 0.0s:  All requests fail\nTime 0.9s:  Request 1 retries\nTime 1.1s:  Request 2 retries\nTime 1.8s:  Request 3 retries\nTime 2.2s:  Request 4 retries\n</code></pre>"},{"location":"reference/retry-strategy/#retry-logic","title":"Retry Logic","text":""},{"location":"reference/retry-strategy/#when-to-retry","title":"When to Retry","text":"<p>By default, all exceptions trigger retry:</p> <pre><code># Default behavior - retry all errors\nconfig = RetryConfig(max_retries=3)\n</code></pre>"},{"location":"reference/retry-strategy/#retry-specific-errors","title":"Retry Specific Errors","text":"<pre><code># Only retry network errors\nimport httpx\n\nconfig = RetryConfig(\n    max_retries=3,\n    retry_on={httpx.ConnectError, httpx.TimeoutException},\n)\n</code></pre>"},{"location":"reference/retry-strategy/#dont-retry-specific-errors","title":"Don't Retry Specific Errors","text":"<pre><code># Retry all errors except 4xx\nimport httpx\n\nconfig = RetryConfig(\n    max_retries=3,\n    dont_retry_on={httpx.HTTPStatusError},\n)\n</code></pre>"},{"location":"reference/retry-strategy/#combined-rules","title":"Combined Rules","text":"<pre><code># Retry only network errors, never 4xx\nconfig = RetryConfig(\n    max_retries=3,\n    retry_on={httpx.ConnectError, httpx.TimeoutException},\n    dont_retry_on={httpx.HTTPStatusError},\n)\n</code></pre>"},{"location":"reference/retry-strategy/#using-retry-strategy","title":"Using Retry Strategy","text":""},{"location":"reference/retry-strategy/#in-parallelrequests-client","title":"In ParallelRequests Client","text":"<pre><code>from fastreq import ParallelRequests\n\nclient = ParallelRequests(\n    max_retries=3,  # Built-in retry\n)\n\nasync with client:\n    results = await client.request(urls)\n</code></pre>"},{"location":"reference/retry-strategy/#standalone-usage","title":"Standalone Usage","text":"<pre><code>from fastreq.utils.retry import RetryStrategy, RetryConfig\nimport httpx\n\nconfig = RetryConfig(max_retries=3, jitter=0.1)\nstrategy = RetryStrategy(config)\n\nasync def fetch(url):\n    async with httpx.AsyncClient() as client:\n        return await client.get(url)\n\n# Retry automatically\nresult = await strategy.execute(fetch, \"https://example.com\")\n</code></pre>"},{"location":"reference/retry-strategy/#exhausted-retries","title":"Exhausted Retries","text":"<p>When all retries are exhausted, <code>RetryExhaustedError</code> is raised:</p> <pre><code>from fastreq.exceptions import RetryExhaustedError\n\ntry:\n    await strategy.execute(func)\nexcept RetryExhaustedError as e:\n    print(f\"Retries exhausted after {e.attempts} attempts\")\n    print(f\"Last error: {e.last_error}\")\n</code></pre>"},{"location":"reference/retry-strategy/#retryexhaustederror-attributes","title":"RetryExhaustedError Attributes","text":"Attribute Type Description <code>attempts</code> <code>int</code> Number of retry attempts <code>last_error</code> <code>Exception \\| None</code> Last exception <code>url</code> <code>str \\| None</code> URL that failed"},{"location":"reference/retry-strategy/#complete-example","title":"Complete Example","text":"<pre><code>from fastreq import ParallelRequests\nfrom fastreq.exceptions import RetryExhaustedError\nimport httpx\n\nclient = ParallelRequests(\n    max_retries=3,              # Retry up to 3 times\n)\n\nasync with client:\n    try:\n        results = await client.request(urls)\n    except RetryExhaustedError as e:\n        print(f\"Failed after {e.attempts} retries\")\n        print(f\"Last error: {e.last_error}\")\n        # Handle partial failure or abort\n</code></pre>"},{"location":"reference/retry-strategy/#see-also","title":"See Also","text":"<ul> <li>Reference: Exceptions</li> <li>How-to: Handle Errors</li> </ul>"},{"location":"reference/return-types/","title":"Return Types","text":"<p>Control how responses are parsed using the <code>ReturnType</code> enum or string values.</p>"},{"location":"reference/return-types/#available-return-types","title":"Available Return Types","text":""},{"location":"reference/return-types/#json","title":"JSON","text":"<p>Parses response body as JSON. Returns <code>dict</code>, <code>list</code>, or <code>None</code> if response is not valid JSON.</p> <pre><code>from fastreq import FastRequests\n\nasync with FastRequests() as client:\n    # Returns dict/list if JSON\n    result = await client.request(\n        \"https://api.github.com/repos/python/cpython\",\n        return_type=\"json\"\n    )\n    print(result['name'])  # 'cpython'\n</code></pre> <p>Use when: Working with APIs that return JSON data</p> <p>Returns: <code>dict | list | None</code></p>"},{"location":"reference/return-types/#text","title":"TEXT","text":"<p>Returns response body as decoded UTF-8 string.</p> <pre><code>from fastreq import FastRequests\n\nasync with FastRequests() as client:\n    # Returns decoded string\n    html = await client.request(\n        \"https://example.com\",\n        return_type=\"text\"\n    )\n    print(html[:100])\n</code></pre> <p>Use when: Working with HTML, plain text, or non-JSON APIs</p> <p>Returns: <code>str</code></p>"},{"location":"reference/return-types/#content","title":"CONTENT","text":"<p>Returns response body as raw bytes.</p> <pre><code>from fastreq import FastRequests\n\nasync with FastRequests() as client:\n    # Returns raw bytes\n    image_data = await client.request(\n        \"https://example.com/image.png\",\n        return_type=\"content\"\n    )\n    with open(\"image.png\", \"wb\") as f:\n        f.write(image_data)\n</code></pre> <p>Use when: Downloading binary files (images, PDFs, archives)</p> <p>Returns: <code>bytes</code></p>"},{"location":"reference/return-types/#response","title":"RESPONSE","text":"<p>Returns full <code>NormalizedResponse</code> object with all response details.</p> <pre><code>from fastreq import FastRequests\n\nasync with FastRequests() as client:\n    # Returns NormalizedResponse\n    response = await client.request(\n        \"https://httpbin.org/get\",\n        return_type=\"response\"\n    )\n    print(response.status_code)\n    print(response.headers['content-type'])\n    print(response.text)\n    print(response.json_data)\n</code></pre> <p>Use when: You need status codes, headers, or raw response details</p> <p>Returns: <code>NormalizedResponse</code></p> <p>NormalizedResponse attributes:</p> Attribute Type Description <code>status_code</code> <code>int</code> HTTP status code <code>headers</code> <code>dict[str, str]</code> Response headers (lowercase keys) <code>content</code> <code>bytes</code> Raw response body <code>text</code> <code>str</code> Decoded response body <code>json_data</code> <code>Any</code> Parsed JSON (if valid) <code>url</code> <code>str</code> Final URL (after redirects) <code>is_json</code> <code>bool</code> Whether response is valid JSON"},{"location":"reference/return-types/#stream","title":"STREAM","text":"<p>Streams response content through a callback function.</p> <pre><code>from fastreq import FastRequests\n\ndef stream_callback(chunk: bytes):\n    print(f\"Received {len(chunk)} bytes\")\n\nasync with FastRequests() as client:\n    await client.request(\n        \"https://example.com/large-file.zip\",\n        return_type=\"stream\",\n        stream_callback=stream_callback\n    )\n</code></pre> <p>Use when: Processing large files without loading into memory</p> <p>Returns: <code>None</code> (data processed via callback)</p> <p>Note: Requires <code>stream_callback</code> parameter</p>"},{"location":"reference/return-types/#using-returntype-enum","title":"Using ReturnType Enum","text":"<p>You can use either string values or the <code>ReturnType</code> enum:</p> <pre><code>from fastreq import FastRequests, ReturnType\n\nasync with FastRequests() as client:\n    # String value\n    result1 = await client.request(url, return_type=\"json\")\n\n    # Enum value\n    result2 = await client.request(url, return_type=ReturnType.JSON)\n</code></pre>"},{"location":"reference/return-types/#default-return-type","title":"Default Return Type","text":"<p>The default return type is <code>JSON</code>. If a response is not valid JSON, it returns <code>None</code> rather than raising an error.</p> <pre><code># Defaults to JSON\nresult = await client.request(\"https://example.com\")\n# Returns None if response is not JSON\n</code></pre>"},{"location":"reference/return-types/#see-also","title":"See Also","text":"<ul> <li>API Reference: FastRequests.request()</li> <li>API Reference: ReturnType</li> <li>How-to: Post JSON Data</li> </ul>"},{"location":"reference/validation/","title":"Validation","text":"<p>Input validation functions for URLs, proxies, headers, and more.</p>"},{"location":"reference/validation/#validate_url","title":"validate_url()","text":"<p>Validate URL format (must start with http:// or https://).</p> <pre><code>from fastreq.utils.validators import validate_url\n\nis_valid = validate_url(\"https://example.com\")  # True\n</code></pre>"},{"location":"reference/validation/#parameters","title":"Parameters","text":"Parameter Type Description <code>url</code> <code>str</code> URL string to validate"},{"location":"reference/validation/#returns","title":"Returns","text":"<p><code>bool</code> - <code>True</code> if valid</p>"},{"location":"reference/validation/#raises","title":"Raises","text":"<p><code>ValidationError</code> - If URL is invalid</p>"},{"location":"reference/validation/#examples","title":"Examples","text":"<pre><code>from fastreq.utils.validators import validate_url, ValidationError\n\n# Valid URLs\nvalidate_url(\"https://example.com\")           # True\nvalidate_url(\"http://example.com/path\")      # True\n\n# Invalid URLs (raises ValidationError)\ntry:\n    validate_url(\"ftp://example.com\")\nexcept ValidationError as e:\n    print(f\"Invalid URL: {e}\")\n    # ValidationError: Invalid URL: ftp://example.com. Must start with http:// or https://\n\ntry:\n    validate_url(\"not-a-url\")\nexcept ValidationError as e:\n    print(f\"Invalid URL: {e}\")\n</code></pre>"},{"location":"reference/validation/#validation-pattern","title":"Validation Pattern","text":"<pre><code>pattern = r\"^https?://.+\"\n</code></pre>"},{"location":"reference/validation/#validate_proxy","title":"validate_proxy()","text":"<p>Validate proxy URL format.</p> <pre><code>from fastreq.utils.validators import validate_proxy\n\nis_valid = validate_proxy(\"192.168.1.1:8080\")  # True\n</code></pre>"},{"location":"reference/validation/#parameters_1","title":"Parameters","text":"Parameter Type Description <code>proxy</code> <code>str</code> Proxy URL string to validate"},{"location":"reference/validation/#returns_1","title":"Returns","text":"<p><code>bool</code> - <code>True</code> if valid format, <code>False</code> otherwise</p>"},{"location":"reference/validation/#valid-formats","title":"Valid Formats","text":"<ol> <li> <p>IP:PORT <pre><code>\"192.168.1.1:8080\"\n</code></pre></p> </li> <li> <p>IP:PORT:USER:PASS <pre><code>\"192.168.1.1:8080:admin:password\"\n</code></pre></p> </li> <li> <p>http://user:pass@host:port <pre><code>\"http://user:pass@proxy.example.com:8080\"\n</code></pre></p> </li> <li> <p>https://user:pass@host:port <pre><code>\"https://user:pass@proxy.example.com:8080\"\n</code></pre></p> </li> </ol>"},{"location":"reference/validation/#examples_1","title":"Examples","text":"<pre><code># Valid proxies\nvalidate_proxy(\"192.168.1.1:8080\")                      # True\nvalidate_proxy(\"192.168.1.1:8080:user:pass\")            # True\nvalidate_proxy(\"http://user:pass@proxy:8080\")           # True\nvalidate_proxy(\"https://user:pass@proxy:8080\")          # True\n\n# Invalid proxies\nvalidate_proxy(\"not-a-proxy\")          # False\nvalidate_proxy(\"192.168.1.1\")          # False (missing port)\nvalidate_proxy(\"\")                     # False\nvalidate_proxy(None)                   # False\n</code></pre>"},{"location":"reference/validation/#validation-patterns","title":"Validation Patterns","text":"<pre><code>ip_port_simple = r\"^\\d{1,3}\\.\\d{1,3}\\.\\d{1,3}\\.\\d{1,3}:\\d+$\"\nip_port_with_auth = r\"^\\d{1,3}\\.\\d{1,3}\\.\\d{1,3}\\.\\d{1,3}:\\d+:\\w+:\\w+$\"\nhttp_url = r\"^https?://.+\"\n</code></pre>"},{"location":"reference/validation/#validate_headers","title":"validate_headers()","text":"<p>Validate headers dictionary.</p> <pre><code>from fastreq.utils.validators import validate_headers\n\nis_valid = validate_headers({\n    \"Content-Type\": \"application/json\",\n    \"Authorization\": \"Bearer token\"\n})  # True\n</code></pre>"},{"location":"reference/validation/#parameters_2","title":"Parameters","text":"Parameter Type Description <code>headers</code> <code>dict[str, Any]</code> Headers dictionary to validate"},{"location":"reference/validation/#returns_2","title":"Returns","text":"<p><code>bool</code> - <code>True</code> if valid</p>"},{"location":"reference/validation/#raises_1","title":"Raises","text":"<p><code>ValidationError</code> - If headers are invalid</p>"},{"location":"reference/validation/#validation-rules","title":"Validation Rules","text":"<ul> <li><code>headers</code> must be a dictionary</li> <li>All keys must be strings</li> <li>All values must be strings</li> </ul>"},{"location":"reference/validation/#examples_2","title":"Examples","text":"<pre><code>from fastreq.utils.validators import validate_headers, ValidationError\n\n# Valid headers\nvalidate_headers({\n    \"Content-Type\": \"application/json\",\n    \"Authorization\": \"Bearer token\",\n})  # True\n\n# Invalid headers (raises ValidationError)\ntry:\n    validate_headers(\"not-a-dict\")\nexcept ValidationError as e:\n    print(f\"Invalid headers: {e}\")\n    # ValidationError: Headers must be a dictionary\n\ntry:\n    validate_headers({123: \"value\"})  # Key not string\nexcept ValidationError as e:\n    print(f\"Invalid headers: {e}\")\n    # ValidationError: Header key must be a string, got int\n\ntry:\n    validate_headers({\"key\": 123})  # Value not string\nexcept ValidationError as e:\n    print(f\"Invalid headers: {e}\")\n    # ValidationError: Header value for key 'key' must be a string, got int\n</code></pre>"},{"location":"reference/validation/#normalize_urls","title":"normalize_urls()","text":"<p>Normalize URLs to list format.</p> <pre><code>from fastreq.utils.validators import normalize_urls\n\n# Single URL \u2192 list\nresult = normalize_urls(\"https://example.com\")\n# [\"https://example.com\"]\n\n# List of URLs \u2192 list (unchanged)\nresult = normalize_urls([\"https://a.com\", \"https://b.com\"])\n# [\"https://a.com\", \"https://b.com\"]\n\n# None \u2192 None\nresult = normalize_urls(None)\n# None\n</code></pre>"},{"location":"reference/validation/#parameters_3","title":"Parameters","text":"Parameter Type Description <code>urls</code> <code>str \\| list[str] \\| None</code> Single URL, list of URLs, or None"},{"location":"reference/validation/#returns_3","title":"Returns","text":"<p><code>list[str] \\| None</code> - List of URLs or None</p>"},{"location":"reference/validation/#examples_3","title":"Examples","text":"<pre><code>from fastreq.utils.validators import normalize_urls\n\n# Single string\nnormalize_urls(\"https://example.com\")\n# [\"https://example.com\"]\n\n# List of strings\nnormalize_urls([\"https://a.com\", \"https://b.com\", \"https://c.com\"])\n# [\"https://a.com\", \"https://b.com\", \"https://c.com\"]\n\n# None\nnormalize_urls(None)\n# None\n\n# Empty list\nnormalize_urls([])\n# []\n</code></pre>"},{"location":"reference/validation/#using-validation-functions","title":"Using Validation Functions","text":""},{"location":"reference/validation/#manual-validation","title":"Manual Validation","text":"<pre><code>from fastreq.utils.validators import (\n    validate_url,\n    validate_proxy,\n    validate_headers,\n    normalize_urls,\n)\n\n# Validate URL\nif validate_url(\"https://example.com\"):\n    print(\"URL is valid\")\n\n# Validate proxy\nif validate_proxy(\"192.168.1.1:8080\"):\n    print(\"Proxy is valid\")\n\n# Validate headers\ntry:\n    validate_headers({\"Content-Type\": \"application/json\"})\n    print(\"Headers are valid\")\nexcept ValidationError as e:\n    print(f\"Invalid headers: {e}\")\n\n# Normalize URLs\nurls = normalize_urls(\"https://example.com\")\nprint(urls)  # [\"https://example.com\"]\n</code></pre>"},{"location":"reference/validation/#integration-with-parallelrequests","title":"Integration with ParallelRequests","text":"<p>ParallelRequests uses these validators internally:</p> <pre><code>from fastreq import ParallelRequests\n\nasync with ParallelRequests() as client:\n    # URLs are validated internally\n    results = await client.request(\"https://example.com\")\n\n    # Headers are validated internally\n    results = await client.request(\n        \"https://example.com\",\n        headers={\"Authorization\": \"Bearer token\"}\n    )\n</code></pre>"},{"location":"reference/validation/#validationerror","title":"ValidationError","text":"<p>Base validation error with <code>field_name</code> attribute.</p> <pre><code>from fastreq.exceptions import ValidationError\n\ntry:\n    validate_url(\"invalid-url\")\nexcept ValidationError as e:\n    print(f\"Field '{e.field_name}' failed validation\")\n    # Field 'url' failed validation\n</code></pre>"},{"location":"reference/validation/#attributes","title":"Attributes","text":"Attribute Type Description <code>message</code> <code>str</code> Error message <code>field_name</code> <code>str \\| None</code> Name of the field that failed"},{"location":"reference/validation/#see-also","title":"See Also","text":"<ul> <li>Reference: Exceptions</li> <li>How-to: Debug Issues</li> </ul>"},{"location":"reference/api/fastreq/","title":"fastreq()","text":""},{"location":"reference/api/fastreq/#fastreq.client.fastreq","title":"fastreq.client.fastreq","text":"<pre><code>fastreq(\n    urls: str | list[str],\n    *,\n    backend: str = \"auto\",\n    concurrency: int = 20,\n    max_retries: int = 3,\n    rate_limit: float | None = None,\n    rate_limit_burst: int = 5,\n    http2: bool = True,\n    follow_redirects: bool = True,\n    verify_ssl: bool = True,\n    timeout: float | None = None,\n    cookies: dict[str, str] | None = None,\n    random_user_agent: bool = True,\n    random_proxy: bool = False,\n    debug: bool = False,\n    verbose: bool = True,\n    return_none_on_failure: bool = False,\n    method: str = \"GET\",\n    params: dict[str, Any] | None = None,\n    data: Any = None,\n    json: Any = None,\n    headers: dict[str, str] | None = None,\n    proxy: str | None = None,\n    return_type: ReturnType | str = ReturnType.JSON,\n    parse_func: Callable[[Any], Any] | None = None,\n    keys: list[str] | None = None\n) -&gt; Any\n</code></pre> <p>Synchronous convenience function for parallel requests.</p> <p>This is the easiest way to make parallel requests. Uses asyncio.run() internally.</p> Example <p>from fastreq import fastreq results = fastreq( ...     urls=[\"https://api.github.com/repos/python/cpython\"], ...     concurrency=3, ... ) print(results[0][\"name\"]) 'cpython'</p> <p>Parameters:</p> Name Type Description Default <code>urls</code> <code>str | list[str]</code> <p>Single URL or list of URLs to request</p> required <code>backend</code> <code>str</code> <p>Backend to use (\"auto\", \"niquests\", \"aiohttp\", or \"requests\")</p> <code>'auto'</code> <code>concurrency</code> <code>int</code> <p>Maximum number of concurrent requests</p> <code>20</code> <code>max_retries</code> <code>int</code> <p>Maximum retry attempts per request</p> <code>3</code> <code>rate_limit</code> <code>float | None</code> <p>Requests per second (None for no limit)</p> <code>None</code> <code>rate_limit_burst</code> <code>int</code> <p>Burst size for rate limiter</p> <code>5</code> <code>http2</code> <code>bool</code> <p>Enable HTTP/2 (if supported by backend)</p> <code>True</code> <code>follow_redirects</code> <code>bool</code> <p>Follow HTTP redirects</p> <code>True</code> <code>verify_ssl</code> <code>bool</code> <p>Verify SSL certificates</p> <code>True</code> <code>timeout</code> <code>float | None</code> <p>Default timeout per request (seconds)</p> <code>None</code> <code>cookies</code> <code>dict[str, str] | None</code> <p>Initial session cookies</p> <code>None</code> <code>random_user_agent</code> <code>bool</code> <p>Rotate user agents</p> <code>True</code> <code>random_proxy</code> <code>bool</code> <p>Enable proxy rotation</p> <code>False</code> <code>debug</code> <code>bool</code> <p>Enable debug logging</p> <code>False</code> <code>verbose</code> <code>bool</code> <p>Enable verbose output</p> <code>True</code> <code>return_none_on_failure</code> <code>bool</code> <p>Return None instead of raising on failure</p> <code>False</code> <code>method</code> <code>str</code> <p>HTTP method (GET, POST, etc.)</p> <code>'GET'</code> <code>params</code> <code>dict[str, Any] | None</code> <p>Query parameters</p> <code>None</code> <code>data</code> <code>Any</code> <p>Request body data</p> <code>None</code> <code>json</code> <code>Any</code> <p>JSON body (serialized automatically)</p> <code>None</code> <code>headers</code> <code>dict[str, str] | None</code> <p>Request headers</p> <code>None</code> <code>proxy</code> <code>str | None</code> <p>Proxy URL</p> <code>None</code> <code>return_type</code> <code>ReturnType | str</code> <p>How to parse the response (json, text, content, response, stream)</p> <code>JSON</code> <code>parse_func</code> <code>Callable[[Any], Any] | None</code> <p>Custom function to parse each response</p> <code>None</code> <code>keys</code> <code>list[str] | None</code> <p>Keys for dict return (must match urls length)</p> <code>None</code> <p>Returns:</p> Type Description <code>Any</code> <ul> <li>Single URL: single result</li> </ul> <code>Any</code> <ul> <li>List of URLs: list of results</li> </ul> <code>Any</code> <ul> <li>List of URLs with keys: dict mapping keys to results</li> </ul> Source code in <code>fastreq/client.py</code> <pre><code>def fastreq(\n    urls: str | list[str],\n    *,\n    backend: str = \"auto\",\n    concurrency: int = 20,\n    max_retries: int = 3,\n    rate_limit: float | None = None,\n    rate_limit_burst: int = 5,\n    http2: bool = True,\n    follow_redirects: bool = True,\n    verify_ssl: bool = True,\n    timeout: float | None = None,\n    cookies: dict[str, str] | None = None,\n    random_user_agent: bool = True,\n    random_proxy: bool = False,\n    debug: bool = False,\n    verbose: bool = True,\n    return_none_on_failure: bool = False,\n    method: str = \"GET\",\n    params: dict[str, Any] | None = None,\n    data: Any = None,\n    json: Any = None,\n    headers: dict[str, str] | None = None,\n    proxy: str | None = None,\n    return_type: ReturnType | str = ReturnType.JSON,\n    parse_func: Callable[[Any], Any] | None = None,\n    keys: list[str] | None = None,\n) -&gt; Any:\n    \"\"\"Synchronous convenience function for parallel requests.\n\n    This is the easiest way to make parallel requests. Uses asyncio.run() internally.\n\n    Example:\n        &gt;&gt;&gt; from fastreq import fastreq\n        &gt;&gt;&gt; results = fastreq(\n        ...     urls=[\"https://api.github.com/repos/python/cpython\"],\n        ...     concurrency=3,\n        ... )\n        &gt;&gt;&gt; print(results[0][\"name\"])\n        'cpython'\n\n    Args:\n        urls: Single URL or list of URLs to request\n        backend: Backend to use (\"auto\", \"niquests\", \"aiohttp\", or \"requests\")\n        concurrency: Maximum number of concurrent requests\n        max_retries: Maximum retry attempts per request\n        rate_limit: Requests per second (None for no limit)\n        rate_limit_burst: Burst size for rate limiter\n        http2: Enable HTTP/2 (if supported by backend)\n        follow_redirects: Follow HTTP redirects\n        verify_ssl: Verify SSL certificates\n        timeout: Default timeout per request (seconds)\n        cookies: Initial session cookies\n        random_user_agent: Rotate user agents\n        random_proxy: Enable proxy rotation\n        debug: Enable debug logging\n        verbose: Enable verbose output\n        return_none_on_failure: Return None instead of raising on failure\n        method: HTTP method (GET, POST, etc.)\n        params: Query parameters\n        data: Request body data\n        json: JSON body (serialized automatically)\n        headers: Request headers\n        proxy: Proxy URL\n        return_type: How to parse the response (json, text, content, response, stream)\n        parse_func: Custom function to parse each response\n        keys: Keys for dict return (must match urls length)\n\n    Returns:\n        - Single URL: single result\n        - List of URLs: list of results\n        - List of URLs with keys: dict mapping keys to results\n    \"\"\"\n\n    async def _run() -&gt; Any:\n        client = FastRequests(\n            backend=backend,\n            concurrency=concurrency,\n            max_retries=max_retries,\n            rate_limit=rate_limit,\n            rate_limit_burst=rate_limit_burst,\n            http2=http2,\n            follow_redirects=follow_redirects,\n            verify_ssl=verify_ssl,\n            timeout=timeout,\n            cookies=cookies,\n            random_user_agent=random_user_agent,\n            random_proxy=random_proxy,\n            debug=debug,\n            verbose=verbose,\n            return_none_on_failure=return_none_on_failure,\n        )\n        async with client:\n            return await client.request(\n                urls,\n                method=method,\n                params=params,\n                data=data,\n                json=json,\n                headers=headers,\n                timeout=timeout,\n                proxy=proxy,\n                return_type=return_type,\n                parse_func=parse_func,\n                keys=keys,\n            )\n\n    return asyncio.run(_run())\n</code></pre>"},{"location":"reference/api/fastreq_async/","title":"fastreq_async()","text":""},{"location":"reference/api/fastreq_async/#fastreq.client.fastreq_async","title":"fastreq.client.fastreq_async  <code>async</code>","text":"<pre><code>fastreq_async(\n    urls: str | list[str],\n    *,\n    backend: str = \"auto\",\n    concurrency: int = 20,\n    max_retries: int = 3,\n    rate_limit: float | None = None,\n    rate_limit_burst: int = 5,\n    http2: bool = True,\n    follow_redirects: bool = True,\n    verify_ssl: bool = True,\n    timeout: float | None = None,\n    cookies: dict[str, str] | None = None,\n    random_user_agent: bool = True,\n    random_proxy: bool = False,\n    debug: bool = False,\n    verbose: bool = True,\n    return_none_on_failure: bool = False,\n    method: str = \"GET\",\n    params: dict[str, Any] | None = None,\n    data: Any = None,\n    json: Any = None,\n    headers: dict[str, str] | None = None,\n    proxy: str | None = None,\n    return_type: ReturnType | str = ReturnType.JSON,\n    parse_func: Callable[[Any], Any] | None = None,\n    keys: list[str] | None = None\n) -&gt; Any\n</code></pre> <p>Async convenience function for parallel requests.</p> Example <p>import asyncio from fastreq import fastreq_async async def main(): ...     results = await fastreq_async( ...         urls=[\"https://httpbin.org/get\"] * 3, ...         concurrency=5, ...     ) ...     return results results = asyncio.run(main()) print(len(results)) 3</p> <p>Parameters:</p> Name Type Description Default <code>urls</code> <code>str | list[str]</code> <p>Single URL or list of URLs to request</p> required <code>backend</code> <code>str</code> <p>Backend to use (\"auto\", \"niquests\", \"aiohttp\", or \"requests\")</p> <code>'auto'</code> <code>concurrency</code> <code>int</code> <p>Maximum number of concurrent requests</p> <code>20</code> <code>max_retries</code> <code>int</code> <p>Maximum retry attempts per request</p> <code>3</code> <code>rate_limit</code> <code>float | None</code> <p>Requests per second (None for no limit)</p> <code>None</code> <code>rate_limit_burst</code> <code>int</code> <p>Burst size for rate limiter</p> <code>5</code> <code>http2</code> <code>bool</code> <p>Enable HTTP/2 (if supported by backend)</p> <code>True</code> <code>follow_redirects</code> <code>bool</code> <p>Follow HTTP redirects</p> <code>True</code> <code>verify_ssl</code> <code>bool</code> <p>Verify SSL certificates</p> <code>True</code> <code>timeout</code> <code>float | None</code> <p>Default timeout per request (seconds)</p> <code>None</code> <code>cookies</code> <code>dict[str, str] | None</code> <p>Initial session cookies</p> <code>None</code> <code>random_user_agent</code> <code>bool</code> <p>Rotate user agents</p> <code>True</code> <code>random_proxy</code> <code>bool</code> <p>Enable proxy rotation</p> <code>False</code> <code>debug</code> <code>bool</code> <p>Enable debug logging</p> <code>False</code> <code>verbose</code> <code>bool</code> <p>Enable verbose output</p> <code>True</code> <code>return_none_on_failure</code> <code>bool</code> <p>Return None instead of raising on failure</p> <code>False</code> <code>method</code> <code>str</code> <p>HTTP method (GET, POST, etc.)</p> <code>'GET'</code> <code>params</code> <code>dict[str, Any] | None</code> <p>Query parameters</p> <code>None</code> <code>data</code> <code>Any</code> <p>Request body data</p> <code>None</code> <code>json</code> <code>Any</code> <p>JSON body (serialized automatically)</p> <code>None</code> <code>headers</code> <code>dict[str, str] | None</code> <p>Request headers</p> <code>None</code> <code>proxy</code> <code>str | None</code> <p>Proxy URL</p> <code>None</code> <code>return_type</code> <code>ReturnType | str</code> <p>How to parse the response (json, text, content, response, stream)</p> <code>JSON</code> <code>parse_func</code> <code>Callable[[Any], Any] | None</code> <p>Custom function to parse each response</p> <code>None</code> <code>keys</code> <code>list[str] | None</code> <p>Keys for dict return (must match urls length)</p> <code>None</code> <p>Returns:</p> Type Description <code>Any</code> <ul> <li>Single URL: single result</li> </ul> <code>Any</code> <ul> <li>List of URLs: list of results</li> </ul> <code>Any</code> <ul> <li>List of URLs with keys: dict mapping keys to results</li> </ul> Source code in <code>fastreq/client.py</code> <pre><code>async def fastreq_async(\n    urls: str | list[str],\n    *,\n    backend: str = \"auto\",\n    concurrency: int = 20,\n    max_retries: int = 3,\n    rate_limit: float | None = None,\n    rate_limit_burst: int = 5,\n    http2: bool = True,\n    follow_redirects: bool = True,\n    verify_ssl: bool = True,\n    timeout: float | None = None,\n    cookies: dict[str, str] | None = None,\n    random_user_agent: bool = True,\n    random_proxy: bool = False,\n    debug: bool = False,\n    verbose: bool = True,\n    return_none_on_failure: bool = False,\n    method: str = \"GET\",\n    params: dict[str, Any] | None = None,\n    data: Any = None,\n    json: Any = None,\n    headers: dict[str, str] | None = None,\n    proxy: str | None = None,\n    return_type: ReturnType | str = ReturnType.JSON,\n    parse_func: Callable[[Any], Any] | None = None,\n    keys: list[str] | None = None,\n) -&gt; Any:\n    \"\"\"Async convenience function for parallel requests.\n\n    Example:\n        &gt;&gt;&gt; import asyncio\n        &gt;&gt;&gt; from fastreq import fastreq_async\n        &gt;&gt;&gt; async def main():\n        ...     results = await fastreq_async(\n        ...         urls=[\"https://httpbin.org/get\"] * 3,\n        ...         concurrency=5,\n        ...     )\n        ...     return results\n        &gt;&gt;&gt; results = asyncio.run(main())\n        &gt;&gt;&gt; print(len(results))\n        3\n\n    Args:\n        urls: Single URL or list of URLs to request\n        backend: Backend to use (\"auto\", \"niquests\", \"aiohttp\", or \"requests\")\n        concurrency: Maximum number of concurrent requests\n        max_retries: Maximum retry attempts per request\n        rate_limit: Requests per second (None for no limit)\n        rate_limit_burst: Burst size for rate limiter\n        http2: Enable HTTP/2 (if supported by backend)\n        follow_redirects: Follow HTTP redirects\n        verify_ssl: Verify SSL certificates\n        timeout: Default timeout per request (seconds)\n        cookies: Initial session cookies\n        random_user_agent: Rotate user agents\n        random_proxy: Enable proxy rotation\n        debug: Enable debug logging\n        verbose: Enable verbose output\n        return_none_on_failure: Return None instead of raising on failure\n        method: HTTP method (GET, POST, etc.)\n        params: Query parameters\n        data: Request body data\n        json: JSON body (serialized automatically)\n        headers: Request headers\n        proxy: Proxy URL\n        return_type: How to parse the response (json, text, content, response, stream)\n        parse_func: Custom function to parse each response\n        keys: Keys for dict return (must match urls length)\n\n    Returns:\n        - Single URL: single result\n        - List of URLs: list of results\n        - List of URLs with keys: dict mapping keys to results\n    \"\"\"\n    client = FastRequests(\n        backend=backend,\n        concurrency=concurrency,\n        max_retries=max_retries,\n        rate_limit=rate_limit,\n        rate_limit_burst=rate_limit_burst,\n        http2=http2,\n        follow_redirects=follow_redirects,\n        verify_ssl=verify_ssl,\n        timeout=timeout,\n        cookies=cookies,\n        random_user_agent=random_user_agent,\n        random_proxy=random_proxy,\n        debug=debug,\n        verbose=verbose,\n        return_none_on_failure=return_none_on_failure,\n    )\n    async with client:\n        return await client.request(\n            urls,\n            method=method,\n            params=params,\n            data=data,\n            json=json,\n            headers=headers,\n            timeout=timeout,\n            proxy=proxy,\n            return_type=return_type,\n            parse_func=parse_func,\n            keys=keys,\n        )\n</code></pre>"},{"location":"reference/api/fastrequests/","title":"FastRequests","text":""},{"location":"reference/api/fastrequests/#fastreq.client.FastRequests","title":"fastreq.client.FastRequests","text":"<p>Main client for parallel HTTP requests.</p> Example <p>from fastreq import FastRequests client = FastRequests(concurrency=5) async with client: ...     results = await client.request( ...         urls=[\"https://httpbin.org/get\"] * 3, ...     ) print(len(results)) 3</p> <p>Parameters:</p> Name Type Description Default <code>backend</code> <code>str</code> <p>Backend to use (\"auto\", \"niquests\", \"aiohttp\", or \"requests\")</p> <code>'auto'</code> <code>concurrency</code> <code>int</code> <p>Maximum number of concurrent requests</p> <code>20</code> <code>max_retries</code> <code>int</code> <p>Maximum retry attempts per request</p> <code>3</code> <code>rate_limit</code> <code>float | None</code> <p>Requests per second (None for no limit)</p> <code>None</code> <code>rate_limit_burst</code> <code>int</code> <p>Burst size for rate limiter</p> <code>5</code> <code>http2</code> <code>bool</code> <p>Enable HTTP/2 (if supported by backend)</p> <code>True</code> <code>follow_redirects</code> <code>bool</code> <p>Follow HTTP redirects</p> <code>True</code> <code>verify_ssl</code> <code>bool</code> <p>Verify SSL certificates</p> <code>True</code> <code>timeout</code> <code>float | None</code> <p>Default timeout per request (seconds)</p> <code>None</code> <code>cookies</code> <code>dict[str, str] | None</code> <p>Initial session cookies</p> <code>None</code> <code>random_user_agent</code> <code>bool</code> <p>Rotate user agents</p> <code>True</code> <code>random_proxy</code> <code>bool</code> <p>Enable proxy rotation (requires proxy config)</p> <code>False</code> <code>debug</code> <code>bool</code> <p>Enable debug logging</p> <code>False</code> <code>verbose</code> <code>bool</code> <p>Enable verbose output</p> <code>True</code> <code>return_none_on_failure</code> <code>bool</code> <p>Return None instead of raising on failure</p> <code>False</code> Source code in <code>fastreq/client.py</code> <pre><code>class FastRequests:\n    \"\"\"Main client for parallel HTTP requests.\n\n    Example:\n        &gt;&gt;&gt; from fastreq import FastRequests\n        &gt;&gt;&gt; client = FastRequests(concurrency=5)\n        &gt;&gt;&gt; async with client:\n        ...     results = await client.request(\n        ...         urls=[\"https://httpbin.org/get\"] * 3,\n        ...     )\n        &gt;&gt;&gt; print(len(results))\n        3\n\n    Args:\n        backend: Backend to use (\"auto\", \"niquests\", \"aiohttp\", or \"requests\")\n        concurrency: Maximum number of concurrent requests\n        max_retries: Maximum retry attempts per request\n        rate_limit: Requests per second (None for no limit)\n        rate_limit_burst: Burst size for rate limiter\n        http2: Enable HTTP/2 (if supported by backend)\n        follow_redirects: Follow HTTP redirects\n        verify_ssl: Verify SSL certificates\n        timeout: Default timeout per request (seconds)\n        cookies: Initial session cookies\n        random_user_agent: Rotate user agents\n        random_proxy: Enable proxy rotation (requires proxy config)\n        debug: Enable debug logging\n        verbose: Enable verbose output\n        return_none_on_failure: Return None instead of raising on failure\n    \"\"\"\n\n    def __init__(\n        self,\n        backend: str = \"auto\",\n        concurrency: int = 20,\n        max_retries: int = 3,\n        rate_limit: float | None = None,\n        rate_limit_burst: int = 5,\n        http2: bool = True,\n        follow_redirects: bool = True,\n        verify_ssl: bool = True,\n        timeout: float | None = None,\n        cookies: dict[str, str] | None = None,\n        random_user_agent: bool = True,\n        random_proxy: bool = False,\n        debug: bool = False,\n        verbose: bool = True,\n        return_none_on_failure: bool = False,\n    ) -&gt; None:\n        self.backend_name = backend\n        self.concurrency = concurrency\n        self.follow_redirects = follow_redirects\n        self.verify_ssl = verify_ssl\n        self.timeout = timeout\n        self.random_user_agent = random_user_agent\n        self.random_proxy = random_proxy\n        self.debug = debug\n        self.verbose = verbose\n        self.return_none_on_failure = return_none_on_failure\n\n        configure_logging(debug, verbose)\n\n        self._backend: Backend | None = None\n        self._cookies: dict[str, str] = cookies.copy() if cookies else {}\n        self._rate_limiter: AsyncRateLimiter | None = None\n\n        retry_config = RetryConfig(max_retries=max_retries)\n        self._retry_strategy = RetryStrategy(retry_config)\n\n        self._concurrency_semaphore = asyncio.Semaphore(concurrency)\n\n        if rate_limit is not None:\n            rate_limit_config = RateLimitConfig(\n                requests_per_second=rate_limit,\n                burst=rate_limit_burst,\n            )\n            self._rate_limiter = AsyncRateLimiter(rate_limit_config)\n\n        self._http2 = http2\n        self._select_backend()\n\n    def _select_backend(self) -&gt; None:\n        if self.backend_name == \"auto\":\n            backend_candidates = [\n                (\"niquests\", \"niquests\", \"NiquestsBackend\"),\n                (\"httpx\", \"httpx\", \"HttpxBackend\"),\n                (\"aiohttp\", \"aiohttp\", \"AiohttpBackend\"),\n                (\"requests\", \"requests\", \"RequestsBackend\"),\n            ]\n\n            unavailable: list[str] = []\n            for backend_name, dependency_module, backend_class_name in backend_candidates:\n                if importlib.util.find_spec(dependency_module) is None:\n                    unavailable.append(backend_name)\n                    continue\n\n                try:\n                    module = importlib.import_module(f\"fastreq.backends.{backend_name}\")\n                    backend_cls = getattr(module, backend_class_name)\n                    self._backend = backend_cls(\n                        http2_enabled=self._http2, concurrency=self.concurrency\n                    )\n                    if unavailable:\n                        logger.info(\n                            f\"Using backend: {backend_name} ({', '.join(unavailable)} unavailable)\"\n                        )\n                    else:\n                        logger.info(f\"Using backend: {backend_name}\")\n                    return\n                except ImportError:\n                    unavailable.append(backend_name)\n                    continue\n\n            raise ConfigurationError(\n                \"No suitable backend found. Please install one of: niquests, httpx, aiohttp, or requests\"\n            )\n        else:\n            try:\n                module = importlib.import_module(f\"fastreq.backends.{self.backend_name}\")\n                backend_options: list[tuple[str, type[Backend]]] = [\n                    (name, cls)\n                    for name, cls in module.__dict__.items()\n                    if isinstance(cls, type) and issubclass(cls, Backend) and cls is not Backend\n                ]\n\n                if not backend_options:\n                    raise ConfigurationError(f\"Backend '{self.backend_name}' not found\")\n\n                backend_cls = backend_options[0][1]\n                self._backend = backend_cls(http2_enabled=self._http2, concurrency=self.concurrency)\n                logger.info(f\"Using backend: {self.backend_name}\")\n            except ImportError as e:\n                raise ConfigurationError(\n                    f\"Failed to load backend '{self.backend_name}': {e}\"\n                ) from e\n\n    async def __aenter__(self) -&gt; \"FastRequests\":\n        \"\"\"Enter async context manager and initialize backend session.\n\n        Returns:\n            Self for use in async with statement\n        \"\"\"\n        if self._backend:\n            await self._backend.__aenter__()\n        return self\n\n    async def __aexit__(self, *args: Any) -&gt; None:\n        \"\"\"Exit async context manager and close backend session.\"\"\"\n        if self._backend:\n            await self._backend.__aexit__(*args)\n\n    async def close(self) -&gt; None:\n        \"\"\"Close backend session and cleanup resources.\"\"\"\n        if self._backend:\n            await self._backend.close()\n\n    def reset_cookies(self) -&gt; None:\n        \"\"\"Clear all session cookies.\"\"\"\n        self._cookies = {}\n\n    def set_cookies(self, cookies: dict[str, str]) -&gt; None:\n        \"\"\"Add cookies to the session.\n\n        Args:\n            cookies: Dictionary of cookies to add (updates existing cookies)\n        \"\"\"\n        self._cookies.update(cookies)\n\n    @staticmethod\n    @contextlib.asynccontextmanager\n    async def _null_context() -&gt; AsyncGenerator[None, None]:\n        \"\"\"A null async context manager to replace rate limiting when disabled.\"\"\"\n        yield\n\n    # Single URL -&gt; single result\n    @overload\n    async def request(\n        self,\n        urls: str,\n        *,\n        method: str = ...,\n        params: dict[str, Any] | None = ...,\n        data: Any = ...,\n        json: Any = ...,\n        headers: dict[str, str] | None = ...,\n        timeout: float | None = ...,\n        proxy: str | None = ...,\n        return_type: ReturnType | str = ...,\n        follow_redirects: bool | None = ...,\n        verify_ssl: bool | None = ...,\n        parse_func: Callable[[Any], T] | None = ...,\n        keys: None = ...,\n    ) -&gt; Any: ...\n\n    # List of URLs with keys -&gt; dict result\n    @overload\n    async def request(\n        self,\n        urls: list[str],\n        *,\n        method: str = ...,\n        params: dict[str, Any] | None = ...,\n        data: Any = ...,\n        json: Any = ...,\n        headers: dict[str, str] | None = ...,\n        timeout: float | None = ...,\n        proxy: str | None = ...,\n        return_type: ReturnType | str = ...,\n        follow_redirects: bool | None = ...,\n        verify_ssl: bool | None = ...,\n        parse_func: Callable[[Any], T] | None = ...,\n        keys: list[str] = ...,\n    ) -&gt; dict[str, Any]: ...\n\n    # List of URLs without keys -&gt; list result\n    @overload\n    async def request(\n        self,\n        urls: list[str],\n        *,\n        method: str = ...,\n        params: dict[str, Any] | None = ...,\n        data: Any = ...,\n        json: Any = ...,\n        headers: dict[str, str] | None = ...,\n        timeout: float | None = ...,\n        proxy: str | None = ...,\n        return_type: ReturnType | str = ...,\n        follow_redirects: bool | None = ...,\n        verify_ssl: bool | None = ...,\n        parse_func: Callable[[Any], T] | None = ...,\n        keys: None = ...,\n    ) -&gt; list[Any]: ...\n\n    # General overload for str | list[str] with optional keys -&gt; Any\n    @overload\n    async def request(\n        self,\n        urls: str | list[str],\n        *,\n        method: str = ...,\n        params: dict[str, Any] | None = ...,\n        data: Any = ...,\n        json: Any = ...,\n        headers: dict[str, str] | None = ...,\n        timeout: float | None = ...,\n        proxy: str | None = ...,\n        return_type: ReturnType | str = ...,\n        follow_redirects: bool | None = ...,\n        verify_ssl: bool | None = ...,\n        parse_func: Callable[[Any], T] | None = ...,\n        keys: list[str] | None = ...,\n    ) -&gt; Any: ...\n\n    async def request(\n        self,\n        urls: str | list[str],\n        *,\n        method: str = \"GET\",\n        params: dict[str, Any] | None = None,\n        data: Any = None,\n        json: Any = None,\n        headers: dict[str, str] | None = None,\n        timeout: float | None = None,\n        proxy: str | None = None,\n        return_type: ReturnType | str = ReturnType.JSON,\n        follow_redirects: bool | None = None,\n        verify_ssl: bool | None = None,\n        parse_func: Callable[[Any], Any] | None = None,\n        keys: list[str] | None = None,\n    ) -&gt; Any:\n        \"\"\"Make parallel HTTP requests.\n\n        Args:\n            urls: Single URL or list of URLs to request.\n            method: HTTP method (GET, POST, etc.).\n            params: Query parameters.\n            data: Request body data.\n            json: JSON body (serialized automatically).\n            headers: Request headers.\n            timeout: Per-request timeout in seconds.\n            proxy: Proxy URL.\n            return_type: How to parse the response (json, text, content, response).\n            follow_redirects: Override default follow_redirects setting.\n            verify_ssl: Override default verify_ssl setting.\n            parse_func: Custom function to parse each response.\n            keys: Keys for dict return (must match urls length).\n\n        Returns:\n            - Single URL: single result\n            - List of URLs: list of results\n            - List of URLs with keys: dict mapping keys to results\n        \"\"\"\n        if not self._backend:\n            raise ConfigurationError(\"Backend not initialized\")\n\n        # Normalize return_type to enum\n        if isinstance(return_type, str):\n            return_type = ReturnType(return_type)\n\n        # Resolve per-request overrides\n        effective_follow_redirects = (\n            follow_redirects if follow_redirects is not None else self.follow_redirects\n        )\n        effective_verify_ssl = verify_ssl if verify_ssl is not None else self.verify_ssl\n        effective_timeout = timeout if timeout is not None else self.timeout\n\n        # Normalize single URL to list for uniform processing\n        if isinstance(urls, str):\n            single_url = True\n            url_list: list[str] = [urls]\n        else:\n            single_url = False\n            url_list = list(urls)\n\n        # Validate keys if provided\n        if keys is not None and len(keys) != len(url_list):\n            raise ConfigurationError(\n                f\"Number of keys ({len(keys)}) must match number of URLs ({len(url_list)})\"\n            )\n\n        # Build request options for each URL\n        request_options = [\n            RequestOptions(\n                url=u,\n                method=method,\n                params=params,\n                data=data,\n                json=json,\n                headers=headers,\n                timeout=effective_timeout,\n                proxy=proxy,\n                return_type=return_type,\n            )\n            for u in url_list\n        ]\n\n        tasks = [\n            self._execute_request(\n                req,\n                follow_redirects=effective_follow_redirects,\n                verify_ssl=effective_verify_ssl,\n            )\n            for req in request_options\n        ]\n\n        results = await asyncio.gather(*tasks, return_exceptions=True)\n\n        failures: dict[str, FailureDetails] = {}\n        processed_results: list[Any] = []\n\n        for idx, result in enumerate(results):\n            current_url = url_list[idx]\n\n            if isinstance(result, Exception):\n                if self.return_none_on_failure:\n                    processed_results.append(None)\n                else:\n                    failures[current_url] = FailureDetails(url=current_url, error=result)\n                    processed_results.append(result)\n            else:\n                # Apply parse_func if provided\n                if parse_func is not None:\n                    result = parse_func(result)\n                processed_results.append(result)\n\n        if failures and not self.return_none_on_failure:\n            raise PartialFailureError(\n                f\"Partial failure: {len(failures)} of {len(url_list)} requests failed\",\n                failures=failures,\n                successes=len([r for r in results if not isinstance(r, Exception)]),\n                total=len(url_list),\n            )\n\n        # Return based on input type and keys\n        if single_url:\n            return processed_results[0]\n        elif keys is not None:\n            return dict(zip(keys, processed_results, strict=True))\n        else:\n            return processed_results\n\n    async def _execute_request(\n        self,\n        req: RequestOptions,\n        *,\n        follow_redirects: bool,\n        verify_ssl: bool,\n    ) -&gt; Any:\n        if not self._backend:\n            raise ConfigurationError(\"Backend not initialized\")\n\n        backend = self._backend\n\n        async def make_request() -&gt; NormalizedResponse:\n            rate_limit_ctx = (\n                self._rate_limiter.acquire() if self._rate_limiter else self._null_context()\n            )\n            async with self._concurrency_semaphore:\n                logger.debug(f\"Concurrency slot acquired, making request to: {req.url}\")\n                async with rate_limit_ctx:\n                    return await backend.request(\n                        RequestConfig(\n                            url=req.url,\n                            method=req.method,\n                            params=req.params,\n                            data=req.data,\n                            json=req.json,\n                            headers=req.headers,\n                            cookies={**self._cookies},\n                            timeout=req.timeout,\n                            proxy=req.proxy,\n                            http2=self._http2,\n                            stream=req.return_type == ReturnType.STREAM,\n                            follow_redirects=follow_redirects,\n                            verify_ssl=verify_ssl,\n                        )\n                    )\n\n        response = await self._retry_strategy.execute(make_request)\n        return self._parse_response(response, req)\n\n    def _parse_response(self, response: NormalizedResponse, req: RequestOptions) -&gt; Any:\n        logger.debug(f\"Request completed: {req.url} - Status: {response.status_code}\")\n        match req.return_type:\n            case ReturnType.JSON:\n                return response.json_data if response.is_json else None\n            case ReturnType.TEXT:\n                return response.text\n            case ReturnType.CONTENT:\n                return response.content\n            case ReturnType.RESPONSE:\n                return response\n            case ReturnType.STREAM:\n                if req.stream_callback:\n                    req.stream_callback(response.content)\n                return None\n</code></pre>"},{"location":"reference/api/fastrequests/#fastreq.client.FastRequests.__aenter__","title":"__aenter__  <code>async</code>","text":"<pre><code>__aenter__() -&gt; FastRequests\n</code></pre> <p>Enter async context manager and initialize backend session.</p> <p>Returns:</p> Type Description <code>FastRequests</code> <p>Self for use in async with statement</p> Source code in <code>fastreq/client.py</code> <pre><code>async def __aenter__(self) -&gt; \"FastRequests\":\n    \"\"\"Enter async context manager and initialize backend session.\n\n    Returns:\n        Self for use in async with statement\n    \"\"\"\n    if self._backend:\n        await self._backend.__aenter__()\n    return self\n</code></pre>"},{"location":"reference/api/fastrequests/#fastreq.client.FastRequests.__aexit__","title":"__aexit__  <code>async</code>","text":"<pre><code>__aexit__(*args: Any) -&gt; None\n</code></pre> <p>Exit async context manager and close backend session.</p> Source code in <code>fastreq/client.py</code> <pre><code>async def __aexit__(self, *args: Any) -&gt; None:\n    \"\"\"Exit async context manager and close backend session.\"\"\"\n    if self._backend:\n        await self._backend.__aexit__(*args)\n</code></pre>"},{"location":"reference/api/fastrequests/#fastreq.client.FastRequests.close","title":"close  <code>async</code>","text":"<pre><code>close() -&gt; None\n</code></pre> <p>Close backend session and cleanup resources.</p> Source code in <code>fastreq/client.py</code> <pre><code>async def close(self) -&gt; None:\n    \"\"\"Close backend session and cleanup resources.\"\"\"\n    if self._backend:\n        await self._backend.close()\n</code></pre>"},{"location":"reference/api/fastrequests/#fastreq.client.FastRequests.reset_cookies","title":"reset_cookies","text":"<pre><code>reset_cookies() -&gt; None\n</code></pre> <p>Clear all session cookies.</p> Source code in <code>fastreq/client.py</code> <pre><code>def reset_cookies(self) -&gt; None:\n    \"\"\"Clear all session cookies.\"\"\"\n    self._cookies = {}\n</code></pre>"},{"location":"reference/api/fastrequests/#fastreq.client.FastRequests.set_cookies","title":"set_cookies","text":"<pre><code>set_cookies(cookies: dict[str, str]) -&gt; None\n</code></pre> <p>Add cookies to the session.</p> <p>Parameters:</p> Name Type Description Default <code>cookies</code> <code>dict[str, str]</code> <p>Dictionary of cookies to add (updates existing cookies)</p> required Source code in <code>fastreq/client.py</code> <pre><code>def set_cookies(self, cookies: dict[str, str]) -&gt; None:\n    \"\"\"Add cookies to the session.\n\n    Args:\n        cookies: Dictionary of cookies to add (updates existing cookies)\n    \"\"\"\n    self._cookies.update(cookies)\n</code></pre>"},{"location":"reference/api/fastrequests/#fastreq.client.FastRequests.request","title":"request  <code>async</code>","text":"<pre><code>request(\n    urls: str,\n    *,\n    method: str = ...,\n    params: dict[str, Any] | None = ...,\n    data: Any = ...,\n    json: Any = ...,\n    headers: dict[str, str] | None = ...,\n    timeout: float | None = ...,\n    proxy: str | None = ...,\n    return_type: ReturnType | str = ...,\n    follow_redirects: bool | None = ...,\n    verify_ssl: bool | None = ...,\n    parse_func: Callable[[Any], T] | None = ...,\n    keys: None = ...\n) -&gt; Any\n</code></pre><pre><code>request(\n    urls: list[str],\n    *,\n    method: str = ...,\n    params: dict[str, Any] | None = ...,\n    data: Any = ...,\n    json: Any = ...,\n    headers: dict[str, str] | None = ...,\n    timeout: float | None = ...,\n    proxy: str | None = ...,\n    return_type: ReturnType | str = ...,\n    follow_redirects: bool | None = ...,\n    verify_ssl: bool | None = ...,\n    parse_func: Callable[[Any], T] | None = ...,\n    keys: list[str] = ...\n) -&gt; dict[str, Any]\n</code></pre><pre><code>request(\n    urls: list[str],\n    *,\n    method: str = ...,\n    params: dict[str, Any] | None = ...,\n    data: Any = ...,\n    json: Any = ...,\n    headers: dict[str, str] | None = ...,\n    timeout: float | None = ...,\n    proxy: str | None = ...,\n    return_type: ReturnType | str = ...,\n    follow_redirects: bool | None = ...,\n    verify_ssl: bool | None = ...,\n    parse_func: Callable[[Any], T] | None = ...,\n    keys: None = ...\n) -&gt; list[Any]\n</code></pre><pre><code>request(\n    urls: str | list[str],\n    *,\n    method: str = ...,\n    params: dict[str, Any] | None = ...,\n    data: Any = ...,\n    json: Any = ...,\n    headers: dict[str, str] | None = ...,\n    timeout: float | None = ...,\n    proxy: str | None = ...,\n    return_type: ReturnType | str = ...,\n    follow_redirects: bool | None = ...,\n    verify_ssl: bool | None = ...,\n    parse_func: Callable[[Any], T] | None = ...,\n    keys: list[str] | None = ...\n) -&gt; Any\n</code></pre> <pre><code>request(\n    urls: str | list[str],\n    *,\n    method: str = \"GET\",\n    params: dict[str, Any] | None = None,\n    data: Any = None,\n    json: Any = None,\n    headers: dict[str, str] | None = None,\n    timeout: float | None = None,\n    proxy: str | None = None,\n    return_type: ReturnType | str = ReturnType.JSON,\n    follow_redirects: bool | None = None,\n    verify_ssl: bool | None = None,\n    parse_func: Callable[[Any], Any] | None = None,\n    keys: list[str] | None = None\n) -&gt; Any\n</code></pre> <p>Make parallel HTTP requests.</p> <p>Parameters:</p> Name Type Description Default <code>urls</code> <code>str | list[str]</code> <p>Single URL or list of URLs to request.</p> required <code>method</code> <code>str</code> <p>HTTP method (GET, POST, etc.).</p> <code>'GET'</code> <code>params</code> <code>dict[str, Any] | None</code> <p>Query parameters.</p> <code>None</code> <code>data</code> <code>Any</code> <p>Request body data.</p> <code>None</code> <code>json</code> <code>Any</code> <p>JSON body (serialized automatically).</p> <code>None</code> <code>headers</code> <code>dict[str, str] | None</code> <p>Request headers.</p> <code>None</code> <code>timeout</code> <code>float | None</code> <p>Per-request timeout in seconds.</p> <code>None</code> <code>proxy</code> <code>str | None</code> <p>Proxy URL.</p> <code>None</code> <code>return_type</code> <code>ReturnType | str</code> <p>How to parse the response (json, text, content, response).</p> <code>JSON</code> <code>follow_redirects</code> <code>bool | None</code> <p>Override default follow_redirects setting.</p> <code>None</code> <code>verify_ssl</code> <code>bool | None</code> <p>Override default verify_ssl setting.</p> <code>None</code> <code>parse_func</code> <code>Callable[[Any], Any] | None</code> <p>Custom function to parse each response.</p> <code>None</code> <code>keys</code> <code>list[str] | None</code> <p>Keys for dict return (must match urls length).</p> <code>None</code> <p>Returns:</p> Type Description <code>Any</code> <ul> <li>Single URL: single result</li> </ul> <code>Any</code> <ul> <li>List of URLs: list of results</li> </ul> <code>Any</code> <ul> <li>List of URLs with keys: dict mapping keys to results</li> </ul> Source code in <code>fastreq/client.py</code> <pre><code>async def request(\n    self,\n    urls: str | list[str],\n    *,\n    method: str = \"GET\",\n    params: dict[str, Any] | None = None,\n    data: Any = None,\n    json: Any = None,\n    headers: dict[str, str] | None = None,\n    timeout: float | None = None,\n    proxy: str | None = None,\n    return_type: ReturnType | str = ReturnType.JSON,\n    follow_redirects: bool | None = None,\n    verify_ssl: bool | None = None,\n    parse_func: Callable[[Any], Any] | None = None,\n    keys: list[str] | None = None,\n) -&gt; Any:\n    \"\"\"Make parallel HTTP requests.\n\n    Args:\n        urls: Single URL or list of URLs to request.\n        method: HTTP method (GET, POST, etc.).\n        params: Query parameters.\n        data: Request body data.\n        json: JSON body (serialized automatically).\n        headers: Request headers.\n        timeout: Per-request timeout in seconds.\n        proxy: Proxy URL.\n        return_type: How to parse the response (json, text, content, response).\n        follow_redirects: Override default follow_redirects setting.\n        verify_ssl: Override default verify_ssl setting.\n        parse_func: Custom function to parse each response.\n        keys: Keys for dict return (must match urls length).\n\n    Returns:\n        - Single URL: single result\n        - List of URLs: list of results\n        - List of URLs with keys: dict mapping keys to results\n    \"\"\"\n    if not self._backend:\n        raise ConfigurationError(\"Backend not initialized\")\n\n    # Normalize return_type to enum\n    if isinstance(return_type, str):\n        return_type = ReturnType(return_type)\n\n    # Resolve per-request overrides\n    effective_follow_redirects = (\n        follow_redirects if follow_redirects is not None else self.follow_redirects\n    )\n    effective_verify_ssl = verify_ssl if verify_ssl is not None else self.verify_ssl\n    effective_timeout = timeout if timeout is not None else self.timeout\n\n    # Normalize single URL to list for uniform processing\n    if isinstance(urls, str):\n        single_url = True\n        url_list: list[str] = [urls]\n    else:\n        single_url = False\n        url_list = list(urls)\n\n    # Validate keys if provided\n    if keys is not None and len(keys) != len(url_list):\n        raise ConfigurationError(\n            f\"Number of keys ({len(keys)}) must match number of URLs ({len(url_list)})\"\n        )\n\n    # Build request options for each URL\n    request_options = [\n        RequestOptions(\n            url=u,\n            method=method,\n            params=params,\n            data=data,\n            json=json,\n            headers=headers,\n            timeout=effective_timeout,\n            proxy=proxy,\n            return_type=return_type,\n        )\n        for u in url_list\n    ]\n\n    tasks = [\n        self._execute_request(\n            req,\n            follow_redirects=effective_follow_redirects,\n            verify_ssl=effective_verify_ssl,\n        )\n        for req in request_options\n    ]\n\n    results = await asyncio.gather(*tasks, return_exceptions=True)\n\n    failures: dict[str, FailureDetails] = {}\n    processed_results: list[Any] = []\n\n    for idx, result in enumerate(results):\n        current_url = url_list[idx]\n\n        if isinstance(result, Exception):\n            if self.return_none_on_failure:\n                processed_results.append(None)\n            else:\n                failures[current_url] = FailureDetails(url=current_url, error=result)\n                processed_results.append(result)\n        else:\n            # Apply parse_func if provided\n            if parse_func is not None:\n                result = parse_func(result)\n            processed_results.append(result)\n\n    if failures and not self.return_none_on_failure:\n        raise PartialFailureError(\n            f\"Partial failure: {len(failures)} of {len(url_list)} requests failed\",\n            failures=failures,\n            successes=len([r for r in results if not isinstance(r, Exception)]),\n            total=len(url_list),\n        )\n\n    # Return based on input type and keys\n    if single_url:\n        return processed_results[0]\n    elif keys is not None:\n        return dict(zip(keys, processed_results, strict=True))\n    else:\n        return processed_results\n</code></pre>"},{"location":"reference/api/globalconfig/","title":"GlobalConfig","text":""},{"location":"reference/api/globalconfig/#fastreq.config.GlobalConfig","title":"fastreq.config.GlobalConfig  <code>dataclass</code>","text":"<p>Global configuration for parallel requests.</p> <p>Can be loaded from environment variables or created programmatically.</p> Example <p>from fastreq.config import GlobalConfig config = GlobalConfig( ...     backend=\"niquests\", ...     default_concurrency=10, ... ) config.save_to_env(\".env\")</p> Environment variables <p>PARALLEL_BACKEND: Backend to use (\"auto\", \"niquests\", \"aiohttp\", \"requests\") PARALLEL_CONCURRENCY: Default concurrency limit PARALLEL_MAX_RETRIES: Default max retries PARALLEL_RATE_LIMIT: Rate limit (requests per second) PARALLEL_RATE_LIMIT_BURST: Rate limit burst size PARALLEL_HTTP2: Enable HTTP/2 (true/false) PARALLEL_RANDOM_USER_AGENT: Rotate user agents (true/false) PARALLEL_RANDOM_PROXY: Enable proxy rotation (true/false) PARALLEL_PROXY_ENABLED: Enable proxies (true/false) PARALLEL_FREE_PROXIES: Enable free proxy fetching (true/false)</p> <p>Attributes:</p> Name Type Description <code>backend</code> <code>str</code> <p>Default backend selection</p> <code>default_concurrency</code> <code>int</code> <p>Default concurrency limit</p> <code>default_max_retries</code> <code>int</code> <p>Default maximum retry attempts</p> <code>rate_limit</code> <code>float | None</code> <p>Rate limit in requests per second (None for no limit)</p> <code>rate_limit_burst</code> <code>int</code> <p>Burst size for rate limiter</p> <code>http2_enabled</code> <code>bool</code> <p>Enable HTTP/2 support</p> <code>random_user_agent</code> <code>bool</code> <p>Enable user agent rotation</p> <code>random_proxy</code> <code>bool</code> <p>Enable proxy rotation</p> <code>proxy_enabled</code> <code>bool</code> <p>Enable proxy usage</p> <code>free_proxies_enabled</code> <code>bool</code> <p>Enable free proxy fetching</p> Source code in <code>fastreq/config.py</code> <pre><code>@dataclass\nclass GlobalConfig:\n    \"\"\"Global configuration for parallel requests.\n\n    Can be loaded from environment variables or created programmatically.\n\n    Example:\n        &gt;&gt;&gt; from fastreq.config import GlobalConfig\n        &gt;&gt;&gt; config = GlobalConfig(\n        ...     backend=\"niquests\",\n        ...     default_concurrency=10,\n        ... )\n        &gt;&gt;&gt; config.save_to_env(\".env\")\n\n    Environment variables:\n        PARALLEL_BACKEND: Backend to use (\"auto\", \"niquests\", \"aiohttp\", \"requests\")\n        PARALLEL_CONCURRENCY: Default concurrency limit\n        PARALLEL_MAX_RETRIES: Default max retries\n        PARALLEL_RATE_LIMIT: Rate limit (requests per second)\n        PARALLEL_RATE_LIMIT_BURST: Rate limit burst size\n        PARALLEL_HTTP2: Enable HTTP/2 (true/false)\n        PARALLEL_RANDOM_USER_AGENT: Rotate user agents (true/false)\n        PARALLEL_RANDOM_PROXY: Enable proxy rotation (true/false)\n        PARALLEL_PROXY_ENABLED: Enable proxies (true/false)\n        PARALLEL_FREE_PROXIES: Enable free proxy fetching (true/false)\n\n    Attributes:\n        backend: Default backend selection\n        default_concurrency: Default concurrency limit\n        default_max_retries: Default maximum retry attempts\n        rate_limit: Rate limit in requests per second (None for no limit)\n        rate_limit_burst: Burst size for rate limiter\n        http2_enabled: Enable HTTP/2 support\n        random_user_agent: Enable user agent rotation\n        random_proxy: Enable proxy rotation\n        proxy_enabled: Enable proxy usage\n        free_proxies_enabled: Enable free proxy fetching\n    \"\"\"\n\n    backend: str = \"auto\"\n    default_concurrency: int = 20\n    default_max_retries: int = 3\n    rate_limit: float | None = None\n    rate_limit_burst: int = 5\n    http2_enabled: bool = True\n    random_user_agent: bool = True\n    random_proxy: bool = False\n    proxy_enabled: bool = False\n    free_proxies_enabled: bool = False\n\n    @classmethod\n    def load_from_env(cls, prefix: str = \"PARALLEL_\") -&gt; \"GlobalConfig\":\n        import os\n\n        def get_bool(key: str, default: bool) -&gt; bool:\n            value = os.getenv(f\"{prefix}{key}\", str(default).lower())\n            return value.lower() == \"true\"\n\n        def get_int(key: str, default: int) -&gt; int:\n            value = os.getenv(f\"{prefix}{key}\")\n            return int(value) if value is not None else default\n\n        def get_float(key: str, default: float | None) -&gt; float | None:\n            value = os.getenv(f\"{prefix}{key}\")\n            return float(value) if value is not None else default\n\n        return cls(\n            backend=os.getenv(f\"{prefix}BACKEND\", \"auto\"),\n            default_concurrency=get_int(\"CONCURRENCY\", 20),\n            default_max_retries=get_int(\"MAX_RETRIES\", 3),\n            rate_limit=get_float(\"RATE_LIMIT\", None),\n            rate_limit_burst=get_int(\"RATE_LIMIT_BURST\", 5),\n            http2_enabled=get_bool(\"HTTP2\", True),\n            random_user_agent=get_bool(\"RANDOM_USER_AGENT\", True),\n            random_proxy=get_bool(\"RANDOM_PROXY\", False),\n            proxy_enabled=get_bool(\"PROXY_ENABLED\", False),\n            free_proxies_enabled=get_bool(\"FREE_PROXIES\", False),\n        )\n\n    def to_env(self, prefix: str = \"PARALLEL_\") -&gt; dict[str, str]:\n        \"\"\"Convert config to environment variable dictionary.\n\n        Args:\n            prefix: Prefix for environment variable names\n\n        Returns:\n            Dictionary of environment variable name to value\n        \"\"\"\n        env: dict[str, str] = {\n            f\"{prefix}BACKEND\": self.backend,\n            f\"{prefix}CONCURRENCY\": str(self.default_concurrency),\n            f\"{prefix}MAX_RETRIES\": str(self.default_max_retries),\n            f\"{prefix}RATE_LIMIT\": str(self.rate_limit) if self.rate_limit else \"\",\n            f\"{prefix}RATE_LIMIT_BURST\": str(self.rate_limit_burst),\n            f\"{prefix}HTTP2\": str(self.http2_enabled).lower(),\n            f\"{prefix}RANDOM_USER_AGENT\": str(self.random_user_agent).lower(),\n            f\"{prefix}RANDOM_PROXY\": str(self.random_proxy).lower(),\n            f\"{prefix}PROXY_ENABLED\": str(self.proxy_enabled).lower(),\n            f\"{prefix}FREE_PROXIES\": str(self.free_proxies_enabled).lower(),\n        }\n        return env\n\n    def save_to_env(self, path: Path | str, prefix: str = \"PARALLEL_\") -&gt; None:\n        \"\"\"Save configuration to an environment file.\n\n        Args:\n            path: Path to save the .env file\n            prefix: Prefix for environment variable names\n\n        Example:\n            &gt;&gt;&gt; config = GlobalConfig(backend=\"niquests\")\n            &gt;&gt;&gt; config.save_to_env(\".env\")\n        \"\"\"\n        p = Path(path) if isinstance(path, str) else path\n        env_content = \"\"\n        for key, value in self.to_env(prefix).items():\n            if value:\n                env_content += f\"{key}={value}\\n\"\n        p.write_text(env_content)\n</code></pre>"},{"location":"reference/api/globalconfig/#fastreq.config.GlobalConfig.to_env","title":"to_env","text":"<pre><code>to_env(prefix: str = 'PARALLEL_') -&gt; dict[str, str]\n</code></pre> <p>Convert config to environment variable dictionary.</p> <p>Parameters:</p> Name Type Description Default <code>prefix</code> <code>str</code> <p>Prefix for environment variable names</p> <code>'PARALLEL_'</code> <p>Returns:</p> Type Description <code>dict[str, str]</code> <p>Dictionary of environment variable name to value</p> Source code in <code>fastreq/config.py</code> <pre><code>def to_env(self, prefix: str = \"PARALLEL_\") -&gt; dict[str, str]:\n    \"\"\"Convert config to environment variable dictionary.\n\n    Args:\n        prefix: Prefix for environment variable names\n\n    Returns:\n        Dictionary of environment variable name to value\n    \"\"\"\n    env: dict[str, str] = {\n        f\"{prefix}BACKEND\": self.backend,\n        f\"{prefix}CONCURRENCY\": str(self.default_concurrency),\n        f\"{prefix}MAX_RETRIES\": str(self.default_max_retries),\n        f\"{prefix}RATE_LIMIT\": str(self.rate_limit) if self.rate_limit else \"\",\n        f\"{prefix}RATE_LIMIT_BURST\": str(self.rate_limit_burst),\n        f\"{prefix}HTTP2\": str(self.http2_enabled).lower(),\n        f\"{prefix}RANDOM_USER_AGENT\": str(self.random_user_agent).lower(),\n        f\"{prefix}RANDOM_PROXY\": str(self.random_proxy).lower(),\n        f\"{prefix}PROXY_ENABLED\": str(self.proxy_enabled).lower(),\n        f\"{prefix}FREE_PROXIES\": str(self.free_proxies_enabled).lower(),\n    }\n    return env\n</code></pre>"},{"location":"reference/api/globalconfig/#fastreq.config.GlobalConfig.save_to_env","title":"save_to_env","text":"<pre><code>save_to_env(\n    path: Path | str, prefix: str = \"PARALLEL_\"\n) -&gt; None\n</code></pre> <p>Save configuration to an environment file.</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>Path | str</code> <p>Path to save the .env file</p> required <code>prefix</code> <code>str</code> <p>Prefix for environment variable names</p> <code>'PARALLEL_'</code> Example <p>config = GlobalConfig(backend=\"niquests\") config.save_to_env(\".env\")</p> Source code in <code>fastreq/config.py</code> <pre><code>def save_to_env(self, path: Path | str, prefix: str = \"PARALLEL_\") -&gt; None:\n    \"\"\"Save configuration to an environment file.\n\n    Args:\n        path: Path to save the .env file\n        prefix: Prefix for environment variable names\n\n    Example:\n        &gt;&gt;&gt; config = GlobalConfig(backend=\"niquests\")\n        &gt;&gt;&gt; config.save_to_env(\".env\")\n    \"\"\"\n    p = Path(path) if isinstance(path, str) else path\n    env_content = \"\"\n    for key, value in self.to_env(prefix).items():\n        if value:\n            env_content += f\"{key}={value}\\n\"\n    p.write_text(env_content)\n</code></pre>"},{"location":"reference/api/returntype/","title":"ReturnType","text":""},{"location":"reference/api/returntype/#fastreq.client.ReturnType","title":"fastreq.client.ReturnType","text":"<p>               Bases: <code>str</code>, <code>Enum</code></p> <p>Enum for response parsing options.</p> <p>Attributes:</p> Name Type Description <code>JSON</code> <p>Parse response as JSON (returns dict/list or None)</p> <code>TEXT</code> <p>Return response as decoded string</p> <code>CONTENT</code> <p>Return response as raw bytes</p> <code>RESPONSE</code> <p>Return full NormalizedResponse object</p> <code>STREAM</code> <p>Stream response content (requires stream_callback)</p> Source code in <code>fastreq/client.py</code> <pre><code>class ReturnType(str, Enum):\n    \"\"\"Enum for response parsing options.\n\n    Attributes:\n        JSON: Parse response as JSON (returns dict/list or None)\n        TEXT: Return response as decoded string\n        CONTENT: Return response as raw bytes\n        RESPONSE: Return full NormalizedResponse object\n        STREAM: Stream response content (requires stream_callback)\n    \"\"\"\n\n    JSON = \"json\"\n    TEXT = \"text\"\n    CONTENT = \"content\"\n    RESPONSE = \"response\"\n    STREAM = \"stream\"\n</code></pre>"},{"location":"tutorials/","title":"Tutorials","text":"<p>Welcome to the tutorials section! These step-by-step guides will help you learn fastreq from the ground up, starting with installation and basic usage, and progressing to more advanced concepts.</p>"},{"location":"tutorials/#tutorial-path","title":"Tutorial Path","text":"<p>We recommend following the tutorials in order:</p> <ol> <li>Getting Started - Installation and your first parallel requests (~10 min)</li> <li>Parallel Fundamentals - Understanding concurrency and async patterns (~15 min)</li> <li>Handling Errors - Working with exceptions and error handling (~15 min)</li> </ol>"},{"location":"tutorials/#what-youll-learn","title":"What You'll Learn","text":"<p>After completing these tutorials, you'll be able to:</p> <ul> <li>Install and configure fastreq</li> <li>Make basic parallel HTTP requests</li> <li>Understand how async/await works with parallel requests</li> <li>Handle different types of errors and failures</li> <li>Configure backends, retries, and rate limiting</li> </ul>"},{"location":"tutorials/#next-steps","title":"Next Steps","text":"<p>After completing the tutorials, check out the How-to Guides for practical solutions to common tasks, or dive into the Reference section for complete API documentation.</p>"},{"location":"tutorials/getting-started/","title":"Getting Started","text":"<p>This tutorial will walk you through installing fastreq and making your first parallel HTTP requests.</p> <p>Estimated reading time: 10 minutes</p>"},{"location":"tutorials/getting-started/#installation","title":"Installation","text":"<p>Install fastreq using pip:</p> <pre><code>pip install fastreq\n</code></pre>"},{"location":"tutorials/getting-started/#installing-with-backend-support","title":"Installing with Backend Support","text":"<p>The library supports three HTTP backends. You can install with all backends or choose specific ones:</p> <pre><code># Install with all backends (recommended)\npip install fastreq[all]\n\n# Install with specific backend\npip install fastreq[niquests]  # HTTP/2 support\npip install fastreq[aiohttp]\npip install fastreq[requests]\n</code></pre>"},{"location":"tutorials/getting-started/#backend-priority","title":"Backend Priority","text":"<p>The library automatically detects and uses the best available backend in this order:</p> <ol> <li>niquests - Recommended (HTTP/2 support, streaming, async native)</li> <li>aiohttp - Streaming support, async native</li> <li>requests - Sync-first, streaming via thread wrapper</li> </ol>"},{"location":"tutorials/getting-started/#your-first-parallel-request","title":"Your First Parallel Request","text":"<p>Let's start with a simple example that makes multiple API calls in parallel:</p> <pre><code>from fastreq import fastreq\n\n# Make parallel requests\nresults = fastreq(\n    urls=[\n        \"https://api.github.com/repos/python/cpython\",\n        \"https://api.github.com/repos/python/cpython/issues\",\n        \"https://api.github.com/repos/python/cpython/pulls\",\n    ],\n    concurrency=3,\n)\n\n# Process results\nfor result in results:\n    print(f\"Name: {result.get('name', result.get('title', 'N/A'))}\")\n</code></pre> <p>This code fetches information about the CPython repository, issues, and pull requests in parallel, significantly faster than making these requests sequentially.</p>"},{"location":"tutorials/getting-started/#async-usage","title":"Async Usage","text":"<p>For async applications, use the async version:</p> <pre><code>import asyncio\nfrom fastreq import fastreq_async\n\nasync def main():\n    results = await fastreq_async(\n        urls=[\n            \"https://httpbin.org/delay/1\",\n            \"https://httpbin.org/delay/2\",\n            \"https://httpbin.org/delay/3\",\n        ],\n        concurrency=5,\n        timeout=10,\n    )\n    return results\n\nresults = asyncio.run(main())\nprint(f\"Got {len(results)} results\")\n</code></pre>"},{"location":"tutorials/getting-started/#response-types","title":"Response Types","text":"<p>By default, responses are parsed as JSON. You can specify different return types:</p> <pre><code># Get response as JSON (default)\nresults = fastreq(\n    urls=[\"https://api.github.com/repos/python/cpython\"],\n    return_type=\"json\",\n)\n\n# Get response as text\nresults = fastreq(\n    urls=[\"https://example.com\"],\n    return_type=\"text\",\n)\n\n# Get raw bytes\nresults = fastreq(\n    urls=[\"https://example.com\"],\n    return_type=\"content\",\n)\n\n# Get full response object\nfrom fastreq import fastreq, ReturnType\n\nresults = fastreq(\n    urls=[\"https://httpbin.org/get\"],\n    return_type=ReturnType.RESPONSE,\n)\nprint(results[0].status_code)  # 200\nprint(results[0].headers)      # Response headers\n</code></pre>"},{"location":"tutorials/getting-started/#configuration-options","title":"Configuration Options","text":"<p>Configure the client with various options:</p> <pre><code>from fastreq import fastreq\n\nresults = fastreq(\n    urls=[\"https://httpbin.org/get\"] * 5,\n    concurrency=3,            # Max concurrent requests\n    max_retries=2,            # Retry failed requests up to 2 times\n    rate_limit=10,            # 10 requests per second\n    timeout=5,                # 5 second timeout per request\n    debug=True,               # Enable debug logging\n    backend=\"niquests\",       # Explicit backend selection\n)\n</code></pre>"},{"location":"tutorials/getting-started/#post-requests","title":"POST Requests","text":"<p>Make POST requests with JSON data:</p> <pre><code>results = fastreq(\n    urls=[\"https://httpbin.org/post\"] * 3,\n    method=\"POST\",\n    json={\"key\": \"value\"},\n    headers={\"Content-Type\": \"application/json\"},\n)\n</code></pre>"},{"location":"tutorials/getting-started/#using-a-context-manager","title":"Using a Context Manager","text":"<p>For more control, use the FastRequests class with an async context manager:</p> <pre><code>import asyncio\nfrom fastreq import FastRequests\n\nasync def main():\n    async with FastRequests(concurrency=5) as client:\n        # First batch\n        results1 = await client.request(\n            urls=[\"https://api.github.com/repos/python/cpython\"],\n        )\n\n        # Second batch (reuses the same session)\n        results2 = await client.request(\n            urls=[\"https://api.github.com/repos/legout/fastreq\"],\n        )\n\n    return results1, results2\n\nresults1, results2 = asyncio.run(main())\n</code></pre>"},{"location":"tutorials/getting-started/#next-steps","title":"Next Steps","text":"<ul> <li>Learn about Parallel Fundamentals to understand concurrency and async patterns</li> <li>Explore How-to Guides for practical solutions</li> <li>Check the API Reference for complete documentation</li> </ul>"},{"location":"tutorials/handling-errors/","title":"Handling Errors","text":"<p>This tutorial covers error handling patterns and working with exceptions in fastreq.</p> <p>Estimated reading time: 15 minutes</p>"},{"location":"tutorials/handling-errors/#types-of-errors","title":"Types of Errors","text":"<p>The library defines several exception types:</p> <ul> <li><code>FastRequestsError</code>: Base exception class</li> <li><code>BackendError</code>: Backend operation failures</li> <li><code>ProxyError</code>: Proxy-related failures</li> <li><code>RetryExhaustedError</code>: All retry attempts exhausted</li> <li><code>RateLimitExceededError</code>: Rate limit triggered</li> <li><code>ValidationError</code>: Invalid input parameters</li> <li><code>ConfigurationError</code>: Invalid configuration</li> <li><code>PartialFailureError</code>: Some requests succeeded, others failed</li> </ul>"},{"location":"tutorials/handling-errors/#basic-exception-handling","title":"Basic Exception Handling","text":"<p>Wrap your requests in try-except blocks:</p> <pre><code>from fastreq import fastreq, FastRequestsError\n\ntry:\n    results = fastreq(\n        urls=[\"https://api.github.com/invalid\"],\n    )\nexcept FastRequestsError as e:\n    print(f\"Request failed: {e}\")\n</code></pre>"},{"location":"tutorials/handling-errors/#partial-failures","title":"Partial Failures","text":"<p>When making multiple requests, some may succeed while others fail. By default, the library raises <code>PartialFailureError</code>:</p> <pre><code>from fastreq import fastreq, PartialFailureError\n\nurls = [\n    \"https://api.github.com/repos/python/cpython\",  # Valid\n    \"https://invalid-url-that-does-not-exist.com\",  # Invalid\n    \"https://api.github.com/repos/python/pypy\",     # Valid\n]\n\ntry:\n    results = fastreq(urls=urls)\nexcept PartialFailureError as e:\n    print(f\"Partial failure: {e.successes}/{e.total} succeeded\")\n    print(f\"Failed URLs: {e.get_failed_urls()}\")\n\n    # Access individual failures\n    for url, details in e.failures.items():\n        print(f\"  {url}: {details.error}\")\n</code></pre>"},{"location":"tutorials/handling-errors/#graceful-failure-handling","title":"Graceful Failure Handling","text":"<p>Use <code>return_none_on_failure</code> to return <code>None</code> for failed requests instead of raising exceptions:</p> <pre><code>from fastreq import fastreq\n\nresults = fastreq(\n    urls=[\n        \"https://api.github.com/repos/python/cpython\",\n        \"https://invalid-url.com\",\n        \"https://api.github.com/repos/python/pypy\",\n    ],\n    return_none_on_failure=True,\n)\n\nfor url, result in zip(urls, results):\n    if result is None:\n        print(f\"Failed: {url}\")\n    else:\n        print(f\"Success: {url}\")\n</code></pre>"},{"location":"tutorials/handling-errors/#retry-configuration","title":"Retry Configuration","text":"<p>Control retry behavior with <code>max_retries</code>:</p> <pre><code>from fastreq import fastreq\n\n# Retry up to 3 times (default)\nresults = fastreq(\n    urls=[\"https://api.example.com/unstable\"],\n    max_retries=3,\n)\n\n# Disable retries\nresults = fastreq(\n    urls=[\"https://api.example.com/unstable\"],\n    max_retries=0,\n)\n</code></pre>"},{"location":"tutorials/handling-errors/#catching-retry-exhaustion","title":"Catching Retry Exhaustion","text":"<pre><code>from fastreq import fastreq, RetryExhaustedError\n\ntry:\n    results = fastreq(\n        urls=[\"https://api.example.com/unreliable\"],\n        max_retries=3,\n    )\nexcept RetryExhaustedError as e:\n    print(f\"Retries exhausted after {e.attempts} attempts\")\n    print(f\"Last error: {e.last_error}\")\n</code></pre>"},{"location":"tutorials/handling-errors/#timeout-handling","title":"Timeout Handling","text":"<p>Set timeouts to prevent hanging requests:</p> <pre><code>from fastreq import fastreq\nfrom concurrent.futures import TimeoutError\n\ntry:\n    results = fastreq(\n        urls=[\"https://httpbin.org/delay/10\"],\n        timeout=5,  # 5 second timeout\n    )\nexcept TimeoutError:\n    print(\"Request timed out\")\n</code></pre>"},{"location":"tutorials/handling-errors/#validation-errors","title":"Validation Errors","text":"<p>Catch validation errors for invalid inputs:</p> <pre><code>from fastreq import fastreq, ValidationError\n\ntry:\n    results = fastreq(\n        urls=[\"ftp://invalid-protocol.com\"],  # Invalid URL\n    )\nexcept ValidationError as e:\n    print(f\"Validation error: {e}\")\n    print(f\"Field: {e.field_name}\")\n</code></pre>"},{"location":"tutorials/handling-errors/#error-handling-with-context-manager","title":"Error Handling with Context Manager","text":"<p>Using a context manager gives you more control:</p> <pre><code>import asyncio\nfrom fastreq import FastRequests, PartialFailureError\n\nasync def fetch_with_retry():\n    async with FastRequests(max_retries=3) as client:\n        try:\n            results = await client.request(\n                urls=[\n                    \"https://api.github.com/repos/python/cpython\",\n                    \"https://invalid-url.com\",\n                ],\n            )\n            return results\n        except PartialFailureError as e:\n            print(f\"Partial failure: {e.successes}/{e.total}\")\n            # Handle partial results\n            return None\n\nresults = asyncio.run(fetch_with_retry())\n</code></pre>"},{"location":"tutorials/handling-errors/#best-practices","title":"Best Practices","text":""},{"location":"tutorials/handling-errors/#1-use-specific-exceptions","title":"1. Use Specific Exceptions","text":"<pre><code># Good: Catch specific exceptions\nfrom fastreq import RetryExhaustedError, PartialFailureError\n\ntry:\n    results = fastreq(urls=urls)\nexcept RetryExhaustedError as e:\n    # Handle retry exhaustion\n    pass\nexcept PartialFailureError as e:\n    # Handle partial failures\n    pass\nexcept FastRequestsError as e:\n    # Catch-all for other errors\n    pass\n</code></pre>"},{"location":"tutorials/handling-errors/#2-log-errors","title":"2. Log Errors","text":"<pre><code>from loguru import logger\nfrom fastreq import fastreq, PartialFailureError\n\ntry:\n    results = fastreq(urls=urls)\nexcept PartialFailureError as e:\n    logger.error(f\"Partial failure: {e.successes}/{e.total}\")\n    for url, details in e.failures.items():\n        logger.error(f\"  {url}: {details.error}\")\n</code></pre>"},{"location":"tutorials/handling-errors/#3-implement-fallback-logic","title":"3. Implement Fallback Logic","text":"<pre><code>from fastreq import fastreq\n\ndef fetch_with_fallback(urls):\n    try:\n        return fastreq(urls=urls)\n    except PartialFailureError:\n        # Retry only failed URLs\n        failed_urls = list(e.get_failed_urls())\n        return fastreq(urls=failed_urls)\n</code></pre>"},{"location":"tutorials/handling-errors/#4-use-return_none_on_failure-for-non-critical-requests","title":"4. Use <code>return_none_on_failure</code> for Non-Critical Requests","text":"<pre><code>from fastreq import fastreq\n\n# Fetch multiple resources, ignore failures\nresults = fastreq(\n    urls=[\n        \"https://api1.example.com/data\",\n        \"https://api2.example.com/data\",\n        \"https://api3.example.com/data\",\n    ],\n    return_none_on_failure=True,\n)\n\nvalid_results = [r for r in results if r is not None]\nprint(f\"Got {len(valid_results)} valid results\")\n</code></pre>"},{"location":"tutorials/handling-errors/#summary","title":"Summary","text":"<ul> <li>Use try-except to handle exceptions</li> <li><code>PartialFailureError</code> indicates mixed success/failure</li> <li><code>return_none_on_failure</code> for graceful degradation</li> <li>Configure <code>max_retries</code> for automatic retries</li> <li>Set <code>timeout</code> to prevent hanging requests</li> <li>Use specific exception types for better error handling</li> </ul>"},{"location":"tutorials/handling-errors/#next-steps","title":"Next Steps","text":"<ul> <li>Explore How-to Guides for more practical examples</li> <li>Check the API Reference for complete exception documentation</li> </ul>"},{"location":"tutorials/parallel-fundamentals/","title":"Parallel Fundamentals","text":"<p>This tutorial explains the core concepts of parallel requests: concurrency, async/await, and backend selection.</p> <p>Estimated reading time: 15 minutes</p>"},{"location":"tutorials/parallel-fundamentals/#what-is-concurrency","title":"What is Concurrency?","text":"<p>Concurrency means performing multiple operations at the same time. In the context of HTTP requests, it means making multiple network calls simultaneously instead of one after another.</p>"},{"location":"tutorials/parallel-fundamentals/#sequential-vs-parallel","title":"Sequential vs Parallel","text":"<pre><code>import time\n\n# Sequential requests (slow)\nstart = time.time()\nfor i in range(5):\n    requests.get(\"https://httpbin.org/delay/1\")\nprint(f\"Sequential: {time.time() - start:.1f}s\")  # ~5 seconds\n\n# Parallel requests (fast)\nfrom fastreq import fastreq\n\nstart = time.time()\nfastreq(\n    urls=[\"https://httpbin.org/delay/1\"] * 5,\n    concurrency=5,\n)\nprint(f\"Parallel: {time.time() - start:.1f}s\")  # ~1 second\n</code></pre> <p>In this example, sequential requests take ~5 seconds (1 second per request), while parallel requests take only ~1 second because all 5 requests happen simultaneously.</p>"},{"location":"tutorials/parallel-fundamentals/#understanding-asyncawait","title":"Understanding Async/Await","text":"<p>The library uses Python's <code>async</code> and <code>await</code> syntax for parallel execution.</p>"},{"location":"tutorials/parallel-fundamentals/#async-basics","title":"Async Basics","text":"<pre><code>import asyncio\nfrom fastreq import fastreq_async\n\nasync def fetch_data():\n    # This async function can pause while waiting for network I/O\n    results = await fastreq_async(\n        urls=[\"https://api.github.com/repos/python/cpython\"],\n    )\n    return results\n\n# Run async code\nresults = asyncio.run(fetch_data())\n</code></pre>"},{"location":"tutorials/parallel-fundamentals/#how-it-works","title":"How It Works","text":"<p>When you use <code>await fastreq_async()</code>, the function:</p> <ol> <li>Creates multiple async tasks (one per URL)</li> <li>Executes tasks concurrently using <code>asyncio.gather()</code></li> <li>Pauses while waiting for network responses</li> <li>Returns when all requests complete</li> </ol> <p>This allows Python to efficiently wait for multiple network operations simultaneously.</p>"},{"location":"tutorials/parallel-fundamentals/#concurrency-limits","title":"Concurrency Limits","text":"<p>The <code>concurrency</code> parameter controls how many requests run simultaneously.</p> <pre><code>from fastreq import fastreq\n\n# Process 100 URLs, 10 at a time\nresults = fastreq(\n    urls=[f\"https://api.example.com/page/{i}\" for i in range(100)],\n    concurrency=10,  # Max 10 concurrent requests\n)\n</code></pre>"},{"location":"tutorials/parallel-fundamentals/#choosing-the-right-concurrency","title":"Choosing the Right Concurrency","text":"<ul> <li>Low concurrency (1-5): For rate-limited APIs or when preserving order matters</li> <li>Medium concurrency (10-20): Good balance for most public APIs</li> <li>High concurrency (50-100): For internal services or when speed is critical</li> </ul> <p>Be careful with high concurrency - it may: - Trigger rate limits - Overload servers - Exhaust local resources</p>"},{"location":"tutorials/parallel-fundamentals/#backend-selection","title":"Backend Selection","text":"<p>The library abstracts away different HTTP client libraries.</p>"},{"location":"tutorials/parallel-fundamentals/#auto-detection","title":"Auto-Detection","text":"<pre><code># Automatically picks the best available backend\nresults = fastreq(\n    urls=[\"https://httpbin.org/get\"],\n    backend=\"auto\",  # Default\n)\n</code></pre>"},{"location":"tutorials/parallel-fundamentals/#explicit-backend-selection","title":"Explicit Backend Selection","text":"<pre><code># Force specific backend\nresults = fastreq(\n    urls=[\"https://httpbin.org/get\"],\n    backend=\"niquests\",  # or \"aiohttp\", \"requests\"\n)\n</code></pre>"},{"location":"tutorials/parallel-fundamentals/#backend-comparison","title":"Backend Comparison","text":"Feature niquests aiohttp requests HTTP/2 Support \u2705 Yes \u274c No \u274c No Streaming \u2705 Yes \u2705 Yes \u2705 Yes Async Native \u2705 Yes \u2705 Yes \u274c No Sync Native \u2705 Yes \u274c No \u2705 Yes Ecosystem New Mature Mature <p>Recommendation: Use <code>niquests</code> for HTTP/2 support and best performance.</p>"},{"location":"tutorials/parallel-fundamentals/#rate-limiting","title":"Rate Limiting","text":"<p>Control request rate to avoid overwhelming servers or hitting rate limits.</p> <pre><code>from fastreq import fastreq\n\n# Limit to 10 requests per second with burst of 5\nresults = fastreq(\n    urls=[\"https://api.example.com/endpoint\"] * 50,\n    rate_limit=10,           # 10 requests per second\n    rate_limit_burst=5,      # Allow bursts of 5\n)\n</code></pre>"},{"location":"tutorials/parallel-fundamentals/#why-rate-limit","title":"Why Rate Limit?","text":"<ul> <li>Avoid API rate limits (e.g., 1000 requests/hour)</li> <li>Be a good citizen and don't overwhelm servers</li> <li>Maintain predictable performance</li> </ul>"},{"location":"tutorials/parallel-fundamentals/#retry-logic","title":"Retry Logic","text":"<p>Automatically retry failed requests with exponential backoff.</p> <pre><code>from fastreq import fastreq\n\n# Retry up to 3 times with backoff\nresults = fastreq(\n    urls=[\"https://api.example.com/unstable\"],\n    max_retries=3,\n)\n</code></pre>"},{"location":"tutorials/parallel-fundamentals/#how-backoff-works","title":"How Backoff Works","text":"<pre><code># Attempt 0: immediate\n# Attempt 1: wait 1s (1.0 * 2^1)\n# Attempt 2: wait 2s (1.0 * 2^2)\n# Attempt 3: wait 4s (1.0 * 2^3)\n# Failed after 4 total attempts\n</code></pre> <p>The library adds jitter (random variation) to prevent thundering herd problems.</p>"},{"location":"tutorials/parallel-fundamentals/#summary","title":"Summary","text":"<p>Key concepts: - Concurrency: Make multiple requests simultaneously - Async/Await: Use <code>asyncio</code> for efficient parallel execution - Concurrency Limit: Control how many requests run at once - Backends: Choose niquests, aiohttp, or requests - Rate Limiting: Control request rate to avoid rate limits - Retry Logic: Automatically retry failed requests</p>"},{"location":"tutorials/parallel-fundamentals/#next-steps","title":"Next Steps","text":"<ul> <li>Learn about Handling Errors for robust error handling</li> <li>Explore How-to Guides for practical examples</li> </ul>"}]}